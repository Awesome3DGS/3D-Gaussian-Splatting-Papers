### Optimized 3D Gaussian Splatting using Coarse-to-Fine Image Frequency Modulation

The field of Novel View Synthesis has been revolutionized by 3D Gaussian Splatting (3DGS), which enables high-quality scene reconstruction that can be rendered in real-time. 3DGS-based techniques typically suffer from high GPU memory and disk storage requirements which limits their practical application on consumer-grade devices. We propose Opti3DGS, a novel frequency-modulated coarse-to-fine optimization framework that aims to minimize the number of Gaussian primitives used to represent a scene, thus reducing memory and storage demands. Opti3DGS leverages image frequency modulation, initially enforcing a coarse scene representation and progressively refining it by modulating frequency details in the training images. On the baseline 3DGS, we demonstrate an average reduction of 62% in Gaussians, a 40% reduction in the training GPU memory requirements and a 20% reduction in optimization time without sacrificing the visual quality. Furthermore, we show that our method integrates seamlessly with many 3DGS-based techniques, consistently reducing the number of Gaussian primitives while maintaining, and often improving, visual quality. Additionally, Opti3DGS inherently produces a level-of-detail scene representation at no extra cost, a natural byproduct of the optimization pipeline.

新颖视角合成领域已经被三维高斯点云渲染（3DGS）所革新，它能够实现高质量的场景重建，并且能够实时渲染。然而，基于3DGS的技术通常存在较高的GPU内存和磁盘存储需求，这限制了它们在消费级设备上的实际应用。我们提出了Opti3DGS，一种新颖的频率调制粗到细优化框架，旨在最小化用于表示场景的高斯原语数量，从而减少内存和存储需求。Opti3DGS利用图像频率调制，最初强制执行粗略的场景表示，并通过调节训练图像中的频率细节逐步优化该表示。在基准的3DGS上，我们展示了高斯点数量平均减少了62%，训练GPU内存需求减少了40%，优化时间减少了20%，且视觉质量没有受到牺牲。此外，我们展示了我们的方法可以与许多基于3DGS的技术无缝集成，在保持视觉质量的同时，始终减少高斯原语的数量，且通常还能改善视觉质量。更重要的是，Opti3DGS自然地生成了一个分级细节的场景表示，而无需额外的成本，这是优化流程的自然副产品。
