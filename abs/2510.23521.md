### Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation

Remembering where object segments were predicted in the past is useful for improving the accuracy and consistency of class-agnostic video segmentation algorithms. Existing video segmentation algorithms typically use either no object-level memory (e.g. FastSAM) or they use implicit memories in the form of recurrent neural network features (e.g. SAM2). In this paper, we augment both types of segmentation models using an explicit 3D memory and show that the resulting models have more accurate and consistent predictions. For this, we develop an online 3D Gaussian Splatting (3DGS) technique to store predicted object-level segments generated throughout the duration of a video. Based on this 3DGS representation, a set of fusion techniques are developed, named FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve their respective foundation models' predictions. Ablation experiments are used to validate the proposed techniques' design and hyperparameter settings. Results from both real-world and simulated benchmarking experiments show that models which use explicit 3D memories result in more accurate and consistent predictions than those which use no memory or only implicit neural network memories.

记忆视频中过去所预测的目标分割位置，有助于提升类别无关视频分割算法的准确性与一致性。现有视频分割算法通常要么不使用目标级别的记忆（如 FastSAM），要么仅使用隐式记忆，例如循环神经网络特征（如 SAM2）。在本文中，我们通过引入显式的三维记忆来增强这两类分割模型，并证明增强后的模型在预测准确性和一致性方面都有显著提升。为此，我们提出了一种在线 3D 高斯泼洒（3DGS）技术，用于存储视频整个时序过程中预测得到的目标级别分割信息。基于该 3DGS 表示，我们开发了一系列融合技术，分别命名为 FastSAM-Splat 和 SAM2-Splat，利用显式的 3DGS 记忆来提升各自基础模型的预测性能。我们还通过消融实验验证了所提出方法的设计合理性与超参数设置。来自真实世界与模拟基准测试的实验结果表明，相较于不使用记忆或仅使用隐式神经网络记忆的模型，采用显式三维记忆的模型在预测准确度和一致性方面表现得更加优越。
