### One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements

Reconstructing 3D Radiance Field (RF) scenes through opaque obstacles is a long-standing goal, yet it is fundamentally constrained by a laborious data acquisition process requiring thousands of static measurements, which treats human motion as noise to be filtered. This work introduces a new paradigm with a core objective: to perform fast, data-efficient, and high-fidelity RF reconstruction of occluded 3D static scenes, using only a single, brief human walk. We argue that this unstructured motion is not noise, but is in fact an information-rich signal available for reconstruction. To achieve this, we design a factorization framework based on composite 3D Gaussian Splatting (3DGS) that learns to model the dynamic effects of human motion from the persistent static scene geometry within a raw RF stream. Trained on just a single 60-second casual walk, our model reconstructs the full static scene with a Structural Similarity Index (SSIM) of 0.96, remarkably outperforming heavily-sampled state-of-the-art (SOTA) by 12%. By transforming the human movements into its valuable signals, our method eliminates the data acquisition bottleneck and paves the way for on-the-fly 3D RF mapping of unseen environments.

通过不透明障碍物重建三维辐射场（Radiance Field, RF）场景一直是一个长期目标，但该任务本质上受到繁重的数据采集流程的限制，通常需要成千上万次静态测量，并将人类运动视为需要过滤的噪声。本文提出了一种新的范式，核心目标是仅利用一次短暂的人类行走，实现对被遮挡三维静态场景的快速、高效且高保真的RF重建。我们认为这种非结构化运动并非噪声，反而是可用于重建的高信息量信号。为此，我们设计了一个基于复合三维高斯溅射（3DGS）的因式分解框架，该框架能够从原始RF流中持续存在的静态场景几何中学习人类运动的动态效应。仅通过一次 60 秒的随意行走训练后，我们的模型即可重建完整静态场景，结构相似度指数（SSIM）高达 0.96，显著超过依赖密集采样的最先进方法（SOTA）12%。通过将人类动作转化为有价值的信号，我们的方法消除了数据采集瓶颈，为未知环境的即时三维RF建图开辟了新路径。
