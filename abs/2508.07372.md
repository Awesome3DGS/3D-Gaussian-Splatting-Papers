### DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery

3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method, obtaining high-quality reconstruction with real-time rendering runtime performance. The main idea behind 3DGS is to represent the scene as a collection of 3D gaussians, while learning their parameters to fit the given views of the scene. While achieving superior performance in the presence of many views, 3DGS struggles with sparse view reconstruction, where the input views are sparse and do not fully cover the scene and have low overlaps. In this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By using the DIP prior, which utilizes internal structure and patterns, with coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla 3DGS fails, such as sparse view recovery. Note that our approach does not use any pre-trained models such as generative models and depth estimation, but rather relies only on the input frames. Among such methods, DIP-GS obtains state-of-the-art (SOTA) competitive results on various sparse-view reconstruction tasks, demonstrating its capabilities.

三维高斯溅射（3DGS）是一种领先的三维场景重建方法，能够在保持实时渲染性能的同时获得高质量的重建效果。3DGS 的核心思想是将场景表示为一组三维高斯，并通过学习其参数来拟合给定的场景视图。尽管在拥有大量视图时能实现优越表现，但3DGS在稀疏视图重建方面表现不佳，此时输入视图稀少，无法全面覆盖场景且重叠度低。本文提出了 DIP-GS，一种基于深度图像先验（DIP）的3DGS表示方法。通过利用DIP先验（利用内部结构和模式）并采用由粗到细的方式，基于DIP的3DGS能够在标准3DGS失效的场景下（如稀疏视图恢复）发挥作用。需要注意的是，我们的方法不依赖任何预训练模型（如生成模型或深度估计），而仅依赖输入帧。在同类方法中，DIP-GS 在多项稀疏视图重建任务上取得了最新的先进水平（SOTA）竞争性结果，展现了其能力。
