### Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss

Novel view synthesis is a fundamental task in 3D computer vision that aims to reconstruct realistic images from a set of posed input views. However, reconstruction quality degrades significantly under sparse-view conditions due to limited geometric cues. Existing methods, such as Neural Radiance Fields (NeRF) and the more recent 3D Gaussian Splatting (3DGS), often suffer from blurred details and structural artifacts when trained with insufficient views. Recent works have identified the quality of rendered depth as a key factor in mitigating these artifacts, as it directly affects geometric accuracy and view consistency. In this paper, we address these challenges by introducing Hierarchical Depth-Guided Splatting (HDGS), a depth supervision framework that progressively refines geometry from coarse to fine levels. Central to HDGS is a novel Cascade Pearson Correlation Loss (CPCL), which aligns rendered and estimated monocular depths across multiple spatial scales. By enforcing multi-scale depth consistency, our method substantially improves structural fidelity in sparse-view scenarios. Extensive experiments on the LLFF and DTU benchmarks demonstrate that HDGS achieves state-of-the-art performance under sparse-view settings while maintaining efficient and high-quality rendering

新视角合成是三维计算机视觉中的一项基础任务，旨在根据一组带位姿的输入视图重建逼真的图像。然而，在稀疏视角条件下，由于几何线索有限，重建质量会显著下降。现有方法，如神经辐射场（Neural Radiance Fields, NeRF）以及近期提出的三维高斯投影（3D Gaussian Splatting, 3DGS），在训练视角不足的情况下，往往会出现细节模糊与结构伪影等问题。已有研究指出，渲染深度图的质量是缓解这些问题的关键因素，因为其直接影响几何精度与视角一致性。
本文针对上述挑战，提出了一种分层深度引导的投影框架——Hierarchical Depth-Guided Splatting（HDGS），通过逐级细化几何结构，从粗到细进行深度监督。HDGS 的核心是我们设计的 级联皮尔逊相关损失（Cascade Pearson Correlation Loss, CPCL），该损失函数在多个空间尺度上对渲染深度与估计的单目深度进行对齐。通过强制实施多尺度深度一致性，我们的方法在稀疏视角场景中显著提升了结构保真度。
在 LLFF 和 DTU 基准测试上的大量实验表明，HDGS 在稀疏视角条件下实现了当前最优的重建性能，同时兼具高效性与高质量渲染效果。
