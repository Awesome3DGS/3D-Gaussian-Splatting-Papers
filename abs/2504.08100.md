### ContrastiveGaussian: High-Fidelity 3D Generation with Contrastive Learning and Gaussian Splatting

Creating 3D content from single-view images is a challenging problem that has attracted considerable attention in recent years. Current approaches typically utilize score distillation sampling (SDS) from pre-trained 2D diffusion models to generate multi-view 3D representations. Although some methods have made notable progress by balancing generation speed and model quality, their performance is often limited by the visual inconsistencies of the diffusion model outputs. In this work, we propose ContrastiveGaussian, which integrates contrastive learning into the generative process. By using a perceptual loss, we effectively differentiate between positive and negative samples, leveraging the visual inconsistencies to improve 3D generation quality. To further enhance sample differentiation and improve contrastive learning, we incorporate a super-resolution model and introduce another Quantity-Aware Triplet Loss to address varying sample distributions during training. Our experiments demonstrate that our approach achieves superior texture fidelity and improved geometric consistency.

从单视图图像生成三维内容是一项具有挑战性的任务，近年来受到了广泛关注。当前的方法通常依赖于来自预训练二维扩散模型的评分蒸馏采样（Score Distillation Sampling, SDS），以生成多视角的三维表示。尽管部分方法在生成速度与模型质量之间取得了一定的平衡，但其性能仍常受限于扩散模型输出的视觉不一致性。
在本研究中，我们提出了 ContrastiveGaussian，将**对比学习（contrastive learning）**引入三维生成过程。通过引入感知损失（perceptual loss），我们能够有效区分正负样本，利用视觉不一致性反向促进三维生成质量的提升。
为进一步增强样本区分能力并提升对比学习效果，我们引入了一个超分辨率模型，并提出一种新的 数量感知三元组损失（Quantity-Aware Triplet Loss），用于应对训练过程中样本分布的差异。
实验结果表明，我们的方法在纹理保真度和几何一致性方面均优于现有方法。
