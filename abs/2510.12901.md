### SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms

Rigorous testing of autonomous robots, such as self-driving vehicles, is essential to ensure their safety in real-world deployments. This requires building high-fidelity simulators to test scenarios beyond those that can be safely or exhaustively collected in the real-world. Existing neural rendering methods based on NeRF and 3DGS hold promise but suffer from low rendering speeds or can only render pinhole camera models, hindering their suitability to applications that commonly require high-distortion lenses and LiDAR data. Multi-sensor simulation poses additional challenges as existing methods handle cross-sensor inconsistencies by favoring the quality of one modality at the expense of others. To overcome these limitations, we propose SimULi, the first method capable of rendering arbitrary camera models and LiDAR data in real-time. Our method extends 3DGUT, which natively supports complex camera models, with LiDAR support, via an automated tiling strategy for arbitrary spinning LiDAR models and ray-based culling. To address cross-sensor inconsistencies, we design a factorized 3D Gaussian representation and anchoring strategy that reduces mean camera and depth error by up to 40% compared to existing methods. SimULi renders 10-20x faster than ray tracing approaches and 1.5-10x faster than prior rasterization-based work (and handles a wider range of camera models). When evaluated on two widely benchmarked autonomous driving datasets, SimULi matches or exceeds the fidelity of existing state-of-the-art methods across numerous camera and LiDAR metrics.

对自动驾驶汽车等自主机器人进行严格测试对于其在真实环境中的安全部署至关重要。这要求构建高保真模拟器，以测试那些在现实中难以安全或全面采集的场景。现有基于NeRF和3DGS的神经渲染方法虽具有潜力，但存在渲染速度慢或仅支持针孔相机模型的问题，限制了它们在需要高畸变镜头和LiDAR数据的常见应用场景中的适用性。多传感器模拟还面临额外挑战，目前的方法往往通过牺牲某一模态的质量来应对跨传感器不一致问题。为克服这些限制，我们提出了SimULi，这是首个能够实时渲染任意相机模型和LiDAR数据的方法。该方法在支持复杂相机模型的3DGUT基础上扩展了对LiDAR的支持，采用自动平铺策略来适配任意旋转LiDAR模型，并结合基于射线的剔除机制。为缓解跨传感器不一致问题，我们设计了一种分解式三维高斯表示及锚定策略，与现有方法相比可将平均相机误差与深度误差降低最多达40%。SimULi在渲染速度方面比光线追踪方法快10至20倍，比现有基于光栅化的方法快1.5至10倍，同时支持更广泛的相机模型。在两个广泛使用的自动驾驶数据集上进行评估时，SimULi在多个相机和LiDAR指标上均达到了或超过了现有最先进方法的保真度表现。
