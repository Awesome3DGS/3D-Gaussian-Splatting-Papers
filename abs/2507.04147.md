### A3FR: Agile 3D Gaussian Splatting with Incremental Gaze Tracked Foveated Rendering in Virtual Reality

Virtual reality (VR) significantly transforms immersive digital interfaces, greatly enhancing education, professional practices, and entertainment by increasing user engagement and opening up new possibilities in various industries. Among its numerous applications, image rendering is crucial. Nevertheless, rendering methodologies like 3D Gaussian Splatting impose high computational demands, driven predominantly by user expectations for superior visual quality. This results in notable processing delays for real-time image rendering, which greatly affects the user experience. Additionally, VR devices such as head-mounted displays (HMDs) are intricately linked to human visual behavior, leveraging knowledge from perception and cognition to improve user experience. These insights have spurred the development of foveated rendering, a technique that dynamically adjusts rendering resolution based on the user's gaze direction. The resultant solution, known as gaze-tracked foveated rendering, significantly reduces the computational burden of the rendering process. Although gaze-tracked foveated rendering can reduce rendering costs, the computational overhead of the gaze tracking process itself can sometimes outweigh the rendering savings, leading to increased processing latency. To address this issue, we propose an efficient rendering framework called A3FR, designed to minimize the latency of gaze-tracked foveated rendering via the parallelization of gaze tracking and foveated rendering processes. For the rendering algorithm, we utilize 3D Gaussian Splatting, a state-of-the-art neural rendering technique. Evaluation results demonstrate that A3FR can reduce end-to-end rendering latency by up to 2× while maintaining visual quality.

虚拟现实（VR）正在深刻改变沉浸式数字交互界面，通过提升用户参与度并为各行业开辟新可能，极大地推动了教育、专业实践和娱乐的发展。在众多应用中，图像渲染尤为关键。然而，诸如三维高斯投影（3D Gaussian Splatting）等渲染方法在满足用户对高视觉质量期望的驱动下，计算需求极高，导致实时图像渲染出现显著延迟，从而严重影响用户体验。此外，诸如头戴式显示器（HMD）等 VR 设备与人类视觉行为密切相关，借助感知与认知科学的知识来改善用户体验。这些洞察推动了注视点渲染（foveated rendering）的发展，该技术根据用户的注视方向动态调整渲染分辨率。其衍生方案——基于注视跟踪的注视点渲染（gaze-tracked foveated rendering）——显著降低了渲染过程的计算负担。
尽管基于注视跟踪的注视点渲染能够降低渲染成本，但注视跟踪过程本身的计算开销有时可能超过渲染节省的资源，从而导致处理延迟增加。为解决这一问题，我们提出了一种高效渲染框架——A3FR，通过注视跟踪与注视点渲染过程的并行化来最大限度减少基于注视跟踪的注视点渲染延迟。在渲染算法上，我们采用了最先进的神经渲染技术——三维高斯投影。评估结果表明，A3FR 在保持视觉质量的同时，能够将端到端渲染延迟降低最高达 2 倍。
