### Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with Anchor Gaussian Guided Texture Warping

By equipping the most recent 3D Gaussian Splatting representation with head 3D morphable models (3DMM), existing methods manage to create head avatars with high fidelity. However, most existing methods only reconstruct a head without the body, substantially limiting their application scenarios. We found that naively applying Gaussians to model the clothed chest and shoulders tends to result in blurry reconstruction and noisy floaters under novel poses. This is because of the fundamental limitation of Gaussians and point clouds -- each Gaussian or point can only have a single directional radiance without spatial variance, therefore an unnecessarily large number of them is required to represent complicated spatially varying texture, even for simple geometry. In contrast, we propose to model the body part with a neural texture that consists of coarse and pose-dependent fine colors. To properly render the body texture for each view and pose without accurate geometry nor UV mapping, we optimize another sparse set of Gaussians as anchors that constrain the neural warping field that maps image plane coordinates to the texture space. We demonstrate that Gaussian Head & Shoulders can fit the high-frequency details on the clothed upper body with high fidelity and potentially improve the accuracy and fidelity of the head region. We evaluate our method with casual phone-captured and internet videos and show our method archives superior reconstruction quality and robustness in both self and cross reenactment tasks. To fully utilize the efficient rendering speed of Gaussian splatting, we additionally propose an accelerated inference method of our trained model without Multi-Layer Perceptron (MLP) queries and reach a stable rendering speed of around 130 FPS for any subjects.

通过将最新的3D高斯喷溅表示与头部3D可变形模型（3DMM）相结合，现有方法成功地创建了高保真的头像。然而，大多数现有方法只重建了头部而非身体，这在很大程度上限制了它们的应用场景。我们发现，直接应用高斯模型来模拟穿着衣服的胸部和肩膀往往会导致模糊的重建和在新姿势下出现噪声浮点。这是因为高斯和点云的根本限制——每个高斯或点只能有单一方向的辐射而没有空间变异，因此需要大量的点来表示即使是简单几何形状的复杂空间变化纹理。与此相反，我们提出用由粗糙和依赖姿势的细致颜色组成的神经纹理来模拟身体部分。为了在没有精确几何结构或UV映射的情况下正确渲染每个视角和姿势的身体纹理，我们优化了另一组稀疏的高斯锚点，这些锚点限制了将图像平面坐标映射到纹理空间的神经变形场。我们证明了高斯头部与肩膀能够以高保真度适配穿衣上半身的高频细节，并有可能提高头部区域的准确性和保真度。我们使用随意拍摄的手机视频和互联网视频评估我们的方法，并展示了我们的方法在自我和交叉再现任务中具有卓越的重建质量和鲁棒性。为了充分利用3D高斯喷溅的高效渲染速度，我们还提出了一种加速推理方法，无需多层感知器（MLP）查询，就能达到大约130 FPS的稳定渲染速度。
