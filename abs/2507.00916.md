### Masks make discriminative models great again!

We present Image2GS, a novel approach that addresses the challenging problem of reconstructing photorealistic 3D scenes from a single image by focusing specifically on the image-to-3D lifting component of the reconstruction process. By decoupling the lifting problem (converting an image to a 3D model representing what is visible) from the completion problem (hallucinating content not present in the input), we create a more deterministic task suitable for discriminative models. Our method employs visibility masks derived from optimized 3D Gaussian splats to exclude areas not visible from the source view during training. This masked training strategy significantly improves reconstruction quality in visible regions compared to strong baselines. Notably, despite being trained only on masked regions, Image2GS remains competitive with state-of-the-art discriminative models trained on full target images when evaluated on complete scenes. Our findings highlight the fundamental struggle discriminative models face when fitting unseen regions and demonstrate the advantages of addressing image-to-3D lifting as a distinct problem with specialized techniques.

我们提出了 Image2GS，这是一种新方法，针对从单张图像重建照片级逼真三维场景这一具有挑战性的问题，专注于重建过程中的图像到三维提升（image-to-3D lifting）环节。通过将提升问题（将图像转换为表示可见部分的三维模型）与补全问题（臆造输入中不存在的内容）解耦，我们将任务转化为更具确定性、适合判别式模型处理的问题。我们的方法利用从优化后的三维高斯投影中获得的可见性掩码，在训练过程中排除源视角中不可见的区域。这种掩码训练策略相比强基线方法，在可见区域显著提升了重建质量。值得注意的是，即使仅在掩码区域上训练，Image2GS 在完整场景评估中依然能与在完整目标图像上训练的最先进判别式模型保持竞争力。我们的研究结果突出了判别式模型在拟合不可见区域时的根本困境，并展示了将图像到三维提升作为一个独立问题并采用专门技术处理的优势。
