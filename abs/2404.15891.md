### OMEGAS: Object Mesh Extraction from Large Scenes Guided by Gaussian Segmentation

Recent advancements in 3D reconstruction technologies have paved the way for high-quality and real-time rendering of complex 3D scenes. Despite these achievements, a notable challenge persists: it is difficult to precisely reconstruct specific objects from large scenes. Current scene reconstruction techniques frequently result in the loss of object detail textures and are unable to reconstruct object portions that are occluded or unseen in views. To address this challenge, we delve into the meticulous 3D reconstruction of specific objects within large scenes and propose a framework termed OMEGAS: Object Mesh Extraction from Large Scenes Guided by GAussian Segmentation. OMEGAS employs a multi-step approach, grounded in several excellent off-the-shelf methodologies. Specifically, initially, we utilize the Segment Anything Model (SAM) to guide the segmentation of 3D Gaussian Splatting (3DGS), thereby creating a basic 3DGS model of the target object. Then, we leverage large-scale diffusion priors to further refine the details of the 3DGS model, especially aimed at addressing invisible or occluded object portions from the original scene views. Subsequently, by re-rendering the 3DGS model onto the scene views, we achieve accurate object segmentation and effectively remove the background. Finally, these target-only images are used to improve the 3DGS model further and extract the definitive 3D object mesh by the SuGaR model. In various scenarios, our experiments demonstrate that OMEGAS significantly surpasses existing scene reconstruction methods.

近期在3D重建技术上的进展已经为复杂3D场景的高质量和实时渲染铺平了道路。尽管取得了这些成就，仍存在一个显著的挑战：难以从大型场景中精确重建特定对象。当前的场景重建技术常常导致对象细节纹理的丢失，并且无法重建在视图中被遮挡或未见到的对象部分。为了应对这一挑战，我们深入研究大型场景中特定对象的细致3D重建，并提出了一个名为OMEGAS的框架：由高斯分割引导的大场景中的对象网格提取（Object Mesh Extraction from Large Scenes Guided by GAussian Segmentation）。OMEGAS采用多步骤方法，基于几种优秀的现成技术。具体来说，首先，我们利用Segment Anything Model（SAM）来指导3D高斯溅射（3DGS）的分割，从而创建目标对象的基本3DGS模型。然后，我们利用大规模扩散先验来进一步细化3DGS模型的细节，特别是针对原始场景视图中不可见或被遮挡的对象部分。随后，通过将3DGS模型重新渲染到场景视图上，我们实现了准确的对象分割，并有效地移除了背景。最后，这些仅含目标的图像被用来进一步改进3DGS模型，并通过SuGaR模型提取最终的3D对象网格。在各种场景下，我们的实验表明，OMEGAS显著超越了现有的场景重建方法。
