### Generating Synthetic Stereo Datasets using 3D Gaussian Splatting and Expert Knowledge Transfer

In this paper, we introduce a 3D Gaussian Splatting (3DGS)-based pipeline for stereo dataset generation, offering an efficient alternative to Neural Radiance Fields (NeRF)-based methods. To obtain useful geometry estimates, we explore utilizing the reconstructed geometry from the explicit 3D representations as well as depth estimates from the FoundationStereo model in an expert knowledge transfer setup. We find that when fine-tuning stereo models on 3DGS-generated datasets, we demonstrate competitive performance in zero-shot generalization benchmarks. When using the reconstructed geometry directly, we observe that it is often noisy and contains artifacts, which propagate noise to the trained model. In contrast, we find that the disparity estimates from FoundationStereo are cleaner and consequently result in a better performance on the zero-shot generalization benchmarks. Our method highlights the potential for low-cost, high-fidelity dataset creation and fast fine-tuning for deep stereo models. Moreover, we also reveal that while the latest Gaussian Splatting based methods have achieved superior performance on established benchmarks, their robustness falls short in challenging in-the-wild settings warranting further exploration.

在本文中，我们提出了一种基于三维高斯泼洒（3D Gaussian Splatting，3DGS）的立体视觉数据集生成流程，为传统基于神经辐射场（Neural Radiance Fields，NeRF）的方法提供了一种高效替代方案。为了获取有用的几何估计，我们探索了两种方式：一是利用显式三维表示所重建的几何结构，二是采用 FoundationStereo 模型的深度估计结果，在专家知识迁移设置下进行利用。
我们的研究发现，当在 3DGS 生成的数据集上对立体视觉模型进行微调时，在零样本泛化基准测试中能够取得具有竞争力的性能。直接使用重建几何时，我们观察到其通常较为嘈杂，并带有伪影，这些噪声会进一步传递到训练出的模型中。相比之下，FoundationStereo 的视差估计更加干净，从而带来了更优异的零样本泛化表现。
本方法展示了构建低成本、高保真数据集以及快速微调深度立体视觉模型的潜力。此外，我们还指出，尽管最新的高斯泼洒方法在标准基准上取得了优越性能，但其在具有挑战性的真实场景中仍存在稳健性不足的问题，亟需进一步探索。
