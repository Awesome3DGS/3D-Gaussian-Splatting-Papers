### GIGA: Generalizable Sparse Image-driven Gaussian Avatars

Driving a high-quality and photorealistic full-body human avatar, from only a few RGB cameras, is a challenging problem that has become increasingly relevant with emerging virtual reality technologies. To democratize such technology, a promising solution may be a generalizable method that takes sparse multi-view images of an unseen person and then generates photoreal free-view renderings of such identity. However, the current state of the art is not scalable to very large datasets and, thus, lacks in diversity and photorealism. To address this problem, we propose a novel, generalizable full-body model for rendering photoreal humans in free viewpoint, as driven by sparse multi-view video. For the first time in literature, our model can scale up training to thousands of subjects while maintaining high photorealism. At the core, we introduce a MultiHeadUNet architecture, which takes sparse multi-view images in texture space as input and predicts Gaussian primitives represented as 2D texels on top of a human body mesh. Importantly, we represent sparse-view image information, body shape, and the Gaussian parameters in 2D so that we can design a deep and scalable architecture entirely based on 2D convolutions and attention mechanisms. At test time, our method synthesizes an articulated 3D Gaussian-based avatar from as few as four input views and a tracked body template for unseen identities. Our method excels over prior works by a significant margin in terms of cross-subject generalization capability as well as photorealism.

仅使用少量 RGB 相机驱动一个高质量、逼真的全身虚拟人头像，是一个极具挑战性的任务，随着虚拟现实技术的发展，其研究与应用价值愈发凸显。为了实现该技术的大众化应用，一个有前景的解决方案是：设计一种具备泛化能力的方法，能够从稀疏多视角图像中重建未见过的个体，并生成真实感强、可自由视角渲染的人体数字化形象。
然而，当前的最新方法难以扩展至大规模数据集，因此在多样性与真实感方面仍存在不足。为解决这一问题，我们提出了一种新颖的、可泛化的全身模型，能够从稀疏多视角视频中驱动逼真的自由视角人体渲染。该方法首次在文献中实现了对数千个不同主体的训练扩展能力，同时保持极高的真实感。
我们方法的核心是提出了 MultiHeadUNet 架构，该架构以纹理空间中的稀疏多视角图像为输入，预测基于人体网格的 二维 texel 表示的高斯基元（Gaussian primitives）。关键在于，我们将稀疏图像信息、人体形状与高斯参数均表示在二维空间中，从而能够构建一个完全基于二维卷积与注意力机制的深度且可扩展的网络结构。
在测试阶段，该方法能够从仅四个输入视角图像和一个已跟踪的身体模板出发，生成带有运动姿态的 基于三维高斯表示的虚拟人头像，适用于未见身份个体。
在跨主体泛化能力与图像真实感方面，我们的方法相较现有工作均有显著提升。
