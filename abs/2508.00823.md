### IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation

Visual navigation with an image as goal is a fundamental and challenging problem. Conventional methods either rely on end-to-end RL learning or modular-based policy with topological graph or BEV map as memory, which cannot fully model the geometric relationship between the explored 3D environment and the goal image. In order to efficiently and accurately localize the goal image in 3D space, we build our navigation system upon the renderable 3D gaussian (3DGS) representation. However, due to the computational intensity of 3DGS optimization and the large search space of 6-DoF camera pose, directly leveraging 3DGS for image localization during agent exploration process is prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D Gaussian Localization framework for efficient and 3D-aware image-goal navigation. Specifically, we incrementally update the scene representation as new images arrive with feed-forward monocular prediction. Then we coarsely localize the goal by leveraging the geometric information for discrete space matching, which can be equivalent to efficient 3D convolution. When the agent is close to the goal, we finally solve the fine target pose with optimization via differentiable rendering. The proposed IGL-Nav outperforms existing state-of-the-art methods by a large margin across diverse experimental configurations. It can also handle the more challenging free-view image-goal setting and be deployed on real-world robotic platform using a cellphone to capture goal image at arbitrary pose.

以图像作为目标的视觉导航是一个基础且具有挑战性的问题。传统方法要么依赖端到端的强化学习，要么采用基于模块化的策略，将拓扑图或鸟瞰图（BEV）作为记忆，但这些方法无法充分建模已探索的三维环境与目标图像之间的几何关系。为了在三维空间中高效且准确地定位目标图像，我们将导航系统建立在可渲染的三维高斯（3DGS）表示之上。然而，由于 3DGS 优化的计算开销大以及 6 自由度相机位姿的搜索空间庞大，在智能体探索过程中直接利用 3DGS 进行图像定位效率极低。为此，我们提出了 IGL-Nav，这是一种用于高效且具备三维感知能力的图像目标导航的增量式三维高斯定位框架。具体而言，我们在新图像到来时，利用前向单目预测增量更新场景表示；然后利用几何信息进行离散空间匹配以粗略定位目标，这相当于高效的三维卷积；当智能体接近目标时，我们通过可微渲染优化求解精确的目标位姿。所提出的 IGL-Nav 在多种实验配置下均显著超越现有的最新方法，同时还能处理更具挑战性的自由视角图像目标设定，并可部署在真实的机器人平台上，仅需使用手机在任意姿态下拍摄目标图像即可。
