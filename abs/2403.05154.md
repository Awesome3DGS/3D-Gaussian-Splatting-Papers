### GSEdit: Efficient Text-Guided Editing of 3D Objects via Gaussian Splatting

We present GSEdit, a pipeline for text-guided 3D object editing based on Gaussian Splatting models. Our method enables the editing of the style and appearance of 3D objects without altering their main details, all in a matter of minutes on consumer hardware. We tackle the problem by leveraging Gaussian splatting to represent 3D scenes, and we optimize the model while progressively varying the image supervision by means of a pretrained image-based diffusion model. The input object may be given as a 3D triangular mesh, or directly provided as Gaussians from a generative model such as DreamGaussian. GSEdit ensures consistency across different viewpoints, maintaining the integrity of the original object's information. Compared to previously proposed methods relying on NeRF-like MLP models, GSEdit stands out for its efficiency, making 3D editing tasks much faster. Our editing process is refined via the application of the SDS loss, ensuring that our edits are both precise and accurate. Our comprehensive evaluation demonstrates that GSEdit effectively alters object shape and appearance following the given textual instructions while preserving their coherence and detail.

我们介绍了GSEdit，一种基于高斯Splatting模型的文本引导3D对象编辑流程。我们的方法能够在几分钟内，在消费级硬件上编辑3D对象的风格和外观，而不改变它们的主要细节。我们通过利用高斯Splatting来表示3D场景，并通过预训练的基于图像的扩散模型逐渐变化图像监督来优化模型，来解决这个问题。输入对象可以作为3D三角形网格给出，或者直接作为来自如DreamGaussian这样的生成模型的高斯提供。GSEdit确保了不同视点之间的一致性，保持了原始对象信息的完整性。与之前依赖于类NeRF的MLP模型的方法相比，GSEdit以其效率脱颖而出，使3D编辑任务更快完成。我们的编辑过程通过应用SDS损失来细化，确保我们的编辑既精确又准确。我们的全面评估表明，GSEdit有效地根据给定的文本指令改变对象的形状和外观，同时保持它们的连贯性和细节。
