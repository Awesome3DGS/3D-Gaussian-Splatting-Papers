### GEN3D: Generating Domain-Free 3D Scenes from a Single Image

Despite recent advancements in neural 3D reconstruction, the dependence on dense multi-view captures restricts their broader applicability. Additionally, 3D scene generation is vital for advancing embodied AI and world models, which depend on diverse, high-quality scenes for learning and evaluation. In this work, we propose Gen3d, a novel method for generation of high-quality, wide-scope, and generic 3D scenes from a single image. After the initial point cloud is created by lifting the RGBD image, Gen3d maintains and expands its world model. The 3D scene is finalized through optimizing a Gaussian splatting representation. Extensive experiments on diverse datasets demonstrate the strong generalization capability and superior performance of our method in generating a world model and Synthesizing high-fidelity and consistent novel views.

尽管神经三维重建技术取得了显著进展，但其对密集多视图采集的依赖性限制了在更广泛场景中的应用潜力。同时，三维场景生成对于推动具身智能（Embodied AI）与世界模型的发展至关重要，这些系统依赖多样且高质量的场景进行学习与评估。为此，本文提出 Gen3d，一种可从单张图像生成高质量、广覆盖、通用型三维场景的新方法。在通过提升 RGBD 图像生成初始点云后，Gen3d 持续维护并扩展其世界模型，最终通过优化三维高斯投影（Gaussian Splatting）表示来完成三维场景构建。在多个多样化数据集上的实验结果表明，Gen3d 在构建世界模型和合成高保真、一致性强的新视角图像方面表现出色，具有良好的泛化能力。
