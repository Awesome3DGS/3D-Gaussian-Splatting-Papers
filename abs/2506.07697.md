### OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting

3D Gaussian Splatting (3DGS) has emerged as a powerful representation for neural scene reconstruction, offering high-quality novel view synthesis while maintaining computational efficiency. In this paper, we extend the capabilities of 3DGS beyond pure scene representation by introducing an approach for open-vocabulary 3D instance segmentation without requiring manual labeling, termed OpenSplat3D. Our method leverages feature-splatting techniques to associate semantic information with individual Gaussians, enabling fine-grained scene understanding. We incorporate Segment Anything Model instance masks with a contrastive loss formulation as guidance for the instance features to achieve accurate instance-level segmentation. Furthermore, we utilize language embeddings of a vision-language model, allowing for flexible, text-driven instance identification. This combination enables our system to identify and segment arbitrary objects in 3D scenes based on natural language descriptions. We show results on LERF-mask and LERF-OVS as well as the full ScanNet++ validation set, demonstrating the effectiveness of our approach.

三维高斯泼洒（3D Gaussian Splatting，3DGS）近年来作为一种强大的神经场景重建表示方式，因其在保持计算效率的同时实现高质量新颖视角合成而备受关注。本文在传统3DGS仅用于场景表示的基础上进一步拓展其能力，提出了一种无需人工标注的开放词汇三维实例分割方法，称为 OpenSplat3D。
我们的方法利用特征泼洒（feature-splatting）技术将语义信息关联到每一个高斯基元，从而实现对场景的细粒度理解。具体地，我们引入 Segment Anything Model（SAM） 的实例掩码，并结合对比损失（contrastive loss）来引导实例特征学习，从而获得准确的实例级分割。此外，我们还引入了视觉语言模型的语言嵌入，使得系统能够通过自然语言灵活地识别和分割三维场景中的任意对象。
这一方法实现了基于文本描述的任意对象在三维空间中的识别与分割。我们在 LERF-mask、LERF-OVS 以及完整的 ScanNet++ 验证集上进行了实验，结果表明我们的方法在开放词汇三维实例分割任务中表现出色，验证了其有效性。
