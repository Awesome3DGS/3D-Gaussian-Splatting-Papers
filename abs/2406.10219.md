### PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting

Recent advancements in novel view synthesis have enabled real-time rendering speeds and high reconstruction accuracy. 3D Gaussian Splatting (3D-GS), a foundational point-based parametric 3D scene representation, models scenes as large sets of 3D Gaussians. Complex scenes can comprise of millions of Gaussians, amounting to large storage and memory requirements that limit the viability of 3D-GS on devices with limited resources. Current techniques for compressing these pretrained models by pruning Gaussians rely on combining heuristics to determine which ones to remove. In this paper, we propose a principled spatial sensitivity pruning score that outperforms these approaches. It is computed as a second-order approximation of the reconstruction error on the training views with respect to the spatial parameters of each Gaussian. Additionally, we propose a multi-round prune-refine pipeline that can be applied to any pretrained 3D-GS model without changing the training pipeline. After pruning 88.44% of the Gaussians, we observe that our PUP 3D-GS pipeline increases the average rendering speed of 3D-GS by 2.65× while retaining more salient foreground information and achieving higher image quality metrics than previous pruning techniques on scenes from the Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets.

近期在新视图合成领域的进展已经实现了实时渲染速度和高重建精度。三维高斯平涂（3D-GS）是一种基础的基于点的参数化三维场景表示方法，通过大量的三维高斯模型来表示场景。复杂场景可能包括数百万个高斯，这导致大量的存储和内存需求，限制了3D-GS在资源有限的设备上的可行性。目前压缩这些预训练模型的技术通过剪枝高斯，并依赖组合启发式方法来确定去除哪些高斯。在本文中，我们提出了一种基于原理的空间敏感性剪枝得分，其表现超过了这些方法。该得分作为对训练视图中每个高斯的空间参数的重建误差的二阶近似来计算。此外，我们提出了一个可应用于任何预训练3D-GS模型的多轮剪枝-精化流水线，而无需改变训练流程。在剪枝了88.44%的高斯之后，我们观察到我们的PUP 3D-GS流水线将3D-GS的平均渲染速度提高了2.65倍，同时保留了更多显著的前景信息，并在Mip-NeRF 360、坦克与庙宇以及深度混合数据集的场景中，比以前的剪枝技术实现了更高的图像质量指标。
