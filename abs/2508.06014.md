### ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors

Recent advances in novel view synthesis (NVS) have enabled real-time rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle with artifacts and missing regions when rendering from viewpoints that deviate from the training trajectory, limiting seamless scene exploration. To address this, we propose a 3DGS-based pipeline that generates additional training views to enhance reconstruction. We introduce an information-gain-driven virtual camera placement strategy to maximize scene coverage, followed by video diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with these enhanced views significantly improves reconstruction quality. To evaluate our method, we present Wild-Explore, a benchmark designed for challenging scene exploration. Experiments demonstrate that our approach outperforms existing 3DGS-based methods, enabling high-quality, artifact-free rendering from arbitrary viewpoints.

新视图合成（Novel View Synthesis, NVS）的最新进展使得基于三维高斯溅射（3D Gaussian Splatting, 3DGS）的实时渲染成为可能。然而，当从偏离训练轨迹的视点进行渲染时，现有方法容易出现伪影和区域缺失的问题，从而限制了无缝的场景探索。为此，我们提出了一种基于 3DGS 的管线，通过生成额外的训练视图来增强重建效果。我们引入了一种基于信息增益的虚拟相机布置策略，以最大化场景覆盖率，并结合视频扩散先验来优化渲染结果。利用这些增强视图对三维高斯进行微调，可以显著提升重建质量。为评估我们的方法，我们提出了 Wild-Explore 基准，用于应对具有挑战性的场景探索任务。实验结果表明，我们的方法优于现有的基于 3DGS 的方法，实现了任意视点下的高质量、无伪影渲染。
