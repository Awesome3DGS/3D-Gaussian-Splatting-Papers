### PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing

We present PercHead, a method for single-image 3D head reconstruction and semantic 3D editing - two tasks that are inherently challenging due to severe view occlusions, weak perceptual supervision, and the ambiguity of editing in 3D space. We develop a unified base model for reconstructing view-consistent 3D heads from a single input image. The model employs a dual-branch encoder followed by a ViT-based decoder that lifts 2D features into 3D space through iterative cross-attention. Rendering is performed using Gaussian Splatting. At the heart of our approach is a novel perceptual supervision strategy based on DINOv2 and SAM2.1, which provides rich, generalized signals for both geometric and appearance fidelity. Our model achieves state-of-the-art performance in novel-view synthesis and, furthermore, exhibits exceptional robustness to extreme viewing angles compared to established baselines. Furthermore, this base model can be seamlessly extended for semantic 3D editing by swapping the encoder and finetuning the network. In this variant, we disentangle geometry and style through two distinct input modalities: a segmentation map to control geometry and either a text prompt or a reference image to specify appearance. We highlight the intuitive and powerful 3D editing capabilities of our model through a lightweight, interactive GUI, where users can effortlessly sculpt geometry by drawing segmentation maps and stylize appearance via natural language or image prompts.

我们提出了 PercHead，这是一种用于单张图像的三维人头重建与语义三维编辑的方法。这两个任务本质上都极具挑战性，原因包括视角遮挡严重、感知监督信号薄弱，以及三维空间中编辑的模糊性。我们构建了一个统一的基础模型，能够从一张输入图像中重建视角一致的三维人头。该模型采用双分支编码器，接着是一个基于ViT的解码器，利用迭代交叉注意力将二维特征提升至三维空间。渲染则通过高斯投影（Gaussian Splatting）完成。我们方法的核心是一种基于 DINOv2 和 SAM2.1 的新型感知监督策略，能够为几何结构和外观保真提供丰富且通用的信号。我们的模型在新视角合成方面达到了当前最先进的性能，并在极端视角下表现出优于现有基线的强鲁棒性。此外，该基础模型可无缝扩展至语义三维编辑任务，只需替换编码器并微调网络。在这一变体中，我们通过两种不同的输入模态实现几何与风格的解耦：使用分割图控制几何结构，使用文本提示或参考图像指定外观风格。我们通过一个轻量级、交互式的图形界面展示了该模型直观而强大的三维编辑能力，用户可以通过绘制分割图轻松塑造几何结构，并通过自然语言或图像提示进行风格化外观编辑。
