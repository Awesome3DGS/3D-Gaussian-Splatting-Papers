### GraphGSOcc: Semantic-Geometric Graph Transformer with Dynamic-Static Decoupling for 3D Gaussian Splatting-based Occupancy Prediction

Addressing the task of 3D semantic occupancy prediction for autonomous driving, we tackle two key issues in existing 3D Gaussian Splatting (3DGS) methods: (1) unified feature aggregation neglecting semantic correlations among similar categories and across regions, (2) boundary ambiguities caused by the lack of geometric constraints in MLP iterative optimization and (3) biased issues in dynamic-static object coupling optimization. We propose the GraphGSOcc model, a novel framework that combines semantic and geometric graph Transformer and decouples dynamic-static objects optimization for 3D Gaussian Splatting-based Occupancy Prediction. We propose the Dual Gaussians Graph Attenntion, which dynamically constructs dual graph structures: a geometric graph adaptively calculating KNN search radii based on Gaussian poses, enabling large-scale Gaussians to aggregate features from broader neighborhoods while compact Gaussians focus on local geometric consistency; a semantic graph retaining top-M highly correlated nodes via cosine similarity to explicitly encode semantic relationships within and across instances. Coupled with the Multi-scale Graph Attention framework, fine-grained attention at lower layers optimizes boundary details, while coarsegrained attention at higher layers models object-level topology. On the other hand, we decouple dynamic and static objects by leveraging semantic probability distributions and design a Dynamic-Static Decoupled Gaussian Attention mechanism to optimize the prediction performance for both dynamic objects and static scenes. GraphGSOcc achieves state-ofthe-art performance on the SurroundOcc-nuScenes, Occ3D-nuScenes, OpenOcc and KITTI occupancy benchmarks. Experiments on the SurroundOcc dataset achieve an mIoU of 25.20%, reducing GPU memory to 6.8 GB, demonstrating a 1.97% mIoU improvement and 13.7% memory reduction compared to GaussianWorld.

针对自动驾驶中的三维语义占用预测任务，我们着重解决现有三维高斯溅射（3DGS）方法的三个关键问题：(1) 统一特征聚合忽略了相似类别及跨区域之间的语义相关性；(2) 由于 MLP 迭代优化缺乏几何约束而导致的边界模糊问题；(3) 动态-静态物体耦合优化带来的偏差问题。为此，我们提出 **GraphGSOcc** 模型，这是一种结合语义与几何图 Transformer 并实现动态-静态物体优化解耦的三维高斯溅射占用预测新框架。我们提出 **双高斯图注意力机制（Dual Gaussians Graph Attention）**，该机制动态构建双图结构：几何图基于高斯位置自适应计算 KNN 搜索半径，使大尺度高斯能够从更广邻域聚合特征，而紧凑型高斯则专注于局部几何一致性；语义图则通过余弦相似度保留相关性最高的 Top-M 节点，从而显式编码实例内及跨实例的语义关系。结合 **多尺度图注意力框架（Multi-scale Graph Attention）**，在低层通过细粒度注意力优化边界细节，高层通过粗粒度注意力建模目标级拓扑结构。另一方面，我们利用语义概率分布对动态与静态物体进行解耦，并设计了 **动态-静态解耦高斯注意力机制（Dynamic-Static Decoupled Gaussian Attention）**，以同时提升动态目标与静态场景的预测性能。**GraphGSOcc** 在 SurroundOcc-nuScenes、Occ3D-nuScenes、OpenOcc 和 KITTI 占用预测基准上均取得了当前最优性能。在 SurroundOcc 数据集上的实验表明，mIoU 达到 **25.20%**，显存占用降低至 **6.8 GB**，相比 GaussianWorld 提升了 **1.97%** mIoU，并减少了 **13.7%** 的显存消耗。
