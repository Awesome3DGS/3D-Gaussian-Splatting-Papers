### GRaD-Nav: Efficiently Learning Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics

Autonomous visual navigation is an essential element in robot autonomy. Reinforcement learning (RL) offers a promising policy training paradigm. However existing RL methods suffer from high sample complexity, poor sim-to-real transfer, and limited runtime adaptability to navigation scenarios not seen during training. These problems are particularly challenging for drones, with complex nonlinear and unstable dynamics, and strong dynamic coupling between control and perception. In this paper, we propose a novel framework that integrates 3D Gaussian Splatting (3DGS) with differentiable deep reinforcement learning (DDRL) to train vision-based drone navigation policies. By leveraging high-fidelity 3D scene representations and differentiable simulation, our method improves sample efficiency and sim-to-real transfer. Additionally, we incorporate a Context-aided Estimator Network (CENet) to adapt to environmental variations at runtime. Moreover, by curriculum training in a mixture of different surrounding environments, we achieve in-task generalization, the ability to solve new instances of a task not seen during training. Drone hardware experiments demonstrate our method's high training efficiency compared to state-of-the-art RL methods, zero shot sim-to-real transfer for real robot deployment without fine tuning, and ability to adapt to new instances within the same task class (e.g. to fly through a gate at different locations with different distractors in the environment).

自主视觉导航是机器人自主性的核心要素，而强化学习（Reinforcement Learning, RL） 提供了一种有前景的策略训练范式。然而，现有的 RL 方法 存在高样本复杂度、弱 sim-to-real 迁移能力，以及对训练未见导航场景的适应性较差等问题。这些挑战在无人机任务中尤为突出，因其具有复杂的非线性、不稳定动力学，以及控制与感知之间的强动态耦合。
在本文中，我们提出了一种新颖的3D Gaussian Splatting (3DGS) 与可微分深度强化学习（Differentiable Deep Reinforcement Learning, DDRL）相结合的框架，用于训练基于视觉的无人机导航策略。通过高保真 3D 场景表示和可微分仿真，我们的框架提高了样本效率和sim-to-real 迁移能力。此外，我们引入 Context-aided Estimator Network (CENet)，用于适应运行时（runtime）环境变化。
同时，我们采用课程学习（curriculum training），在多种不同环境组合中训练策略，实现任务内泛化（in-task generalization），即在未见过的同类任务实例中仍能保持良好性能（例如，在不同位置的门洞中飞行，或应对不同的环境干扰）。
无人机硬件实验表明，与最先进（SOTA）RL 方法相比，我们的方法训练效率更高，并且无需微调即可实现零样本 sim-to-real 迁移，同时具备在相同任务类别内适应新实例的能力。
