### Fully Explicit Dynamic Gaussian Splatting

3D Gaussian Splatting has shown fast and high-quality rendering results in static scenes by leveraging dense 3D prior and explicit representations. Unfortunately, the benefits of the prior and representation do not involve novel view synthesis for dynamic motions. Ironically, this is because the main barrier is the reliance on them, which requires increasing training and rendering times to account for dynamic motions. In this paper, we design a Explicit 4D Gaussian Splatting(Ex4DGS). Our key idea is to firstly separate static and dynamic Gaussians during training, and to explicitly sample positions and rotations of the dynamic Gaussians at sparse timestamps. The sampled positions and rotations are then interpolated to represent both spatially and temporally continuous motions of objects in dynamic scenes as well as reducing computational cost. Additionally, we introduce a progressive training scheme and a point-backtracking technique that improves Ex4DGS's convergence. We initially train Ex4DGS using short timestamps and progressively extend timestamps, which makes it work well with a few point clouds. The point-backtracking is used to quantify the cumulative error of each Gaussian over time, enabling the detection and removal of erroneous Gaussians in dynamic scenes. Comprehensive experiments on various scenes demonstrate the state-of-the-art rendering quality from our method, achieving fast rendering of 62 fps on a single 2080Ti GPU.

3D高斯点云已在静态场景中展示了快速且高质量的渲染效果，这得益于其密集的3D先验和显式表示。然而，这些优势并未延伸至动态场景的新视角合成。讽刺的是，主要障碍正是对这些先验和表示的依赖，导致在处理动态场景时训练和渲染时间大幅增加。本文提出了一种显式4D高斯点云方法（Ex4DGS）。我们的核心思路是首先在训练过程中分离静态和动态高斯，并在稀疏时间戳上显式采样动态高斯的位置和旋转。采样的位置和旋转随后通过插值来表示动态场景中物体的空间和时间连续运动，同时降低了计算成本。此外，我们引入了一种渐进式训练方案和点回溯技术，以提高Ex4DGS的收敛性。我们初始使用较短的时间戳训练Ex4DGS，并逐步延长时间戳，从而使其在少量点云上表现良好。点回溯用于量化每个高斯随时间的累积误差，从而在动态场景中检测并移除误差较大的高斯。多场景的全面实验验证了我们方法的渲染质量，单块2080Ti GPU上实现了62 fps的快速渲染。
