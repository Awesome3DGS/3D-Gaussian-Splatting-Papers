### 3R-GS: Best Practice in Optimizing Camera Poses Along with 3DGS

3D Gaussian Splatting (3DGS) has revolutionized neural rendering with its efficiency and quality, but like many novel view synthesis methods, it heavily depends on accurate camera poses from Structure-from-Motion (SfM) systems. Although recent SfM pipelines have made impressive progress, questions remain about how to further improve both their robust performance in challenging conditions (e.g., textureless scenes) and the precision of camera parameter estimation simultaneously. We present 3R-GS, a 3D Gaussian Splatting framework that bridges this gap by jointly optimizing 3D Gaussians and camera parameters from large reconstruction priors MASt3R-SfM. We note that naively performing joint 3D Gaussian and camera optimization faces two challenges: the sensitivity to the quality of SfM initialization, and its limited capacity for global optimization, leading to suboptimal reconstruction results. Our 3R-GS, overcomes these issues by incorporating optimized practices, enabling robust scene reconstruction even with imperfect camera registration. Extensive experiments demonstrate that 3R-GS delivers high-quality novel view synthesis and precise camera pose estimation while remaining computationally efficient.

三维高斯投影（3D Gaussian Splatting, 3DGS）以其高效率与高质量彻底革新了神经渲染领域，但与许多新颖的视角合成方法一样，其高度依赖来自结构光恢复（Structure-from-Motion, SfM）系统的精确相机位姿。尽管近期SfM流程已取得显著进展，但在复杂场景下的鲁棒性提升（如无纹理区域）以及相机参数估计精度提升方面，仍存在挑战。
为此，我们提出了 3R-GS，这是一种基于3DGS的框架，通过引入大型重建先验 MASt3R-SfM，实现对三维高斯与相机参数的联合优化，以填补上述空白。
我们指出，直接进行3D高斯与相机参数的联合优化存在两个主要难点：其一是对SfM初始化质量极其敏感；其二是缺乏全局优化能力，容易导致次优重建结果。
3R-GS 通过引入一系列优化实践，有效克服了这些问题，使得即便在相机配准存在误差的条件下，也能实现鲁棒的场景重建。大量实验证明，3R-GS 在保持计算效率的同时，能够实现高质量的新视角合成与高精度的相机位姿估计。
