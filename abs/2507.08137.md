### Occlusion-Aware Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction

We introduce a novel framework for reconstructing dynamic human-object interactions from monocular video that overcomes challenges associated with occlusions and temporal inconsistencies. Traditional 3D reconstruction methods typically assume static objects or full visibility of dynamic subjects, leading to degraded performance when these assumptions are violated-particularly in scenarios where mutual occlusions occur. To address this, our framework leverages amodal completion to infer the complete structure of partially obscured regions. Unlike conventional approaches that operate on individual frames, our method integrates temporal context, enforcing coherence across video sequences to incrementally refine and stabilize reconstructions. This template-free strategy adapts to varying conditions without relying on predefined models, significantly enhancing the recovery of intricate details in dynamic scenes. We validate our approach using 3D Gaussian Splatting on challenging monocular videos, demonstrating superior precision in handling occlusions and maintaining temporal stability compared to existing techniques.

我们提出了一种从单目视频中重建动态人-物交互的新型框架，能够克服遮挡和时间不一致带来的挑战。传统三维重建方法通常假设物体是静止的或动态主体完全可见，当这些假设被打破时（尤其是在发生相互遮挡的场景中），性能会显著下降。为了解决这一问题，我们的框架利用非模态补全（amodal completion）来推断被部分遮挡区域的完整结构。不同于在单帧上独立处理的传统方法，我们的方法融合了时间上下文，在视频序列中强制保持时序一致性，从而逐步优化并稳定重建结果。这种无模板策略无需依赖预定义模型，能够适应多变条件，大幅提升动态场景中细节的恢复效果。我们在具有挑战性的单目视频上结合三维高斯投影（3D Gaussian Splatting）对方法进行了验证，结果表明相比现有技术，我们的方法在处理遮挡与保持时间稳定性方面具有更高的精度。
