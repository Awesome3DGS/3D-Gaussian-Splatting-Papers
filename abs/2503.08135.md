### ArticulatedGS: Self-supervised Digital Twin Modeling of Articulated Objects using 3D Gaussian Splatting

We tackle the challenge of concurrent reconstruction at the part level with the RGB appearance and estimation of motion parameters for building digital twins of articulated objects using the 3D Gaussian Splatting (3D-GS) method. With two distinct sets of multi-view imagery, each depicting an object in separate static articulation configurations, we reconstruct the articulated object in 3D Gaussian representations with both appearance and geometry information at the same time. Our approach decoupled multiple highly interdependent parameters through a multi-step optimization process, thereby achieving a stable optimization procedure and high-quality outcomes. We introduce ArticulatedGS, a self-supervised, comprehensive framework that autonomously learns to model shapes and appearances at the part level and synchronizes the optimization of motion parameters, all without reliance on 3D supervision, motion cues, or semantic labels. Our experimental results demonstrate that, among comparable methodologies, our approach has achieved optimal outcomes in terms of part segmentation accuracy, motion estimation accuracy, and visual quality.

我们针对 构建可动对象（articulated objects）数字孪生 的需求，采用 三维高斯投影（3D Gaussian Splatting, 3D-GS） 方法，解决 基于 RGB 视觉信息的部件级别重建 及 运动参数估计 这一挑战。在我们的设定中，输入为 两组多视角图像，分别捕捉了对象在 不同静态关节配置 下的状态，我们的目标是在 三维高斯表示 中 同时重建对象的外观和几何信息。
我们的方法通过 多步优化过程（multi-step optimization process） 解耦多个高度相关的参数，从而实现 稳定的优化流程 并获得 高质量的重建结果。为此，我们提出 ArticulatedGS，这是一个 自监督（self-supervised）、全面（comprehensive） 的框架，能够 自主学习建模部件级别的形状和外观，并同步优化运动参数，无需 3D 监督、运动线索或语义标签。
实验结果表明，在 可比方法 中，我们的方案在 部件分割精度（part segmentation accuracy）、运动估计精度（motion estimation accuracy） 和 视觉质量（visual quality） 方面均实现了 最佳表现。
