### UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation

Estimating the 6D pose of novel objects is a fundamental yet challenging problem in robotics, often relying on access to object CAD models. However, acquiring such models can be costly and impractical. Recent approaches aim to bypass this requirement by leveraging strong priors from foundation models to reconstruct objects from single or multi-view images, but typically require additional training or produce hallucinated geometry. To this end, we propose UnPose, a novel framework for zero-shot, model-free 6D object pose estimation and reconstruction that exploits 3D priors and uncertainty estimates from a pre-trained diffusion model. Specifically, starting from a single-view RGB-D frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise epistemic uncertainty estimates. As additional observations become available, we incrementally refine the 3DGS model by fusing new views guided by the diffusion model's uncertainty, thereby continuously improving the pose estimation accuracy and 3D reconstruction quality. To ensure global consistency, the diffusion prior-generated views and subsequent observations are further integrated in a pose graph and jointly optimized into a coherent 3DGS field. Extensive experiments demonstrate that UnPose significantly outperforms existing approaches in both 6D pose estimation accuracy and 3D reconstruction quality. We further showcase its practical applicability in real-world robotic manipulation tasks.

新物体的 6D 位姿估计是机器人领域中的一个基础但极具挑战性的问题，通常依赖于物体 CAD 模型。然而，获取此类模型往往代价高昂且不切实际。近期方法试图通过利用基础模型的强先验，从单视角或多视角图像重建物体，以绕过这一需求，但通常需要额外训练或会产生虚构的几何结构。为此，我们提出了 UnPose，这是一种零样本、无模型的 6D 物体位姿估计与重建新框架，利用预训练扩散模型的三维先验和不确定性估计。具体而言，从单帧 RGB-D 图像出发，UnPose 使用多视角扩散模型基于三维高斯溅射（3DGS）表示估计初始三维模型，并生成逐像素的认知不确定性估计。随着更多观测的引入，我们通过融合由扩散模型不确定性引导的新视角，逐步优化 3DGS 模型，从而不断提升位姿估计精度与三维重建质量。为确保全局一致性，扩散先验生成的视角与后续观测被进一步整合进位姿图，并联合优化为一个一致的 3DGS 场。大量实验表明，UnPose 在 6D 位姿估计精度与三维重建质量上均显著优于现有方法。我们还展示了其在真实机器人操作任务中的实用性。
