### HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting

Human hair reconstruction is a challenging problem in computer vision, with growing importance for applications in virtual reality and digital human modeling. Recent advances in 3D Gaussians Splatting (3DGS) provide efficient and explicit scene representations that naturally align with the structure of hair strands. In this work, we extend the 3DGS framework to enable strand-level hair geometry reconstruction from multi-view images. Our multi-stage pipeline first reconstructs detailed hair geometry using a differentiable Gaussian rasterizer, then merges individual Gaussian segments into coherent strands through a novel merging scheme, and finally refines and grows the strands under photometric supervision. While existing methods typically evaluate reconstruction quality at the geometric level, they often neglect the connectivity and topology of hair strands. To address this, we propose a new evaluation metric that serves as a proxy for assessing topological accuracy in strand reconstruction. Extensive experiments on both synthetic and real-world datasets demonstrate that our method robustly handles a wide range of hairstyles and achieves efficient reconstruction, typically completing within one hour.

人类头发重建是计算机视觉中的一项具有挑战性的问题，在虚拟现实和数字人建模等应用中具有日益重要的意义。近年来，三维高斯溅射（3D Gaussian Splatting, 3DGS）的发展为场景提供了一种高效且显式的表示方式，其天然契合了发丝的结构特性。在本研究中，我们扩展了3DGS框架，使其能够从多视角图像中实现基于发丝级别的头发几何重建。我们提出的多阶段管线首先利用可微分高斯光栅化器（differentiable Gaussian rasterizer）重建头发的细节几何结构，然后通过一种全新的合并策略将独立的高斯段融合为连贯的发丝，最后在光度监督下对发丝进行精修与生长。现有方法通常仅在几何层面评估重建质量，而忽视了发丝的连通性与拓扑结构。针对这一问题，我们提出了一种新的评估指标，用于近似衡量发丝重建的拓扑准确性。大量基于合成数据和真实数据集的实验结果表明，我们的方法能够稳健地处理多种不同发型，并实现高效重建，通常在一小时内即可完成。
