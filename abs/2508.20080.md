### Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images

360-degree visual content is widely shared on platforms such as YouTube and plays a central role in virtual reality, robotics, and autonomous navigation. However, consumer-grade dual-fisheye systems consistently yield imperfect panoramas due to inherent lens separation and angular distortions. In this work, we introduce a novel calibration framework that incorporates a dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach not only simulates the realistic visual artifacts produced by dual-fisheye cameras but also enables the synthesis of seamlessly rendered 360-degree images. By jointly optimizing 3D Gaussian parameters alongside calibration variables that emulate lens gaps and angular distortions, our framework transforms imperfect omnidirectional inputs into flawless novel view synthesis. Extensive evaluations on real-world datasets confirm that our method produces seamless renderings-even from imperfect images-and outperforms existing 360-degree rendering models.

360 度视觉内容在 YouTube 等平台上被广泛分享，并在虚拟现实、机器人技术和自动驾驶中发挥着核心作用。然而，消费级双鱼眼系统由于固有的镜头分离和角度畸变，常常生成不完美的全景图。在这项工作中，我们提出了一种新颖的标定框架，将双鱼眼相机模型引入三维高斯点绘（3D Gaussian Splatting）管线。我们的方法不仅能够模拟双鱼眼相机产生的真实视觉伪影，还可以合成无缝渲染的 360 度图像。通过联合优化三维高斯参数与标定变量（用于模拟镜头间隙和角度畸变），我们的框架能够将不完美的全向输入转化为无瑕的新视角合成结果。在真实世界数据集上的大量评估结果表明，我们的方法即便在输入图像不完美的情况下也能生成无缝渲染，并优于现有的 360 度渲染模型。
