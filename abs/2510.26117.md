### JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting

Traditional novel view synthesis methods heavily rely on external camera pose estimation tools such as COLMAP, which often introduce computational bottlenecks and propagate errors. To address these challenges, we propose a unified framework that jointly optimizes 3D Gaussian points and camera poses without requiring pre-calibrated inputs. Our approach iteratively refines 3D Gaussian parameters and updates camera poses through a novel co-optimization strategy, ensuring simultaneous improvements in scene reconstruction fidelity and pose accuracy. The key innovation lies in decoupling the joint optimization into two interleaved phases: first, updating 3D Gaussian parameters via differentiable rendering with fixed poses, and second, refining camera poses using a customized 3D optical flow algorithm that incorporates geometric and photometric constraints. This formulation progressively reduces projection errors, particularly in challenging scenarios with large viewpoint variations and sparse feature distributions, where traditional methods struggle. Extensive evaluations on multiple datasets demonstrate that our approach significantly outperforms existing COLMAP-free techniques in reconstruction quality, and also surpasses the standard COLMAP-based baseline in general.

传统的新视角合成方法严重依赖于外部相机位姿估计工具，如 COLMAP，这类工具常常成为计算瓶颈，并可能引入累积误差。为了解决这些问题，我们提出了一个统一框架，在无需预先校准输入的情况下联合优化三维高斯点与相机位姿。我们的方法通过一种新颖的协同优化策略，迭代地优化三维高斯参数并更新相机位姿，从而实现对场景重建质量和位姿准确性的同步提升。其核心创新在于将联合优化过程解耦为两个交替阶段：第一阶段在固定位姿条件下，通过可微渲染优化三维高斯参数；第二阶段使用定制的三维光流算法，在结合几何与光度约束的基础上对相机位姿进行精细优化。该策略能够持续降低投影误差，尤其适用于视角变化大、特征分布稀疏等传统方法难以处理的复杂场景。在多个数据集上的大量实验结果表明，我们的方法在重建质量方面显著优于现有的无 COLMAP 方法，整体表现也超过了标准的基于 COLMAP 的方法。
