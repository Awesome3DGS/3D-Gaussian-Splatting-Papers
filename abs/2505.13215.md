### Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation

Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.

近年来，动态三维场景重建取得了显著进展，使得具有更高时间一致性的新视角三维图像合成成为可能。其中，4D Gaussian Splatting（4DGS） 凭借其对时空变化的高保真建模能力，成为一个颇具吸引力的方案。然而，现有方法普遍存在计算与内存开销巨大的问题，主要由于对静态区域不必要地分配了冗余的 4D 高斯，从而也可能导致图像质量下降。
为此，本文提出了一种新框架：混合 3D-4D Gaussian Splatting（3D-4DGS）。该方法自适应地使用 3D 高斯表示静态区域，仅将 4D 高斯保留给动态部分。我们的方法以全 4D 高斯初始化表示整个场景，并通过迭代过程将时间上不变的高斯转换为 3D 表达，从而显著减少参数数量，提高计算效率。
同时，动态区域中的高斯保持完整的 4D 表示，用于高保真地捕捉复杂运动。实验表明，相较于传统 4DGS 方法，我们的框架在保持或提升视觉质量的同时，大幅加快了训练速度。
