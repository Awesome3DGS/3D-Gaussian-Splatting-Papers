### ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model

Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for novel view synthesis, offering fast rendering speeds and high fidelity. However, the large number of Gaussians and their associated attributes require effective compression techniques. Existing methods primarily compress neural Gaussians individually and independently, i.e., coding all the neural Gaussians at the same time, with little design for their interactions and spatial dependence. Inspired by the effectiveness of the context model in image compression, we propose the first autoregressive model at the anchor level for 3DGS compression in this work. We divide anchors into different levels and the anchors that are not coded yet can be predicted based on the already coded ones in all the coarser levels, leading to more accurate modeling and higher coding efficiency. To further improve the efficiency of entropy coding, e.g., to code the coarsest level with no already coded anchors, we propose to introduce a low-dimensional quantized feature as the hyperprior for each anchor, which can be effectively compressed. Our work pioneers the context model in the anchor level for 3DGS representation, yielding an impressive size reduction of over 100 times compared to vanilla 3DGS and 15 times compared to the most recent state-of-the-art work Scaffold-GS, while achieving comparable or even higher rendering quality.

最近，三维高斯绘制（3DGS）已成为新视图合成的一个有前景的框架，提供了快速的渲染速度和高保真度。然而，大量的高斯及其相关属性需要有效的压缩技术。现有方法主要是单独和独立地压缩神经高斯，即同时编码所有神经高斯，对它们的交互和空间依赖性设计较少。受图像压缩中上下文模型有效性的启发，我们在这项工作中提出了第一个用于3DGS压缩的锚点级自回归模型。我们将锚点划分为不同的层次，尚未编码的锚点可以基于所有较粗层次中已编码的锚点进行预测，从而实现更准确的建模和更高的编码效率。为了进一步提高熵编码的效率，例如，用于编码没有已编码锚点的最粗层次，我们提议引入每个锚点的低维量化特征作为超先验，这可以被有效压缩。我们的工作在锚点级别为3DGS表示引入了上下文模型，与传统3DGS相比，压缩大小超过100倍，与最新的先进工作Scaffold-GS相比，压缩比达到15倍，同时实现了可比较甚至更高的渲染质量。
