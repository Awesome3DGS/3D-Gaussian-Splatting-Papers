### 3D Gaussian Splatting with Normal Information for Mesh Extraction and Improved Rendering

Differentiable 3D Gaussian splatting has emerged as an efficient and flexible rendering technique for representing complex scenes from a collection of 2D views and enabling high-quality real-time novel-view synthesis. However, its reliance on photometric losses can lead to imprecisely reconstructed geometry and extracted meshes, especially in regions with high curvature or fine detail. We propose a novel regularization method using the gradients of a signed distance function estimated from the Gaussians, to improve the quality of rendering while also extracting a surface mesh. The regularizing normal supervision facilitates better rendering and mesh reconstruction, which is crucial for downstream applications in video generation, animation, AR-VR and gaming. We demonstrate the effectiveness of our approach on datasets such as Mip-NeRF360, Tanks and Temples, and Deep-Blending. Our method scores higher on photorealism metrics compared to other mesh extracting rendering methods without compromising mesh quality.

可微分三维高斯散点（Differentiable 3D Gaussian Splatting）已成为一种高效且灵活的渲染技术，能够从二维视图集合中表示复杂场景，并实现高质量的实时新视角合成。然而，由于其依赖于光度损失，在高曲率区域或细节丰富区域，重建的几何和提取的网格可能不够精确。
我们提出了一种基于从高斯估算的符号距离函数梯度的新正则化方法，以提高渲染质量并实现表面网格的提取。该正则化的法线监督能够改善渲染效果和网格重建质量，这对于视频生成、动画、增强现实（AR）-虚拟现实（VR）以及游戏等下游应用至关重要。
我们在 Mip-NeRF360、Tanks and Temples 和 Deep-Blending 等数据集上验证了该方法的有效性。相比其他网格提取渲染方法，我们的方法在不降低网格质量的前提下，在写实度指标上表现更优。
