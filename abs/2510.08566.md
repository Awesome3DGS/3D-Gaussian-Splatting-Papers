### D2GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction

Recent advances in 3D Gaussian Splatting (3DGS) enable real-time, high-fidelity novel view synthesis (NVS) with explicit 3D representations. However, performance degradation and instability remain significant under sparse-view conditions. In this work, we identify two key failure modes under sparse-view conditions: overfitting in regions with excessive Gaussian density near the camera, and underfitting in distant areas with insufficient Gaussian coverage. To address these challenges, we propose a unified framework D2GS, comprising two key components: a Depth-and-Density Guided Dropout strategy that suppresses overfitting by adaptively masking redundant Gaussians based on density and depth, and a Distance-Aware Fidelity Enhancement module that improves reconstruction quality in under-fitted far-field areas through targeted supervision. Moreover, we introduce a new evaluation metric to quantify the stability of learned Gaussian distributions, providing insights into the robustness of the sparse-view 3DGS. Extensive experiments on multiple datasets demonstrate that our method significantly improves both visual quality and robustness under sparse view conditions.

三维高斯泼溅（3D Gaussian Splatting, 3DGS）的最新进展使得基于显式三维表示的实时高保真新视角合成（NVS）成为可能。然而，在稀疏视角条件下，3DGS 仍面临显著的性能下降与稳定性问题。本文识别出两类典型失败模式：其一是在靠近相机的区域，高斯密度过高导致的过拟合现象；其二是在远距离区域，高斯覆盖不足导致的欠拟合问题。为应对这些挑战，我们提出了一个统一框架 D2GS，其中包含两个关键模块：（1）深度-密度引导的 Dropout 策略（Depth-and-Density Guided Dropout），该方法基于深度与密度信息自适应地屏蔽冗余高斯点，以抑制过拟合；（2）距离感知的保真度增强模块（Distance-Aware Fidelity Enhancement），通过有针对性的监督机制提升远场欠拟合区域的重建质量。此外，我们还引入了一种新的评估指标，用于量化所学习高斯分布的稳定性，从而更好地洞察稀疏视角下 3DGS 的鲁棒性。大量在多个数据集上的实验证明，D2GS 显著提升了稀疏视角条件下的视觉质量与系统稳定性。
