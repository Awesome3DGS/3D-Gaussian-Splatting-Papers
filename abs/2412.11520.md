### EditSplat: Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting

Recent advancements in 3D editing have highlighted the potential of text-driven methods in real-time, user-friendly AR/VR applications. However, current methods rely on 2D diffusion models without adequately considering multi-view information, resulting in multi-view inconsistency. While 3D Gaussian Splatting (3DGS) significantly improves rendering quality and speed, its 3D editing process encounters difficulties with inefficient optimization, as pre-trained Gaussians retain excessive source information, hindering optimization. To address these limitations, we propose \textbf{EditSplat}, a novel 3D editing framework that integrates Multi-view Fusion Guidance (MFG) and Attention-Guided Trimming (AGT). Our MFG ensures multi-view consistency by incorporating essential multi-view information into the diffusion process, leveraging classifier-free guidance from the text-to-image diffusion model and the geometric properties of 3DGS. Additionally, our AGT leverages the explicit representation of 3DGS to selectively prune and optimize 3D Gaussians, enhancing optimization efficiency and enabling precise, semantically rich local edits. Through extensive qualitative and quantitative evaluations, EditSplat achieves superior multi-view consistency and editing quality over existing methods, significantly enhancing overall efficiency.

三维编辑的最新进展凸显了文本驱动方法在实时、用户友好的 AR/VR 应用中的潜力。然而，现有方法依赖于二维扩散模型，未能充分考虑多视角信息，从而导致多视角不一致的问题。尽管三维高斯点云技术（3D Gaussian Splatting, 3DGS）在渲染质量和速度上取得了显著提升，其三维编辑过程却因优化效率低下而面临挑战，主要原因在于预训练的高斯点云保留了过多的原始信息，阻碍了优化过程。
为了解决这些限制，我们提出了 EditSplat，一种融合了多视角融合引导（Multi-view Fusion Guidance, MFG）和注意力引导修剪（Attention-Guided Trimming, AGT）的新型三维编辑框架。MFG 通过在扩散过程中整合关键多视角信息，结合文本到图像扩散模型的无分类器引导和 3DGS 的几何特性，确保了多视角一致性。同时，AGT 利用 3DGS 的显式表示，对三维高斯进行选择性修剪和优化，从而提高优化效率并实现精准且语义丰富的局部编辑。
通过广泛的定性和定量评估，EditSplat 在多视角一致性和编辑质量方面显著优于现有方法，同时显著提升了整体效率。
