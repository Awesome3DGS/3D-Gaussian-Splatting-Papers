### M3: 3D-Spatial MultiModal Memory

We present 3D Spatial MultiModal Memory (M3), a multimodal memory system designed to retain information about medium-sized static scenes through video sources for visual perception. By integrating 3D Gaussian Splatting techniques with foundation models, M3 builds a multimodal memory capable of rendering feature representations across granularities, encompassing a wide range of knowledge. In our exploration, we identify two key challenges in previous works on feature splatting: (1) computational constraints in storing high-dimensional features for each Gaussian primitive, and (2) misalignment or information loss between distilled features and foundation model features. To address these challenges, we propose M3 with key components of principal scene components and Gaussian memory attention, enabling efficient training and inference. To validate M3, we conduct comprehensive quantitative evaluations of feature similarity and downstream tasks, as well as qualitative visualizations to highlight the pixel trace of Gaussian memory attention. Our approach encompasses a diverse range of foundation models, including vision-language models (VLMs), perception models, and large multimodal and language models (LMMs/LLMs). Furthermore, to demonstrate real-world applicability, we deploy M3's feature field in indoor scenes on a quadruped robot. Notably, we claim that M3 is the first work to address the core compression challenges in 3D feature distillation.

我们提出了 3D 空间多模态记忆 (M3)，这是一种多模态记忆系统，旨在通过视频源存储中等规模静态场景的视觉感知信息。M3 结合 3D 高斯散点 (3DGS) 技术与基础模型，构建了一种能够在多个粒度上渲染特征表示的多模态记忆系统，以涵盖广泛的知识范围。
在研究过程中，我们识别出特征散点研究中的两个关键挑战：(1) 计算约束——为每个高斯基元存储高维特征的计算开销较大，(2) 特征错位或信息损失——蒸馏特征与基础模型特征之间可能存在对齐误差或信息损失。为了解决这些问题，我们提出 M3，其核心组件包括主场景组件和高斯记忆注意力，从而实现高效训练与推理。
为了验证 M3，我们进行了全面的定量评估，涵盖特征相似性分析和下游任务测试，并通过定性可视化展示高斯记忆注意力的像素级追踪表现。我们的方法涵盖多种基础模型，包括视觉-语言模型 (VLMs)、感知模型，以及大规模多模态和语言模型 (LMMs/LLMs)。此外，为了展示其在真实场景中的应用能力，我们将 M3 的特征场部署在四足机器人的室内场景感知任务中。值得注意的是，我们认为 M3 是首个针对 3D 特征蒸馏核心压缩挑战的研究。
