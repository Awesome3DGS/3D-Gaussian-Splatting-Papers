### SVR-GS: Spatially Variant Regularization for Probabilistic Masks in 3D Gaussian Splatting

3D Gaussian Splatting (3DGS) enables fast, high-quality novel view synthesis but typically relies on densification followed by pruning to optimize the number of Gaussians. Existing mask-based pruning, such as MaskGS, regularizes the global mean of the mask, which is misaligned with the local per-pixel (per-ray) reconstruction loss that determines image quality along individual camera rays. This paper introduces SVR-GS, a spatially variant regularizer that renders a per-pixel spatial mask from each Gaussian's effective contribution along the ray, thereby applying sparsity pressure where it matters: on low-importance Gaussians. We explore three spatial-mask aggregation strategies, implement them in CUDA, and conduct a gradient analysis to motivate our final design. Extensive experiments on Tanks\&Temples, Deep Blending, and Mip-NeRF360 datasets demonstrate that, on average across the three datasets, the proposed SVR-GS reduces the number of Gaussians by 1.79× compared to MaskGS and 5.63× compared to 3DGS, while incurring only 0.50 dB and 0.40 dB PSNR drops, respectively. These gains translate into significantly smaller, faster, and more memory-efficient models, making them well-suited for real-time applications such as robotics, AR/VR, and mobile perception.

三维高斯溅射（3D Gaussian Splatting, 3DGS）实现了快速且高质量的新视角合成，但通常依赖“密集化（densification）+剪枝（pruning）”的过程来优化高斯原语数量。现有的基于掩码的剪枝方法（如MaskGS）通过正则化掩码的全局均值来约束模型，但这种做法与决定单个相机光线图像质量的局部逐像素（per-pixel / per-ray）重建误差并不一致。为解决这一问题，我们提出了SVR-GS，一种空间可变正则化方法（spatially variant regularizer）。SVR-GS通过渲染每个高斯沿光线的有效贡献，生成逐像素空间掩码，从而在关键位置施加稀疏性约束，重点抑制低重要性高斯。我们探索了三种空间掩码聚合策略，并基于CUDA实现了高效加速，同时进行了梯度分析以验证最终设计的合理性。在Tanks&Temples、Deep Blending和Mip-NeRF360三个基准数据集上的实验表明，SVR-GS在平均表现上相比MaskGS减少了1.79倍的高斯数量，相比原始3DGS减少了5.63倍，同时PSNR仅下降0.50 dB和0.40 dB。这一性能提升使得SVR-GS生成的模型在规模更小、渲染更快、内存更高效的同时，依然保持高质量表现，非常适合实时应用场景，如机器人、增强/虚拟现实（AR/VR）以及移动感知。
