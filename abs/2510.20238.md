### COS3D: Collaborative Open-Vocabulary 3D Segmentation

Open-vocabulary 3D segmentation is a fundamental yet challenging task, requiring a mutual understanding of both segmentation and language. However, existing Gaussian-splatting-based methods rely either on a single 3D language field, leading to inferior segmentation, or on pre-computed class-agnostic segmentations, suffering from error accumulation. To address these limitations, we present COS3D, a new collaborative prompt-segmentation framework that contributes to effectively integrating complementary language and segmentation cues throughout its entire pipeline. We first introduce the new concept of collaborative field, comprising an instance field and a language field, as the cornerstone for collaboration. During training, to effectively construct the collaborative field, our key idea is to capture the intrinsic relationship between the instance field and language field, through a novel instance-to-language feature mapping and designing an efficient two-stage training strategy. During inference, to bridge distinct characteristics of the two fields, we further design an adaptive language-to-instance prompt refinement, promoting high-quality prompt-segmentation inference. Extensive experiments not only demonstrate COS3D's leading performance over existing methods on two widely-used benchmarks but also show its high potential to various applications,~\ie, novel image-based 3D segmentation, hierarchical segmentation, and robotics.

开放词汇三维分割是一项基础但极具挑战性的任务，要求模型在分割与语言之间建立深层次的相互理解。然而，现有基于高斯投影的方法要么依赖于单一的三维语言场，导致分割性能不足；要么依赖于预计算的类别无关分割结果，容易积累误差。为克服这些局限，本文提出了COS3D，一种新颖的协同提示分割框架，能够在整个流程中有效融合语言与分割的互补信息。
我们首先提出“协同场”（collaborative field）的新概念，它由实例场和语言场共同构成，作为协同建模的基础。在训练阶段，为了高效构建协同场，我们的核心思想是通过创新的“实例到语言”特征映射方式，并设计高效的两阶段训练策略，从而建模实例场与语言场之间的内在关系。在推理阶段，为了弥合两种场之间的特征差异，我们进一步设计了自适应的“语言到实例”提示优化机制，以提升提示驱动分割的推理质量。
大量实验证明，COS3D在两个广泛使用的基准上都取得了领先性能，并展现出在多种应用场景中的强大潜力，例如新颖图像驱动的三维分割、分层分割以及机器人系统等。
