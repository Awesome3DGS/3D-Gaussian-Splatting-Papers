### Uncertainty-Aware Normal-Guided Gaussian Splatting for Surface Reconstruction from Sparse Image Sequences

3D Gaussian Splatting (3DGS) has achieved impressive rendering performance in novel view synthesis. However, its efficacy diminishes considerably in sparse image sequences, where inherent data sparsity amplifies geometric uncertainty during optimization. This often leads to convergence at suboptimal local minima, resulting in noticeable structural artifacts in the reconstructed scenes. To mitigate these issues, we propose Uncertainty-aware Normal-Guided Gaussian Splatting (UNG-GS), a novel framework featuring an explicit Spatial Uncertainty Field (SUF) to quantify geometric uncertainty within the 3DGS pipeline. UNG-GS enables high-fidelity rendering and achieves high-precision reconstruction without relying on priors. Specifically, we first integrate Gaussian-based probabilistic modeling into the training of 3DGS to optimize the SUF, providing the model with adaptive error tolerance. An uncertainty-aware depth rendering strategy is then employed to weight depth contributions based on the SUF, effectively reducing noise while preserving fine details. Furthermore, an uncertainty-guided normal refinement method adjusts the influence of neighboring depth values in normal estimation, promoting robust results. Extensive experiments demonstrate that UNG-GS significantly outperforms state-of-the-art methods in both sparse and dense sequences.

3D 高斯溅射（3DGS）在新视角合成中取得了令人印象深刻的渲染性能。然而，在稀疏图像序列中，它的效果显著下降，因为固有的数据稀疏性在优化过程中加剧了几何不确定性。这常常导致模型收敛到次优的局部极小值，从而在重建的场景中产生明显的结构性伪影。为了解决这些问题，我们提出了基于不确定性感知的法线引导高斯溅射（UNG-GS），这是一个新颖的框架，具有一个显式的空间不确定性场（SUF）来量化 3DGS 流程中的几何不确定性。UNG-GS 实现了高保真渲染，并且无需依赖先验即可实现高精度重建。具体来说，我们首先将基于高斯的概率建模集成到 3DGS 的训练过程中，以优化 SUF，从而为模型提供自适应的误差容忍度。然后，采用一种不确定性感知的深度渲染策略，根据 SUF 对深度贡献进行加权，有效地减少噪声，同时保留细节。此外，我们还提出了一种不确定性引导的法线优化方法，调整邻近深度值在法线估计中的影响，促进鲁棒性结果。大量实验表明，UNG-GS 在稀疏和密集序列中的表现均显著优于现有的最先进方法。
