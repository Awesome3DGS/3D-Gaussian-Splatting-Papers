### GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals

3D Morphable Models (3DMMs) enable controllable facial geometry and expression editing for reconstruction, animation, and AR/VR, but traditional PCA-based mesh models are limited in resolution, detail, and photorealism. Neural volumetric methods improve realism but remain too slow for interactive use. Recent Gaussian Splatting (3DGS) based facial models achieve fast, high-quality rendering but still depend solely on a mesh-based 3DMM prior for expression control, limiting their ability to capture fine-grained geometry, expressions, and full-head coverage. We introduce GRMM, the first full-head Gaussian 3D morphable model that augments a base 3DMM with residual geometry and appearance components, additive refinements that recover high-frequency details such as wrinkles, fine skin texture, and hairline variations. GRMM provides disentangled control through low-dimensional, interpretable parameters (e.g., identity shape, facial expressions) while separately modelling residuals that capture subject- and expression-specific detail beyond the base model's capacity. Coarse decoders produce vertex-level mesh deformations, fine decoders represent per-Gaussian appearance, and a lightweight CNN refines rasterised images for enhanced realism, all while maintaining 75 FPS real-time rendering. To learn consistent, high-fidelity residuals, we present EXPRESS-50, the first dataset with 60 aligned expressions across 50 identities, enabling robust disentanglement of identity and expression in Gaussian-based 3DMMs. Across monocular 3D face reconstruction, novel-view synthesis, and expression transfer, GRMM surpasses state-of-the-art methods in fidelity and expression accuracy while delivering interactive real-time performance.

三维可变形模型（3DMM）能够实现可控的人脸几何与表情编辑，广泛应用于重建、动画和AR/VR，但传统基于PCA的网格模型在分辨率、细节和真实感方面存在局限。神经体积方法虽然提升了真实感，但速度过慢，难以满足交互式应用需求。近年来基于高斯溅射（3DGS）的人脸模型实现了快速且高质量的渲染，但仍完全依赖基于网格的3DMM先验进行表情控制，限制了其对细粒度几何、表情以及全头覆盖的捕捉能力。为此，我们提出了GRMM，这是首个全头高斯三维可变形模型，在基础3DMM上增添残差几何和外观组件，通过加性修复恢复诸如皱纹、精细皮肤纹理和发际线变化等高频细节。GRMM通过低维、可解释的参数（如身份形状、面部表情）提供解耦控制，同时单独建模残差，以捕捉超出基础模型能力的个体与表情特定细节。粗解码器生成顶点级网格变形，细解码器表示逐高斯的外观，一个轻量级CNN对光栅化图像进行细化以增强真实感，同时保持75 FPS的实时渲染。为学习一致且高保真的残差，我们提出了EXPRESS-50，这是首个包含50个身份、每个身份对齐60种表情的数据集，从而实现了高斯3DMM中身份与表情的稳健解耦。在单目三维人脸重建、新视角合成和表情迁移等任务上，GRMM在保真度和表情精度方面均超越现有最先进方法，并实现了交互式实时性能。
