### DropGaussian: Structural Regularization for Sparse-view Gaussian Splatting

Recently, 3D Gaussian splatting (3DGS) has gained considerable attentions in the field of novel view synthesis due to its fast performance while yielding the excellent image quality. However, 3DGS in sparse-view settings (e.g., three-view inputs) often faces with the problem of overfitting to training views, which significantly drops the visual quality of novel view images. Many existing approaches have tackled this issue by using strong priors, such as 2D generative contextual information and external depth signals. In contrast, this paper introduces a prior-free method, so-called DropGaussian, with simple changes in 3D Gaussian splatting. Specifically, we randomly remove Gaussians during the training process in a similar way of dropout, which allows non-excluded Gaussians to have larger gradients while improving their visibility. This makes the remaining Gaussians to contribute more to the optimization process for rendering with sparse input views. Such simple operation effectively alleviates the overfitting problem and enhances the quality of novel view synthesis. By simply applying DropGaussian to the original 3DGS framework, we can achieve the competitive performance with existing prior-based 3DGS methods in sparse-view settings of benchmark datasets without any additional complexity.

近年来，三维高斯喷洒（3D Gaussian Splatting, 3DGS）因其高速性能与优异图像质量，在新视角合成领域受到广泛关注。然而，在稀疏视角设置（例如仅提供三个视角）下，3DGS 常常出现对训练视角过拟合的问题，导致新视角图像的视觉质量显著下降。
许多现有方法通过引入强先验信息（如二维生成上下文或外部深度信号）来应对这一问题。与此不同，本文提出了一种无需先验的方法，命名为 DropGaussian，通过对 3DGS 进行简单改动来提升泛化能力。
具体而言，我们在训练过程中随机丢弃部分高斯分布，方式类似于 Dropout。这一策略使得未被丢弃的高斯在训练中获得更大的梯度，并提升其可见性，从而在稀疏输入视角下更有效地参与渲染优化。该操作简单直接，却能有效缓解过拟合问题，并提升新视角合成的图像质量。
仅需在原始 3DGS 框架中引入 DropGaussian，无需引入额外复杂度，即可在基准数据集的稀疏视角设置下达到与现有基于先验方法相当的性能。
