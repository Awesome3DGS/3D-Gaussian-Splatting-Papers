### Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds

Current multi-view 3D reconstruction methods rely on accurate camera calibration and pose estimation, requiring complex and time-intensive pre-processing that hinders their practical deployment. To address this challenge, we introduce Surf3R, an end-to-end feedforward approach that reconstructs 3D surfaces from sparse views without estimating camera poses and completes an entire scene in under 10 seconds. Our method employs a multi-branch and multi-view decoding architecture in which multiple reference views jointly guide the reconstruction process. Through the proposed branch-wise processing, cross-view attention, and inter-branch fusion, the model effectively captures complementary geometric cues without requiring camera calibration. Moreover, we introduce a D-Normal regularizer based on an explicit 3D Gaussian representation for surface reconstruction. It couples surface normals with other geometric parameters to jointly optimize the 3D geometry, significantly improving 3D consistency and surface detail accuracy. Experimental results demonstrate that Surf3R achieves state-of-the-art performance on multiple surface reconstruction metrics on ScanNet++ and Replica datasets, exhibiting excellent generalization and efficiency.

当前的多视图三维重建方法依赖精确的相机标定和位姿估计，这需要复杂且耗时的预处理过程，从而阻碍了其实际部署。为解决这一问题，我们提出了 Surf3R，这是一种端到端的前向方法，可在无需估计相机位姿的情况下，从稀疏视图重建三维表面，并在 10 秒内完成整个场景重建。我们的方法采用多分支、多视图解码架构，由多个参考视图共同引导重建过程。通过提出的分支级处理、跨视角注意力机制和分支间融合，模型能够在无需相机标定的情况下，有效捕获互补的几何线索。此外，我们引入了一种基于显式三维高斯表示的 D-Normal 正则化方法，用于表面重建。该方法将表面法向与其他几何参数耦合起来，共同优化三维几何结构，从而显著提升三维一致性和表面细节精度。实验结果表明，Surf3R 在 ScanNet++ 和 Replica 数据集上的多项表面重建指标上均达到了当前最先进水平，并展现出卓越的泛化能力和高效性。
