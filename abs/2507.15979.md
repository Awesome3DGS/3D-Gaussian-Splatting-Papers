### Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars

We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs animatable 3D human avatars from a single image. This is achieved by leveraging multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of 3D Gaussians. Given an image, we first dream plausible multi-views using a video diffusion model, capturing rich geometric and appearance details. These views are then lifted into unstructured 3D Gaussians. To enable animation, we propose a transformer-based encoder that models global spatial relationships and projects these Gaussians into a structured latent representation aligned with the UV space of a parametric body model. This latent code is decoded into UV-space Gaussians that can be animated via body-driven deformation and rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV manifold, our method ensures consistency during animation while preserving fine visual details. DLA enables real-time rendering and intuitive editing without requiring post-processing. Our method outperforms state-of-the-art approaches on ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric accuracy. By combining the generative strengths of video diffusion models with a pose-aware UV-space Gaussian mapping, DLA bridges the gap between unstructured 3D representations and high-fidelity, animation-ready avatars.

我们提出了 Dream、Lift、Animate（DLA）这一新型框架，可从单张图像重建可动画的三维人类虚拟形象。这一过程依托多视图生成、三维高斯提升（3D Gaussian lifting）以及基于姿态感知的 UV 空间三维高斯映射。给定一张图像，我们首先利用视频扩散模型生成合理的多视图图像（dream），以捕获丰富的几何和外观细节。随后，这些视图被提升为非结构化的三维高斯表示。为实现动画，我们提出了一种基于 Transformer 的编码器，用于建模全局空间关系，并将这些高斯投射到与参数化人体模型 UV 空间对齐的结构化潜在表示中。该潜在编码可解码为 UV 空间高斯，通过身体驱动的形变实现动画，并根据姿态与视角进行渲染。通过将高斯锚定在 UV 流形上，我们的方法在动画过程中确保一致性，同时保留细腻的视觉细节。DLA 支持实时渲染与直观
