### ArmGS: Composite Gaussian Appearance Refinement for Modeling Dynamic Urban Environments

This work focuses on modeling dynamic urban environments for autonomous driving simulation. Contemporary data-driven methods using neural radiance fields have achieved photorealistic driving scene modeling, but they suffer from low rendering efficacy. Recently, some approaches have explored 3D Gaussian splatting for modeling dynamic urban scenes, enabling high-fidelity reconstruction and real-time rendering. However, these approaches often neglect to model fine-grained variations between frames and camera viewpoints, leading to suboptimal results. In this work, we propose a new approach named ArmGS that exploits composite driving Gaussian splatting with multi-granularity appearance refinement for autonomous driving scene modeling. The core idea of our approach is devising a multi-level appearance modeling scheme to optimize a set of transformation parameters for composite Gaussian refinement from multiple granularities, ranging from local Gaussian level to global image level and dynamic actor level. This not only models global scene appearance variations between frames and camera viewpoints, but also models local fine-grained changes of background and objects. Extensive experiments on multiple challenging autonomous driving datasets, namely, Waymo, KITTI, NOTR and VKITTI2, demonstrate the superiority of our approach over the state-of-the-art methods.

本研究聚焦于面向自动驾驶仿真的动态城市环境建模。当前基于数据驱动的神经辐射场方法已在驾驶场景的照片级真实感建模中取得了成果，但渲染效率较低。近期，一些方法开始探索利用三维高斯投影（3D Gaussian Splatting）来建模动态城市场景，实现了高保真重建与实时渲染。然而，这些方法往往忽视了对帧间及相机视角间细粒度变化的建模，从而导致结果次优。为此，我们提出了一种新方法——ArmGS，通过复合驾驶高斯投影结合多粒度外观细化来进行自动驾驶场景建模。其核心思想是设计一种多层级外观建模方案，从局部高斯层级到全局图像层级以及动态主体层级，优化一组复合高斯细化的变换参数。这不仅能够建模帧间与视角间的全局场景外观变化，还能够捕捉背景与物体的局部细粒度变化。在 Waymo、KITTI、NOTR 和 VKITTI2 等多个具有挑战性的自动驾驶数据集上的大量实验表明，我们的方法在性能上优于当前最先进的方法。
