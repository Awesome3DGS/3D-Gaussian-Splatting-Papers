### DIG3D: Marrying Gaussian Splatting with Deformable Transformer for Single Image 3D Reconstruction

In this paper, we study the problem of 3D reconstruction from a single-view RGB image and propose a novel approach called DIG3D for 3D object reconstruction and novel view synthesis. Our method utilizes an encoder-decoder framework which generates 3D Gaussians in decoder with the guidance of depth-aware image features from encoder. In particular, we introduce the use of deformable transformer, allowing efficient and effective decoding through 3D reference point and multi-layer refinement adaptations. By harnessing the benefits of 3D Gaussians, our approach offers an efficient and accurate solution for 3D reconstruction from single-view images. We evaluate our method on the ShapeNet SRN dataset, getting PSNR of 24.21 and 24.98 in car and chair dataset, respectively. The result outperforming the recent method by around 2.25%, demonstrating the effectiveness of our method in achieving superior results.

在本文中，我们研究了从单视图 RGB 图像进行 3D 重建的问题，并提出了一种名为 DIG3D 的新方法，用于 3D 对象重建和新视角合成。我们的方法利用了一个编解码框架，在解码器中生成 3D 高斯分布，并由编码器提供的具有深度感知的图像特征指导。特别地，我们引入了可变形变换器的使用，通过 3D 参考点和多层次细化调整，实现了高效和有效的解码。通过利用 3D 高斯分布的优势，我们的方法为从单视图图像进行 3D 重建提供了一个高效且精确的解决方案。我们在 ShapeNet SRN 数据集上评估了我们的方法，在汽车和椅子数据集中分别获得了 24.21 和 24.98 的 PSNR 值。这一结果比最近的方法提高了约 2.25%，证明了我们的方法在实现优越结果方面的有效性。
