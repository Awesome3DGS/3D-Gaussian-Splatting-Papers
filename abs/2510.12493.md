### BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring

3D Gaussian Splatting has exhibited remarkable capabilities in 3D scene reconstruction. However, reconstructing high-quality 3D scenes from motion-blurred images caused by camera motion poses a significant challenge. The performance of existing 3DGS-based deblurring methods are limited due to their inherent mechanisms, such as extreme dependence on the accuracy of camera poses and inability to effectively control erroneous Gaussian primitives densification caused by motion blur. To solve these problems, we introduce a novel framework, Bi-Stage 3D Gaussian Splatting, to accurately reconstruct 3D scenes from motion-blurred images. BSGS contains two stages. First, Camera Pose Refinement roughly optimizes camera poses to reduce motion-induced distortions. Second, with fixed rough camera poses, Global Rigid Transformation further corrects motion-induced blur distortions. To alleviate multi-subframe gradient conflicts, we propose a subframe gradient aggregation strategy to optimize both stages. Furthermore, a space-time bi-stage optimization strategy is introduced to dynamically adjust primitive densification thresholds and prevent premature noisy Gaussian generation in blurred regions. Comprehensive experiments verify the effectiveness of our proposed deblurring method and show its superiority over the state of the arts.

三维高斯溅射（3D Gaussian Splatting）在三维场景重建方面展现出卓越能力。然而，针对因相机运动而产生的运动模糊图像进行高质量三维重建，仍然是一个极具挑战性的问题。现有基于3DGS的去模糊方法在性能上受限，主要原因在于其机制上的固有限制，例如对相机位姿精度的极度依赖，以及难以有效控制运动模糊导致的错误高斯基元过度密化问题。为解决上述难题，我们提出了一种新颖的双阶段三维高斯溅射框架（Bi-Stage 3D Gaussian Splatting，BSGS），用于从运动模糊图像中精确重建三维场景。BSGS包括两个阶段：第一阶段为相机位姿粗调，用于粗略优化相机姿态以减小运动引起的畸变；第二阶段在固定粗位姿的基础上，通过全局刚体变换进一步校正由运动模糊带来的失真。为缓解多子帧梯度冲突，我们提出了一种子帧梯度聚合策略，用于联合优化两个阶段。此外，我们还引入了时空双阶段优化策略，动态调整基元密化阈值，有效防止在模糊区域中过早生成噪声高斯点。大量实验验证了我们所提出的去模糊方法的有效性，并显示其在性能上显著优于现有最先进技术。
