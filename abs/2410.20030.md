### SCube: Instant Large-Scale Scene Reconstruction using VoxSplats

We present SCube, a novel method for reconstructing large-scale 3D scenes (geometry, appearance, and semantics) from a sparse set of posed images. Our method encodes reconstructed scenes using a novel representation VoxSplat, which is a set of 3D Gaussians supported on a high-resolution sparse-voxel scaffold. To reconstruct a VoxSplat from images, we employ a hierarchical voxel latent diffusion model conditioned on the input images followed by a feedforward appearance prediction model. The diffusion model generates high-resolution grids progressively in a coarse-to-fine manner, and the appearance network predicts a set of Gaussians within each voxel. From as few as 3 non-overlapping input images, SCube can generate millions of Gaussians with a 1024^3 voxel grid spanning hundreds of meters in 20 seconds. Past works tackling scene reconstruction from images either rely on per-scene optimization and fail to reconstruct the scene away from input views (thus requiring dense view coverage as input) or leverage geometric priors based on low-resolution models, which produce blurry results. In contrast, SCube leverages high-resolution sparse networks and produces sharp outputs from few views. We show the superiority of SCube compared to prior art using the Waymo self-driving dataset on 3D reconstruction and demonstrate its applications, such as LiDAR simulation and text-to-scene generation.

我们提出了 SCube，一种从稀疏的姿态图像集合中重建大规模三维场景（几何、外观和语义）的新方法。我们的方法通过一种新的表示方法 VoxSplat 对重建的场景进行编码，该表示是一组在高分辨率稀疏体素框架上支持的三维高斯。为了从图像重建 VoxSplat，我们采用了条件在输入图像上的分层体素潜在扩散模型，随后是一个前馈外观预测模型。扩散模型以粗到细的方式逐步生成高分辨率网格，而外观网络在每个体素内预测一组高斯。
SCube 能够仅从 3 张不重叠的输入图像中生成包含数百万个高斯的 1024³ 体素网格，覆盖数百米范围，并在 20 秒内完成生成。过去基于图像的场景重建工作要么依赖于每个场景的优化，无法重建远离输入视角的区域（因此需要密集的视角覆盖），要么依赖基于低分辨率模型的几何先验，导致结果模糊。相比之下，SCube 利用高分辨率稀疏网络，从少量视角生成清晰的输出。
我们在 Waymo 自动驾驶数据集上展示了 SCube 在三维重建方面相较于现有技术的优越性，并展示了其应用场景，如 LiDAR 模拟和文本生成场景。
