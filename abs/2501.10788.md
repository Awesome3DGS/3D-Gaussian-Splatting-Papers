### Decoupling Appearance Variations with 3D Consistent Features in Gaussian Splatting

Gaussian Splatting has emerged as a prominent 3D representation in novel view synthesis, but it still suffers from appearance variations, which are caused by various factors, such as modern camera ISPs, different time of day, weather conditions, and local light changes. These variations can lead to floaters and color distortions in the rendered images/videos. Recent appearance modeling approaches in Gaussian Splatting are either tightly coupled with the rendering process, hindering real-time rendering, or they only account for mild global variations, performing poorly in scenes with local light changes. In this paper, we propose DAVIGS, a method that decouples appearance variations in a plug-and-play and efficient manner. By transforming the rendering results at the image level instead of the Gaussian level, our approach can model appearance variations with minimal optimization time and memory overhead. Furthermore, our method gathers appearance-related information in 3D space to transform the rendered images, thus building 3D consistency across views implicitly. We validate our method on several appearance-variant scenes, and demonstrate that it achieves state-of-the-art rendering quality with minimal training time and memory usage, without compromising rendering speeds. Additionally, it provides performance improvements for different Gaussian Splatting baselines in a plug-and-play manner.

高斯点渲染已成为新视角合成中的一种重要 3D 表示方法，但仍然面临外观变化问题。这些变化由多种因素引起，例如现代相机 ISP、不同的时间、天气条件和局部光照变化。这些因素可能导致渲染图像或视频中出现浮点伪影和颜色失真问题。目前高斯点渲染中的外观建模方法通常与渲染过程紧密耦合，限制了实时渲染的实现；或者仅能处理轻微的全局变化，在存在局部光照变化的场景中表现较差。
为此，我们提出了 DAVIGS，一种解耦外观变化的高效、模块化方法。通过在图像级别（而非高斯级别）对渲染结果进行转换，我们的方法能够以最小的优化时间和内存开销建模外观变化。此外，我们的方法在 3D 空间中收集与外观相关的信息，用于对渲染图像进行转换，从而隐式地在视角之间建立 3D 一致性。
我们在多个外观变化场景中验证了该方法，结果表明 DAVIGS 在实现最先进渲染质量的同时，显著减少了训练时间和内存使用，并且不影响渲染速度。此外，它还能以模块化的方式为不同的高斯点渲染基线方法带来性能改进。
