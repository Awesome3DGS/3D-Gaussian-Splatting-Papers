### Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting

3D reconstruction from in-the-wild images remains a challenging task due to inconsistent lighting conditions and transient distractors. Existing methods typically rely on heuristic strategies to handle the low-quality training data, which often struggle to produce stable and consistent reconstructions, frequently resulting in visual artifacts. In this work, we propose Asymmetric Dual 3DGS, a novel framework that leverages the stochastic nature of these artifacts: they tend to vary across different training runs due to minor randomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS) models in parallel, enforcing a consistency constraint that encourages convergence on reliable scene geometry while suppressing inconsistent artifacts. To prevent the two models from collapsing into similar failure modes due to confirmation bias, we introduce a divergent masking strategy that applies two complementary masks: a multi-cue adaptive mask and a self-supervised soft mask, which leads to an asymmetric training process of the two models, reducing shared error modes. In addition, to improve the efficiency of model training, we introduce a lightweight variant called Dynamic EMA Proxy, which replaces one of the two models with a dynamically updated Exponential Moving Average (EMA) proxy, and employs an alternating masking strategy to preserve divergence. Extensive experiments on challenging real-world datasets demonstrate that our method consistently outperforms existing approaches while achieving high efficiency.

在自然环境下的图像中进行三维重建仍是一项具有挑战性的任务，主要由于光照条件不一致和瞬时干扰物的存在。现有方法通常依赖启发式策略来应对低质量的训练数据，但往往难以生成稳定、一致的重建结果，容易产生视觉伪影。
本文提出了一种新颖的框架 Asymmetric Dual 3DGS，利用这些伪影的随机性特征：由于微小的随机扰动，不同训练轮次中伪影的表现往往各不相同。具体而言，我们的方法并行训练两个 3D Gaussian Splatting（3DGS）模型，并引入一致性约束，以促使模型在可靠的场景几何结构上收敛，同时抑制不一致的伪影。
为避免两个模型因确认偏差而陷入相似的失败模式，我们提出了分歧掩码策略，即分别施加两个互补的掩码：一个是多线索自适应掩码，另一个是自监督软掩码，从而形成两个模型的不对称训练过程，减少共享误差模式。
此外，为提升训练效率，我们引入了一种轻量级变体 Dynamic EMA Proxy，通过动态更新的指数移动平均（EMA）代理模型替代其中一个模型，并采用交替掩码策略以保持模型之间的分歧。
在多个具有挑战性的真实数据集上的大量实验证明，本文方法在保持高效率的同时，性能稳定且显著优于现有方法。
