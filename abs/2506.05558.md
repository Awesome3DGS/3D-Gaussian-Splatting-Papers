### On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images

Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy reconstruction from photos, enabling free-viewpoint navigation. Nonetheless, pose estimation using Structure from Motion and 3DGS optimization can still each take between minutes and hours of computation after capture is complete. SLAM methods combined with 3DGS are fast but struggle with wide camera baselines and large scenes. We present an on-the-fly method to produce camera poses and a trained 3DGS immediately after capture. Our method can handle dense and wide-baseline captures of ordered photo sequences and large-scale scenes. To do this, we first introduce fast initial pose estimation, exploiting learned features and a GPU-friendly mini bundle adjustment. We then introduce direct sampling of Gaussian primitive positions and shapes, incrementally spawning primitives where required, significantly accelerating training. These two efficient steps allow fast and robust joint optimization of poses and Gaussian primitives. Our incremental approach handles large-scale scenes by introducing scalable radiance field construction, progressively clustering 3DGS primitives, storing them in anchors, and offloading them from the GPU. Clustered primitives are progressively merged, keeping the required scale of 3DGS at any viewpoint. We evaluate our solution on a variety of datasets and show that our solution can provide on-the-fly processing of all the capture scenarios and scene sizes we target while remaining competitive with other methods that only handle specific capture styles or scene sizes in speed, image quality, or both.

辐射场方法（如三维高斯泼洒，3D Gaussian Splatting，3DGS）支持从照片中轻松重建三维场景，实现自由视角导航。然而，基于结构光恢复（Structure from Motion）的相机位姿估计以及 3DGS 优化，通常仍需在采集完成后花费数分钟至数小时的计算时间。尽管将 SLAM 方法与 3DGS 结合可以加快处理速度，但在处理大视差相机基线或大规模场景时往往表现不佳。
为此，本文提出了一种即时生成相机位姿与训练完成的 3DGS 场景的方法。该方法可应对有序图像序列的密集、大视差采集场景，并适用于大规模场景重建。
具体做法包括两大核心改进：首先，我们引入了基于学习特征的快速初始位姿估计方法，并结合 GPU 友好的小规模光束调整（mini bundle adjustment），以实现高效的初始对齐；其次，我们提出了对高斯基元的位置与形状的直接采样策略，在所需区域增量式生成基元，大幅加快训练速度。
这两个高效步骤使得我们能够快速且稳健地联合优化相机位姿与高斯基元。针对大规模场景，我们进一步提出了可扩展的辐射场构建策略：通过逐步对 3DGS 基元进行聚类，并将其存储为锚点（anchors），从而将其卸载出 GPU；聚类后的基元会被渐进式地融合，在任意视角下都可维持合理的重建规模。
我们在多个数据集上对该方法进行了评估，结果表明该方案能够在目标采集场景和场景规模下实现即时处理，在处理速度与图像质量上均具有竞争力，优于那些仅能应对特定采集形式或规模的方法。
