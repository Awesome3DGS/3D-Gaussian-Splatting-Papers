### 4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation

Remarkable advances in recent 2D image and 3D shape generation have induced a significant focus on dynamic 4D content generation. However, previous 4D generation methods commonly struggle to maintain spatial-temporal consistency and adapt poorly to rapid temporal variations, due to the lack of effective spatial-temporal modeling. To address these problems, we propose a novel 4D generation network called 4DSTR, which modulates generative 4D Gaussian Splatting with spatial-temporal rectification. Specifically, temporal correlation across generated 4D sequences is designed to rectify deformable scales and rotations and guarantee temporal consistency. Furthermore, an adaptive spatial densification and pruning strategy is proposed to address significant temporal variations by dynamically adding or deleting Gaussian points with the awareness of their pre-frame movements. Extensive experiments demonstrate that our 4DSTR achieves state-of-the-art performance in video-to-4D generation, excelling in reconstruction quality, spatial-temporal consistency, and adaptation to rapid temporal movements.

近年来二维图像与三维形状生成领域的显著进展，推动了对动态四维内容生成的广泛关注。然而，受限于缺乏有效的时空建模，现有的四维生成方法通常难以保持时空一致性，并且对快速时间变化的适应能力较弱。为了解决上述问题，我们提出了一种新的四维生成网络 4DSTR，通过引入时空校正机制，对生成式四维高斯溅射（4D Gaussian Splatting）进行调制。具体而言，我们利用生成的四维序列之间的时间相关性，对可形变高斯的尺度与旋转进行校正，从而保证时间一致性。此外，我们提出了一种自适应的空间致密化与裁剪策略，在感知前一帧运动信息的基础上，动态地增加或删除高斯点，以应对剧烈的时间变化。大量实验结果表明，4DSTR 在视频到四维生成任务中达到了当前最先进的性能，在重建质量、时空一致性以及对快速时间运动的适应能力方面均表现出显著优势。
