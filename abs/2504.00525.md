### Robust LiDAR-Camera Calibration with 2D Gaussian Splatting

LiDAR-camera systems have become increasingly popular in robotics recently. A critical and initial step in integrating the LiDAR and camera data is the calibration of the LiDAR-camera system. Most existing calibration methods rely on auxiliary target objects, which often involve complex manual operations, whereas targetless methods have yet to achieve practical effectiveness. Recognizing that 2D Gaussian Splatting (2DGS) can reconstruct geometric information from camera image sequences, we propose a calibration method that estimates LiDAR-camera extrinsic parameters using geometric constraints. The proposed method begins by reconstructing colorless 2DGS using LiDAR point clouds. Subsequently, we update the colors of the Gaussian splats by minimizing the photometric loss. The extrinsic parameters are optimized during this process. Additionally, we address the limitations of the photometric loss by incorporating the reprojection and triangulation losses, thereby enhancing the calibration robustness and accuracy.

近年来，LiDAR-相机系统在机器人领域日益受到关注。将LiDAR与相机数据融合的关键且首要的步骤是对系统进行外参标定。目前大多数标定方法依赖于辅助的靶标物体，这类方法通常需要复杂的人工操作；而无靶标方法则尚未达到实用效果。
鉴于二维高斯投影（2D Gaussian Splatting, 2DGS）能够从相机图像序列中重建几何信息，我们提出了一种基于几何约束的LiDAR-相机外参估计方法。该方法首先利用LiDAR点云重建出无颜色的2DGS，随后通过最小化光度损失来更新高斯斑点的颜色，并在此过程中优化外参参数。
此外，为克服光度损失的局限性，我们进一步引入了重投影损失和三角化损失，从而有效提升标定的鲁棒性与精度。
