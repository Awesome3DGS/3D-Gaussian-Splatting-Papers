### NeAR: Coupled Neural Asset-Renderer Stack

Neural asset authoring and neural rendering have traditionally evolved as disjoint paradigms: one generates digital assets for fixed graphics pipelines, while the other maps conventional assets to images. However, treating them as independent entities limits the potential for end-to-end optimization in fidelity and consistency. In this paper, we bridge this gap with NeAR, a Coupled Neural Asset--Renderer Stack. We argue that co-designing the asset representation and the renderer creates a robust "contract" for superior generation. On the asset side, we introduce the Lighting-Homogenized SLAT (LH-SLAT). Leveraging a rectified-flow model, NeAR lifts casually lit single images into a canonical, illumination-invariant latent space, effectively suppressing baked-in shadows and highlights. On the renderer side, we design a lighting-aware neural decoder tailored to interpret these homogenized latents. Conditioned on HDR environment maps and camera views, it synthesizes relightable 3D Gaussian splats in real-time without per-object optimization. We validate NeAR on four tasks: (1) G-buffer-based forward rendering, (2) random-lit reconstruction, (3) unknown-lit relighting, and (4) novel-view relighting. Extensive experiments demonstrate that our coupled stack outperforms state-of-the-art baselines in both quantitative metrics and perceptual quality. We hope this coupled asset-renderer perspective inspires future graphics stacks that view neural assets and renderers as co-designed components instead of independent entities.

神经资产生成与神经渲染传统上被视为两个独立发展的范式：前者为固定图形管线生成数字资产，后者则将传统资产映射为图像。然而，将二者作为彼此独立的模块处理，限制了在保真度与一致性上的端到端优化潜力。为此，本文提出 NeAR（Coupled Neural Asset--Renderer Stack），一种耦合的神经资产与渲染器框架。我们认为，资产表示与渲染器的协同设计能够构建更稳健的“契约”，从而实现更优的生成质量。在资产端，我们提出了光照归一化的 SLAT（Lighting-Homogenized SLAT，简称 LH-SLAT），利用整流流模型将自然光照下的单张图像提升至一个标准化、对光照不敏感的潜空间，从而有效抑制烘焙阴影与高光。在渲染端，我们设计了一个具备光照感知能力的神经解码器，专用于解析上述归一化潜空间。该解码器结合 HDR 环境贴图与相机视角，能够实时合成可重光照的三维高斯溅射表示，且无需每个物体进行独立优化。我们在四项任务中验证了 NeAR 的有效性：（1）基于 G-buffer 的前向渲染；（2）随机光照下的重建；（3）未知光照下的重光照；（4）新视角下的重光照。大量实验证明，该耦合框架在定量指标与感知质量方面均显著优于当前最先进的基线方法。我们希望这一资产与渲染器协同设计的视角，能启发未来神经图形系统将二者作为共同构建的组成部分，而非彼此孤立的单元。
