### Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image

Generating realistic 3D objects from single-view images requires natural appearance, 3D consistency, and the ability to capture multiple plausible interpretations of unseen regions. Existing approaches often rely on fine-tuning pretrained 2D diffusion models or directly generating 3D information through fast network inference or 3D Gaussian Splatting, but their results generally suffer from poor multiview consistency and lack geometric detail. To takle these issues, we present a novel method that seamlessly integrates geometry and perception priors without requiring additional model training to reconstruct detailed 3D objects from a single image. Specifically, we train three different Gaussian branches initialized from the geometry prior, perception prior and Gaussian noise, respectively. The geometry prior captures the rough 3D shapes, while the perception prior utilizes the 2D pretrained diffusion model to enhance multiview information. Subsequently, we refine 3D Gaussian branches through mutual interaction between geometry and perception priors, further enhanced by a reprojection-based strategy that enforces depth consistency. Experiments demonstrate the higher-fidelity reconstruction results of our method, outperforming existing methods on novel view synthesis and 3D reconstruction, demonstrating robust and consistent 3D object generation.

从单视图图像生成逼真的三维物体，需要具备自然的外观表现、三维一致性，以及对不可见区域进行多种合理推断的能力。现有方法通常依赖于对预训练的二维扩散模型进行微调，或通过快速网络推理或三维高斯投影（3D Gaussian Splatting）直接生成三维信息，但这些方法普遍存在多视角一致性差、几何细节不足的问题。为了解决这些问题，我们提出了一种新颖的方法，在无需额外模型训练的前提下，实现几何先验与感知先验的无缝融合，从而从单张图像中重建出细节丰富的三维物体。具体而言，我们设计了三个不同的高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验用于捕捉粗略的三维形状，感知先验则利用预训练的二维扩散模型增强多视角信息。随后，我们通过几何与感知先验之间的相互作用对三维高斯分支进行联合优化，并引入基于重投影的一致性策略以强化深度一致性。实验表明，该方法在新视角合成和三维重建任务中均优于现有方法，能够实现稳健且一致的高保真三维物体生成。
