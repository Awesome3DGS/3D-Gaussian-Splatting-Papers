### ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars

The introduction of 3D Gaussian blendshapes has enabled the real-time reconstruction of animatable head avatars from monocular video. Toonify, a StyleGAN-based framework, has become widely used for facial image stylization. To extend Toonify for synthesizing diverse stylized 3D head avatars using Gaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB. In Stage 1 (stylized video generation), we employ an improved StyleGAN to generate the stylized video from the input video frames, which addresses the limitation of cropping aligned faces at a fixed resolution as preprocessing for normal StyleGAN. This process provides a more stable video, which enables Gaussian blendshapes to better capture the high-frequency details of the video frames, and efficiently generate high-quality animation in the next stage. In Stage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head model and a set of expression blendshapes from the generated video. By combining the neutral head model with expression blendshapes, ToonifyGB can efficiently render stylized avatars with arbitrary expressions. We validate the effectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane and Pixar.

3D 高斯形变模型（Gaussian Blendshapes） 的引入，使得从单目视频中实时重建可动画的人头头像成为可能。而基于 StyleGAN 的 Toonify 框架已被广泛应用于人脸图像的风格化处理。为将 Toonify 扩展至支持利用高斯形变模型生成多样化风格的三维人头头像，我们提出了一种高效的两阶段框架——ToonifyGB。
在**第一阶段（风格化视频生成）**中，我们采用改进版的 StyleGAN 从输入视频帧生成风格化视频。与普通 StyleGAN 需要将人脸对齐后裁剪为固定分辨率不同，我们的方法绕过了这一预处理限制，生成的视频更稳定，从而使得后续的高斯形变能够更好地捕捉视频帧中的高频细节，并高效地支持下一阶段的高质量动画生成。
在第二阶段（高斯形变合成）中，我们从生成的视频中学习一个风格化的中性头部模型与一组表情形变基元（expression blendshapes）。通过将中性头部与表情形变结合，ToonifyGB 可以高效渲染具有任意表情的风格化三维头像。
我们在基准数据集上使用两种风格（**《双城之战》（Arcane）**和 皮克斯（Pixar））对 ToonifyGB 进行了验证，实验结果证明了该方法的有效性。
