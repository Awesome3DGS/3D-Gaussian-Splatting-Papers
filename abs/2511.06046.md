### StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video

Streaming free-viewpoint video~(FVV) in real-time still faces significant challenges, particularly in training, rendering, and transmission efficiency. Harnessing superior performance of 3D Gaussian Splatting~(3DGS), recent 3DGS-based FVV methods have achieved notable breakthroughs in both training and rendering. However, the storage requirements of these methods can reach up to 10MB per frame, making stream FVV in real-time impossible. To address this problem, we propose a novel FVV representation, dubbed StreamSTGS, designed for real-time streaming. StreamSTGS represents a dynamic scene using canonical 3D Gaussians, temporal features, and a deformation field. For high compression efficiency, we encode canonical Gaussian attributes as 2D images and temporal features as a video. This design not only enables real-time streaming, but also inherently supports adaptive bitrate control based on network condition without any extra training. Moreover, we propose a sliding window scheme to aggregate adjacent temporal features to learn local motions, and then introduce a transformer-guided auxiliary training module to learn global motions. On diverse FVV benchmarks, StreamSTGS demonstrates competitive performance on all metrics compared to state-of-the-art methods. Notably, StreamSTGS increases the PSNR by an average of 1dB while reducing the average frame size to just 170KB.

实时流式自由视角视频（Free-Viewpoint Video，FVV）仍然面临诸多挑战，尤其是在训练效率、渲染效率以及传输效率方面。得益于三维高斯溅射（3D Gaussian Splatting，3DGS）的优越性能，近期基于 3DGS 的 FVV 方法在训练与渲染方面均取得了显著突破。然而，这类方法的存储开销可高达每帧 10MB，使得实时流式 FVV 几乎不可行。为了解决这一问题，我们提出了一种新的 FVV 表示方法，称为 StreamSTGS，专为实时流式传输而设计。StreamSTGS 通过规范化的三维高斯、时间特征以及形变场来表示动态场景。为了实现高效压缩，我们将规范化高斯的属性编码为二维图像，并将时间特征编码为视频。这一设计不仅支持实时流式传输，还能够在无需额外训练的情况下，根据网络状况自然地实现自适应码率控制。此外，我们提出了一种滑动窗口机制，用于聚合相邻的时间特征以学习局部运动，并进一步引入一个由 Transformer 引导的辅助训练模块来建模全局运动。在多个 FVV 基准数据集上的实验结果表明，StreamSTGS 在各项指标上均展现出与当前最先进方法相当的性能。值得注意的是，StreamSTGS 在将平均单帧大小压缩至仅 170KB 的同时，使 PSNR 平均提升了约 1dB。
