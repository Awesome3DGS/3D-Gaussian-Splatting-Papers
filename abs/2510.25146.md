### EA3D: Online Open-World 3D Object Extraction from Streaming Videos

Current 3D scene understanding methods are limited by offline-collected multi-view data or pre-constructed 3D geometry. In this paper, we present ExtractAnything3D (EA3D), a unified online framework for open-world 3D object extraction that enables simultaneous geometric reconstruction and holistic scene understanding. Given a streaming video, EA3D dynamically interprets each frame using vision-language and 2D vision foundation encoders to extract object-level knowledge. This knowledge is integrated and embedded into a Gaussian feature map via a feed-forward online update strategy. We then iteratively estimate visual odometry from historical frames and incrementally update online Gaussian features with new observations. A recurrent joint optimization module directs the model's attention to regions of interest, simultaneously enhancing both geometric reconstruction and semantic understanding. Extensive experiments across diverse benchmarks and tasks, including photo-realistic rendering, semantic and instance segmentation, 3D bounding box and semantic occupancy estimation, and 3D mesh generation, demonstrate the effectiveness of EA3D. Our method establishes a unified and efficient framework for joint online 3D reconstruction and holistic scene understanding, enabling a broad range of downstream tasks.

当前的三维场景理解方法通常依赖离线采集的多视角数据或预构建的三维几何信息，存在适应性差和灵活性不足的问题。为此，我们提出了 ExtractAnything3D（EA3D），一个面向开放世界的统一在线三维目标提取框架，能够同时完成几何重建与整体场景理解。面对视频流输入，EA3D 利用视觉-语言与二维视觉基础模型对每一帧图像进行动态解析，提取目标级别的知识，并通过前馈式在线更新策略将这些知识集成并嵌入至高斯特征图中。随后，系统通过历史帧迭代估计视觉里程计，并用新的观测不断更新在线高斯特征。一个循环联合优化模块引导模型聚焦于兴趣区域，从而同时提升几何重建的精度与语义理解的完整性。我们在多个基准数据集和任务上进行了广泛实验证明，包括照片级真实感渲染、语义与实例分割、三维边界框与语义占据估计、三维网格生成等。结果表明，EA3D 在多个方面均展现出卓越性能，成功构建了一个统一高效的三维在线重建与整体场景理解框架，支持多样的下游任务应用。
