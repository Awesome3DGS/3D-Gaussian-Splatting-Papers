### VicaSplat: A Single Run is All You Need for 3D Gaussian Splatting and Camera Estimation from Unposed Video Frames

We present VicaSplat, a novel framework for joint 3D Gaussians reconstruction and camera pose estimation from a sequence of unposed video frames, which is a critical yet underexplored task in real-world 3D applications. The core of our method lies in a novel transformer-based network architecture. In particular, our model starts with an image encoder that maps each image to a list of visual tokens. All visual tokens are concatenated with additional inserted learnable camera tokens. The obtained tokens then fully communicate with each other within a tailored transformer decoder. The camera tokens causally aggregate features from visual tokens of different views, and further modulate them frame-wisely to inject view-dependent features. 3D Gaussian splats and camera pose parameters can then be estimated via different prediction heads. Experiments show that VicaSplat surpasses baseline methods for multi-view inputs, and achieves comparable performance to prior two-view approaches. Remarkably, VicaSplat also demonstrates exceptional cross-dataset generalization capability on the ScanNet benchmark, achieving superior performance without any fine-tuning.

我们提出了 VicaSplat，这是一个新的框架，用于从一系列无姿态视频帧中联合进行 3D 高斯重建和相机姿态估计，这是一个在现实世界 3D 应用中至关重要但尚未充分探索的任务。我们方法的核心在于一个新型的基于 Transformer 的网络架构。具体来说，我们的模型从一个图像编码器开始，将每个图像映射到一组视觉标记。所有视觉标记与额外插入的可学习相机标记一起进行拼接。然后，获得的标记在一个定制的 Transformer 解码器中完全相互通信。相机标记通过因果聚合来自不同视角的视觉标记特征，并进一步按帧调节这些特征，以注入视角依赖特征。随后，可以通过不同的预测头估计 3D 高斯溅射和相机姿态参数。实验表明，VicaSplat 在多视角输入下超越了基线方法，并且与先前的双视角方法性能相当。值得注意的是，VicaSplat 在 ScanNet 基准测试上还展示了卓越的跨数据集泛化能力，且无需任何微调即可获得优异的表现。
