### MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction

We present Multi-Baseline Gaussian Splatting (MuRF), a generalized feed-forward approach for novel view synthesis that effectively handles diverse baseline settings, including sparse input views with both small and large baselines. Specifically, we integrate features from Multi-View Stereo (MVS) and Monocular Depth Estimation (MDE) to enhance feature representations for generalizable reconstruction. Next, We propose a projection-and-sampling mechanism for deep depth fusion, which constructs a fine probability volume to guide the regression of the feature map. Furthermore, We introduce a reference-view loss to improve geometry and optimization efficiency. We leverage 3D Gaussian representations to accelerate training and inference time while enhancing rendering quality. MuRF achieves state-of-the-art performance across multiple baseline settings and diverse scenarios ranging from simple objects (DTU) to complex indoor and outdoor scenes (RealEstate10K). We also demonstrate promising zero-shot performance on the LLFF and Mip-NeRF 360 datasets.

我们提出了多基线高斯溅射（Multi-Baseline Gaussian Splatting，MuRF），这是一种通用的前向新视角合成方法，能够有效处理包括小基线和大基线稀疏输入视图在内的多种基线设置。具体而言，我们融合了多视图立体（Multi-View Stereo, MVS）和单目深度估计（Monocular Depth Estimation, MDE）的特征，以增强特征表示能力，从而实现更强的重建泛化性。随后，我们提出了一种投影与采样机制进行深度融合，构建精细的概率体以引导特征图的回归。此外，我们引入了参考视图损失，以提升几何质量和优化效率。我们利用三维高斯表示加速训练与推理的同时提升渲染质量。MuRF 在多种基线设置及从简单物体（DTU）到复杂室内外场景（RealEstate10K）的多样化场景中均实现了最先进的性能。我们还在 LLFF 和 Mip-NeRF 360 数据集上展示了具有潜力的零样本表现。
