### Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views

Neural rendering has demonstrated remarkable success in high-quality 3D neural reconstruction and novel view synthesis with dense input views and accurate poses. However, applying it to extremely sparse, unposed views in unbounded 360° scenes remains a challenging problem. In this paper, we propose a novel neural rendering framework to accomplish the unposed and extremely sparse-view 3D reconstruction in unbounded 360° scenes. To resolve the spatial ambiguity inherent in unbounded scenes with sparse input views, we propose a layered Gaussian-based representation to effectively model the scene with distinct spatial layers. By employing a dense stereo reconstruction model to recover coarse geometry, we introduce a layer-specific bootstrap optimization to refine the noise and fill occluded regions in the reconstruction. Furthermore, we propose an iterative fusion of reconstruction and generation alongside an uncertainty-aware training approach to facilitate mutual conditioning and enhancement between these two processes. Comprehensive experiments show that our approach outperforms existing state-of-the-art methods in terms of rendering quality and surface reconstruction accuracy. Project page: this https URL

神经渲染在高质量三维神经重建和新视角合成任务中已取得显著成果，尤其是在输入视角稠密且相机位姿精确的条件下。然而，将其应用于位姿未知且极度稀疏视角的无界360°场景仍是一项具有挑战性的问题。本文提出了一种新颖的神经渲染框架，旨在实现无界360°场景中无位姿、极稀疏视角下的三维重建。
为解决稀疏输入视角下无界场景中固有的空间歧义问题，我们提出了一种基于分层高斯的表示方法，能够有效地以不同的空间层次建模场景结构。通过引入稠密立体重建模型以获取粗略几何信息，我们进一步设计了面向层的引导优化策略（bootstrap optimization），用于细化重建中的噪声并补全遮挡区域。
此外，我们提出了重建与生成过程的迭代融合机制，并结合基于不确定性的训练策略，以实现两者之间的相互引导与增强。
大量实验结果表明，我们的方法在渲染质量与表面重建精度方面均优于当前最先进的技术。
