### Efficient multi-view training for 3D Gaussian Splatting

3D Gaussian Splatting (3DGS) has emerged as a preferred choice alongside Neural Radiance Fields (NeRF) in inverse rendering due to its superior rendering speed. Currently, the common approach in 3DGS is to utilize "single-view" mini-batch training, where only one image is processed per iteration, in contrast to NeRF's "multi-view" mini-batch training, which leverages multiple images. We observe that such single-view training can lead to suboptimal optimization due to increased variance in mini-batch stochastic gradients, highlighting the necessity for multi-view training. However, implementing multi-view training in 3DGS poses challenges. Simply rendering multiple images per iteration incurs considerable overhead and may result in suboptimal Gaussian densification due to its reliance on single-view assumptions. To address these issues, we modify the rasterization process to minimize the overhead associated with multi-view training and propose a 3D distance-aware D-SSIM loss and multi-view adaptive density control that better suits multi-view scenarios. Our experiments demonstrate that the proposed methods significantly enhance the performance of 3DGS and its variants, freeing 3DGS from the constraints of single-view training.

三维高斯溅射（3DGS）凭借其卓越的渲染速度，已与神经辐射场（NeRF）一道成为逆向渲染中的优选方案。目前，3DGS 的常见训练方式是采用“单视角”小批量训练，即每次迭代仅处理一张图像；而 NeRF 则采用“多视角”小批量训练，在每次迭代中利用多张图像。我们观察到，这种单视角训练会因小批量随机梯度方差增加而导致次优优化结果，这凸显了多视角训练的必要性。然而，在 3DGS 中实现多视角训练面临挑战：简单地在每次迭代中渲染多张图像会带来显著的计算开销，并且可能由于依赖单视角假设而导致高斯加密效果欠佳。为解决这些问题，我们修改了光栅化过程，以最大限度减少多视角训练的额外开销，并提出了**三维距离感知的 D-SSIM 损失**以及**多视角自适应密度控制**，更好地适配多视角训练场景。实验结果表明，所提方法显著提升了 3DGS 及其变体的性能，使其摆脱了单视角训练的限制。
