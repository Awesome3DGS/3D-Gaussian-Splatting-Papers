### MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models

Recent advances in generalizable 3D Gaussian Splatting have demonstrated promising results in real-time high-fidelity rendering without per-scene optimization, yet existing approaches still struggle to handle unfamiliar visual content during inference on novel scenes due to limited generalizability. To address this challenge, we introduce MonoSplat, a novel framework that leverages rich visual priors from pre-trained monocular depth foundation models for robust Gaussian reconstruction. Our approach consists of two key components: a Mono-Multi Feature Adapter that transforms monocular features into multi-view representations, coupled with an Integrated Gaussian Prediction module that effectively fuses both feature types for precise Gaussian generation. Through the Adapter's lightweight attention mechanism, features are seamlessly aligned and aggregated across views while preserving valuable monocular priors, enabling the Prediction module to generate Gaussian primitives with accurate geometry and appearance. Through extensive experiments on diverse real-world datasets, we convincingly demonstrate that MonoSplat achieves superior reconstruction quality and generalization capability compared to existing methods while maintaining computational efficiency with minimal trainable parameters.

近期在具备泛化能力的3D高斯投影（3D Gaussian Splatting）方面的研究取得了显著进展，展示了无需针对单个场景进行优化即可实现实时高保真渲染的潜力。然而，现有方法在面对新颖场景中的陌生视觉内容时，仍因泛化能力有限而表现不佳。为应对这一挑战，我们提出了 MonoSplat，一个新颖的框架，利用预训练单目深度基础模型中丰富的视觉先验，实现鲁棒的高斯重建。
我们的方法包含两个关键组件：一个Mono-Multi特征适配器，用于将单目特征转换为多视图表示；以及一个集成高斯预测模块，用于高效融合这两类特征，从而精确生成高斯基元。适配器中轻量的注意力机制使得不同视角之间的特征能够无缝对齐与聚合，同时保留关键的单目先验，使预测模块能够生成具备准确几何结构与外观的高斯基元。
在多个真实世界数据集上的大量实验表明，MonoSplat 在保持计算效率和极少可训练参数的前提下，显著优于现有方法，在重建质量和泛化能力方面均表现出色。
