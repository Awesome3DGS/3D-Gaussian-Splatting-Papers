### CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos

Recently, photo-realistic novel view synthesis from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered widespread attention due to their superior performance. However, most works rely on low dynamic range (LDR) images, which limits the capturing of richer scene details. Some prior works have focused on high dynamic range (HDR) scene reconstruction, typically require capturing of multi-view sharp images with different exposure times at fixed camera positions during exposure times, which is time-consuming and challenging in practice. For a more flexible data acquisition, we propose a one-stage method: \textbf{CasualHDRSplat} to easily and robustly reconstruct the 3D HDR scene from casually captured videos with auto-exposure enabled, even in the presence of severe motion blur and varying unknown exposure time. \textbf{CasualHDRSplat} contains a unified differentiable physical imaging model which first applies continuous-time trajectory constraint to imaging process so that we can jointly optimize exposure time, camera response function (CRF), camera poses, and sharp 3D HDR scene. Extensive experiments demonstrate that our approach outperforms existing methods in terms of robustness and rendering quality.

近年来，从多视图图像中合成真实感新视角图像的方法（如 NeRF 和 3D Gaussian Splatting, 3DGS）因其卓越性能而受到广泛关注。然而，大多数方法依赖于低动态范围（LDR）图像，这限制了对更丰富场景细节的捕捉。部分已有工作尝试进行高动态范围（HDR）场景重建，通常需要在曝光期间、固定相机位置下拍摄多视角、不同曝光时间的清晰图像，这在实际中操作繁琐、成本较高。
为实现更灵活的数据采集，我们提出了一种单阶段方法：CasualHDRSplat，能够从启用自动曝光、随手拍摄的视频中，稳健地重建三维 HDR 场景，即便存在严重的运动模糊与未知变化的曝光时间也能应对自如。CasualHDRSplat 包含一个统一的可微物理成像模型，首先在成像过程中引入连续时间轨迹约束，从而可联合优化曝光时间、相机响应函数（CRF）、相机姿态以及清晰的三维 HDR 场景。
大量实验证明，我们的方法在鲁棒性与渲染质量方面均优于现有方法。
