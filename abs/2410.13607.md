### DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering

Dynamic scenes rendering is an intriguing yet challenging problem. Although current methods based on NeRF have achieved satisfactory performance, they still can not reach real-time levels. Recently, 3D Gaussian Splatting (3DGS) has gar?nered researchers attention due to their outstanding rendering quality and real?time speed. Therefore, a new paradigm has been proposed: defining a canonical 3D gaussians and deforming it to individual frames in deformable fields. How?ever, since the coordinates of canonical 3D gaussians are filled with noise, which can transfer noise into the deformable fields, and there is currently no method that adequately considers the aggregation of 4D information. Therefore, we pro?pose Denoised Deformable Network with Temporal-Spatial Aggregation for Dy?namic Scene Rendering (DN-4DGS). Specifically, a Noise Suppression Strategy is introduced to change the distribution of the coordinates of the canonical 3D gaussians and suppress noise. Additionally, a Decoupled Temporal-Spatial Ag?gregation Module is designed to aggregate information from adjacent points and frames. Extensive experiments on various real-world datasets demonstrate that our method achieves state-of-the-art rendering quality under a real-time level.

动态场景渲染是一个引人入胜但具有挑战性的问题。尽管基于NeRF的当前方法已取得了令人满意的表现，但它们仍无法达到实时渲染的水平。最近，3D高斯散射（3DGS）因其卓越的渲染质量和实时速度而引起了研究者的关注。因此，一种新的范式被提出：定义标准的3D高斯并将其变形应用到可变形场中的各个帧。然而，由于标准3D高斯的坐标充满噪声，这些噪声可能会传递到可变形场中，目前还没有方法能够充分考虑4D信息的聚合。为了解决这个问题，我们提出了带有时空聚合的去噪可变形网络用于动态场景渲染（DN-4DGS）。具体来说，我们引入了一种噪声抑制策略，以改变标准3D高斯坐标的分布并抑制噪声。此外，我们设计了一个解耦时空聚合模块，以从相邻点和帧中聚合信息。通过在多个真实世界数据集上的大量实验，我们的方法在实时水平下实现了最先进的渲染质量。

