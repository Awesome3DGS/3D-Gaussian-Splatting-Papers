### WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction

3D Gaussian Splatting (3DGS) has become a powerful representation for image-based object reconstruction, yet its performance drops sharply in sparse-view settings. Prior works address this limitation by employing diffusion models to repair corrupted renders, subsequently using them as pseudo ground truths for later optimization. While effective, such approaches incur heavy computation from the diffusion fine-tuning and repair steps. We present WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object reconstruction. Our key idea is to shift diffusion into the wavelet domain: diffusion is applied only to the low-resolution LL subband, while high-frequency subbands are refined with a lightweight network. We further propose an efficient online random masking strategy to curate training pairs for diffusion fine-tuning, replacing the commonly used, but inefficient, leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360 and OmniObject3D, show WaveletGaussian achieves competitive rendering quality while substantially reducing training time.

三维高斯溅射（3D Gaussian Splatting，3DGS）已成为基于图像的物体重建中一种强大的表示方式，但在稀疏视角设置下，其性能会急剧下降。以往方法通常通过扩散模型修复受损渲染结果，并将其作为伪真值用于后续优化。虽然此类方法有效，但扩散微调与修复步骤带来了高昂的计算开销。为此，我们提出了 WaveletGaussian，一种更高效的稀疏视角三维高斯物体重建框架。其核心思想是将扩散过程转移到小波域中：扩散仅作用于低分辨率的 LL 子带，而高频子带则通过轻量级网络进行精细化补偿。此外，我们提出了一种高效的在线随机掩码策略，用于生成扩散微调的训练对，替代常用但低效的留一法（leave-one-out）策略。在两个基准数据集 Mip-NeRF 360 和 OmniObject3D 上的实验表明，WaveletGaussian 在显著降低训练时间的同时，仍能实现与最先进方法相当的渲染质量。
