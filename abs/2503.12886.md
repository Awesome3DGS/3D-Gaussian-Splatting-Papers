### RGBAvatar: Reduced Gaussian Blendshapes for Online Modeling of Head Avatars

We present Reduced Gaussian Blendshapes Avatar (RGBAvatar), a method for reconstructing photorealistic, animatable head avatars at speeds sufficient for on-the-fly reconstruction. Unlike prior approaches that utilize linear bases from 3D morphable models (3DMM) to model Gaussian blendshapes, our method maps tracked 3DMM parameters into reduced blendshape weights with an MLP, leading to a compact set of blendshape bases. The learned compact base composition effectively captures essential facial details for specific individuals, and does not rely on the fixed base composition weights of 3DMM, leading to enhanced reconstruction quality and higher efficiency. To further expedite the reconstruction process, we develop a novel color initialization estimation method and a batch-parallel Gaussian rasterization process, achieving state-of-the-art quality with training throughput of about 630 images per second. Moreover, we propose a local-global sampling strategy that enables direct on-the-fly reconstruction, immediately reconstructing the model as video streams in real time while achieving quality comparable to offline settings.

我们提出了减少高斯混合形状头像（RGBAvatar）的方法，用于以足够的速度进行即时重建，重建出逼真的、可动画化的头部头像。与先前的方法不同，先前的方法使用来自三维可变形模型（3DMM）的线性基来建模高斯混合形状，而我们的方法通过使用多层感知器（MLP）将追踪到的3DMM参数映射到减少的混合形状权重，从而得到一组紧凑的混合形状基。学习到的紧凑基组合有效捕捉了特定个体的面部细节，并且不依赖于3DMM固定基组合的权重，从而提高了重建质量和效率。为了进一步加速重建过程，我们开发了一种新颖的颜色初始化估计方法和批量并行高斯光栅化过程，实现了最先进的质量，并且训练吞吐量约为每秒630张图像。此外，我们提出了一种局部-全局采样策略，使得能够直接进行即时重建，在实时视频流中立即重建模型，同时达到与离线设置相当的质量。
