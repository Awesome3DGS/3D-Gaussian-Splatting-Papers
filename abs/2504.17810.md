### SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos

Dynamic videos with small baseline motions are ubiquitous in daily life, especially on social media. However, these videos present a challenge to existing pose estimation frameworks due to ambiguous features, drift accumulation, and insufficient triangulation constraints. Gaussian splatting, which maintains an explicit representation for scenes, provides a reliable novel view rasterization when the viewpoint change is small. Inspired by this, we propose SmallGS, a camera pose estimation framework that is specifically designed for small-baseline videos. SmallGS optimizes sequential camera poses using Gaussian splatting, which reconstructs the scene from the first frame in each video segment to provide a stable reference for the rest. The temporal consistency of Gaussian splatting within limited viewpoint differences reduced the requirement of sufficient depth variations in traditional camera pose estimation. We further incorporate pretrained robust visual features, e.g. DINOv2, into Gaussian splatting, where high-dimensional feature map rendering enhances the robustness of camera pose estimation. By freezing the Gaussian splatting and optimizing camera viewpoints based on rasterized features, SmallGS effectively learns camera poses without requiring explicit feature correspondences or strong parallax motion. We verify the effectiveness of SmallGS in small-baseline videos in TUM-Dynamics sequences, which achieves impressive accuracy in camera pose estimation compared to MonST3R and DORID-SLAM for small-baseline videos in dynamic scenes.

日常生活中广泛存在具有小基线运动的动态视频，尤其在社交媒体中尤为常见。然而，由于特征模糊、误差累积以及三角化约束不足，这类视频对现有的位姿估计算法提出了挑战。Gaussian Splatting 通过对场景的显式表示，在视角变化较小时能实现稳定可靠的新视角渲染，激发了我们的方法设计。
本文提出 SmallGS，一个专为小基线视频设计的相机位姿估计框架。SmallGS 利用 Gaussian Splatting 优化连续帧的相机位姿，并以每个视频片段的首帧重建场景，作为后续帧的稳定参考。由于 Gaussian Splatting 在小视角变化内具有良好的时间一致性，SmallGS 可缓解传统方法对明显深度差异的依赖。
此外，我们将预训练的强鲁棒性视觉特征（如 DINOv2）融入 Gaussian Splatting，通过渲染高维特征图增强位姿估计的稳定性。在不更新高斯图元的前提下，仅基于特征图对相机位姿进行优化，SmallGS 无需显式特征匹配或强视差运动，即可有效学习相机运动。
我们在 TUM-Dynamics 数据集的小基线视频上验证了 SmallGS 的有效性，其相机位姿估计精度明显优于 MonST3R 和 DORID-SLAM 等现有方法，展现了在动态场景小基线视频下的强大表现。
