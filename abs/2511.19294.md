### DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting

This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.

本文针对当前三维高斯溅射（3DGS）方法的局限性，特别是其对自适应密度控制的依赖问题，提出了一种全新的预密集化（densify beforehand）策略。传统的自适应密度控制常会引入漂浮伪影并导致资源使用低效，而我们的方法在三维场景初始化阶段，通过融合稀疏的 LiDAR 数据与对应 RGB 图像的单目深度估计，生成更具信息性的初始点云。我们设计了一个 ROI 感知采样机制，优先保留在语义和几何上重要的区域，从而获得更高密度、更高保真度的点云表示，同时提升计算效率。通过在预处理阶段完成密度增强，我们绕过了原始流程中易引入冗余高斯的自适应密度机制，使得后续优化过程可聚焦于高斯基元的其他属性，如颜色、透明度与协方差，从而有效减少重叠并增强视觉质量。实验在四个新采集的数据集上进行，涵盖定量对比与消融分析，结果表明我们的方法在保持语义关注区域清晰重建的同时，大幅降低了资源消耗与训练时间，并在视觉效果上与当前最先进技术持平。
