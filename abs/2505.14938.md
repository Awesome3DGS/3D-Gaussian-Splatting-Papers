### Scan, Materialize, Simulate: A Generalizable Framework for Physically Grounded Robot Planning

Autonomous robots must reason about the physical consequences of their actions to operate effectively in unstructured, real-world environments. We present Scan, Materialize, Simulate (SMS), a unified framework that combines 3D Gaussian Splatting for accurate scene reconstruction, visual foundation models for semantic segmentation, vision-language models for material property inference, and physics simulation for reliable prediction of action outcomes. By integrating these components, SMS enables generalizable physical reasoning and object-centric planning without the need to re-learn foundational physical dynamics. We empirically validate SMS in a billiards-inspired manipulation task and a challenging quadrotor landing scenario, demonstrating robust performance on both simulated domain transfer and real-world experiments. Our results highlight the potential of bridging differentiable rendering for scene reconstruction, foundation models for semantic understanding, and physics-based simulation to achieve physically grounded robot planning across diverse settings.

自主机器人要在非结构化的真实环境中高效运行，必须能够推理其动作所带来的物理后果。我们提出了**Scan, Materialize, Simulate（SMS）**这一统一框架，该框架融合了用于精确场景重建的3D高斯投影（3D Gaussian Splatting）、用于语义分割的视觉基础模型、用于材质属性推断的视觉-语言模型，以及用于动作结果可靠预测的物理仿真模块。通过整合这些组件，SMS 实现了具备良好泛化能力的物理推理与面向物体的规划，而无需重新学习基础物理动力学。我们在一个受台球启发的操作任务和一个具有挑战性的四旋翼着陆场景中对 SMS 进行了实证验证，展现了其在模拟领域迁移与真实世界实验中的稳健性能。我们的结果突显了将可微渲染用于场景重建、将基础模型用于语义理解，以及将基于物理的仿真用于实现物理可解释机器人规划之间的协同潜力，从而在多样化环境中达成基于物理的机器人任务规划。
