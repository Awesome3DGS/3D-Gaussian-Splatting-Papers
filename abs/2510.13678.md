### FlashWorld: High-quality 3D Scene Generation within Seconds

We propose FlashWorld, a generative model that produces 3D scenes from a single image or text prompt in seconds, 10~100× faster than previous works while possessing superior rendering quality. Our approach shifts from the conventional multi-view-oriented (MV-oriented) paradigm, which generates multi-view images for subsequent 3D reconstruction, to a 3D-oriented approach where the model directly produces 3D Gaussian representations during multi-view generation. While ensuring 3D consistency, 3D-oriented method typically suffers poor visual quality. FlashWorld includes a dual-mode pre-training phase followed by a cross-mode post-training phase, effectively integrating the strengths of both paradigms. Specifically, leveraging the prior from a video diffusion model, we first pre-train a dual-mode multi-view diffusion model, which jointly supports MV-oriented and 3D-oriented generation modes. To bridge the quality gap in 3D-oriented generation, we further propose a cross-mode post-training distillation by matching distribution from consistent 3D-oriented mode to high-quality MV-oriented mode. This not only enhances visual quality while maintaining 3D consistency, but also reduces the required denoising steps for inference. Also, we propose a strategy to leverage massive single-view images and text prompts during this process to enhance the model's generalization to out-of-distribution inputs. Extensive experiments demonstrate the superiority and efficiency of our method.

我们提出了FlashWorld，一种能够在数秒内基于单张图像或文本提示生成三维场景的生成模型，其速度相比现有方法提升10到100倍，同时具备更优越的渲染质量。我们的方法突破了传统多视图导向（MV-oriented）范式——即先生成多视图图像再进行三维重建的流程，转而采用三维导向（3D-oriented）策略，在多视图生成阶段直接生成三维高斯表示。尽管3D导向方法能够保证三维一致性，但通常会带来较差的视觉质量。FlashWorld通过“双模态预训练 + 跨模态后训练”的方式，有效融合了两种范式的优点。具体而言，我们首先借助视频扩散模型的先验，预训练了一个支持MV导向与3D导向双模式的多视图扩散模型。在此基础上，我们提出了一种跨模态后训练蒸馏策略，将3D导向模式生成的分布与高质量MV导向模式对齐，从而在保持三维一致性的同时显著提升视觉质量，并减少推理过程中所需的去噪步数。此外，我们还提出了一种利用大规模单视图图像与文本提示的策略，以增强模型在处理分布外输入时的泛化能力。大量实验验证了我们方法在效率与质量上的显著优势。
