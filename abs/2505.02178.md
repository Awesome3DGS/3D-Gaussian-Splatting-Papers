### Sparfels: Fast Reconstruction from Sparse Unposed Imagery

We present a method for Sparse view reconstruction with surface element splatting that runs within 3 minutes on a consumer grade GPU. While few methods address sparse radiance field learning from noisy or unposed sparse cameras, shape recovery remains relatively underexplored in this setting. Several radiance and shape learning test-time optimization methods address the sparse posed setting by learning data priors or using combinations of external monocular geometry priors. Differently, we propose an efficient and simple pipeline harnessing a single recent 3D foundation model. We leverage its various task heads, notably point maps and camera initializations to instantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image correspondences to guide camera optimization midst 2DGS training. Key to our contribution is a novel formulation of splatted color variance along rays, which can be computed efficiently. Reducing this moment in training leads to more accurate shape reconstructions. We demonstrate state-of-the-art performances in the sparse uncalibrated setting in reconstruction and novel view benchmarks based on established multi-view datasets.

我们提出了一种基于表面元素泼溅的稀疏视角重建方法，可在消费级 GPU 上于 3 分钟内完成运行。尽管已有少数方法尝试从噪声或未标定的稀疏相机中学习稀疏辐射场，但在该设定下的形状恢复问题仍相对较少被研究。现有部分辐射场与形状学习方法主要针对已知位姿的稀疏设定，通过学习数据先验或结合外部单目几何先验来实现。
与之不同，我们提出了一种高效且简洁的重建流程，仅依赖一个最新的三维基础模型。我们利用该基础模型提供的多任务输出头，特别是点图（point maps）和相机初始化，用于构建并调整一个二维高斯泼溅（2D Gaussian Splatting, 2DGS）模型，同时利用图像间的对应关系来辅助训练过程中的相机优化。
我们工作的关键贡献之一是提出了一种新的射线上泼溅颜色方差公式化方法，该方法可高效计算并在训练过程中最小化，从而提升形状重建的精度。
在多个标准多视图数据集上进行的稀疏未标定设定下的重建与新视角合成测试表明，我们的方法在精度上达到了当前最先进水平。
