### ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects

Articulated object manipulation remains a critical challenge in robotics due to the complex kinematic constraints and the limited physical reasoning of existing methods. In this work, we introduce ArtGS, a novel framework that extends 3D Gaussian Splatting (3DGS) by integrating visual-physical modeling for articulated object understanding and interaction. ArtGS begins with multi-view RGB-D reconstruction, followed by reasoning with a vision-language model (VLM) to extract semantic and structural information, particularly the articulated bones. Through dynamic, differentiable 3DGS-based rendering, ArtGS optimizes the parameters of the articulated bones, ensuring physically consistent motion constraints and enhancing the manipulation policy. By leveraging dynamic Gaussian splatting, cross-embodiment adaptability, and closed-loop optimization, ArtGS establishes a new framework for efficient, scalable, and generalizable articulated object modeling and manipulation. Experiments conducted in both simulation and real-world environments demonstrate that ArtGS significantly outperforms previous methods in joint estimation accuracy and manipulation success rates across a variety of articulated objects.

关节物体操作由于其复杂的运动学约束以及现有方法在物理推理能力上的不足，仍然是机器人领域的一项关键挑战。在本研究中，我们提出了 ArtGS，这是一种将视觉-物理建模与三维高斯投影（3D Gaussian Splatting, 3DGS）相结合的新型框架，用于关节物体的理解与交互。ArtGS 首先通过多视角 RGB-D 重建获取场景数据，随后利用视觉语言模型（VLM）进行推理，以提取语义与结构信息，尤其是关节骨骼。通过基于动态、可微的 3DGS 渲染，ArtGS 优化关节骨骼的参数，确保物理一致的运动约束，并提升操作策略。借助动态高斯投影、跨机体适应性以及闭环优化，ArtGS 建立了一个高效、可扩展且具有良好泛化能力的关节物体建模与操作新框架。在仿真与真实环境中的实验结果表明，ArtGS 在关节估计精度与操作成功率方面，相较现有方法在多种关节物体上均取得了显著提升。
