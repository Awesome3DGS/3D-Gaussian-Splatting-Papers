### GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors

Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views is an ill-posed problem due to insufficient information, often resulting in noticeable artifacts. While recent approaches have sought to leverage generative priors to complete information for under-constrained regions, they struggle to generate content that remains consistent with input observations. To address this challenge, we propose GSFixer, a novel framework designed to improve the quality of 3DGS representations reconstructed from sparse inputs. The core of our approach is the reference-guided video restoration model, built upon a DiT-based video diffusion model trained on paired artifact 3DGS renders and clean frames with additional reference-based conditions. Considering the input sparse views as references, our model integrates both 2D semantic features and 3D geometric features of reference views extracted from the visual geometry foundation model, enhancing the semantic coherence and 3D consistency when fixing artifact novel views. Furthermore, considering the lack of suitable benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which contains artifact frames rendered using low-quality 3DGS. Extensive experiments demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS artifact restoration and sparse-view 3D reconstruction.

利用三维高斯溅射（3DGS）从稀疏视角重建三维场景是一个病态问题，由于信息不足，往往会产生明显的伪影。尽管近期方法尝试利用生成先验来补全欠约束区域的信息，但仍难以生成与输入观测保持一致的内容。为解决这一挑战，我们提出了 **GSFixer**，一个旨在提升稀疏输入下3DGS重建质量的新框架。其核心是一个基于参考引导的视频修复模型，构建于 DiT 视频扩散模型之上，并在包含成对的伪影 3DGS 渲染帧与干净帧的数据上进行训练，同时引入了额外的参考条件。以输入的稀疏视角作为参考，我们的模型结合了来自视觉几何基础模型提取的二维语义特征与三维几何特征，从而在修复伪影新视角时增强语义一致性与三维一致性。此外，鉴于缺乏适合的 3DGS 伪影修复评测基准，我们提出了 **DL3DV-Res** 数据集，其中包含由低质量3DGS渲染得到的伪影帧。大量实验结果表明，GSFixer 在3DGS伪影修复与稀疏视角三维重建方面均优于当前最先进的方法。
