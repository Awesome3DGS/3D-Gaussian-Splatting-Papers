### iVR-GS: Inverse Volume Rendering for Explorable Visualization via Editable 3D Gaussian Splatting

In volume visualization, users can interactively explore the three-dimensional data by specifying color and opacity mappings in the transfer function (TF) or adjusting lighting parameters, facilitating meaningful interpretation of the underlying structure. However, rendering large-scale volumes demands powerful GPUs and high-speed memory access for real-time performance. While existing novel view synthesis (NVS) methods offer faster rendering speeds with lower hardware requirements, the visible parts of a reconstructed scene are fixed and constrained by preset TF settings, significantly limiting user exploration. This paper introduces inverse volume rendering via Gaussian splatting (iVR-GS), an innovative NVS method that reduces the rendering cost while enabling scene editing for interactive volume exploration. Specifically, we compose multiple iVR-GS models associated with basic TFs covering disjoint visible parts to make the entire volumetric scene visible. Each basic model contains a collection of 3D editable Gaussians, where each Gaussian is a 3D spatial point that supports real-time scene rendering and editing. We demonstrate the superior reconstruction quality and composability of iVR-GS against other NVS solutions (Plenoxels, CCNeRF, and base 3DGS) on various volume datasets. The code is available at this https URL.

在体数据可视化中，用户可以通过在传输函数（Transfer Function, TF）中指定颜色与不透明度映射，或调整光照参数，交互式地探索三维数据，从而更有意义地理解其潜在结构。然而，对大规模体数据的实时渲染通常依赖高性能 GPU 和高速内存访问，这对计算资源提出了较高要求。尽管现有的新视角合成（Novel View Synthesis, NVS）方法具有更快的渲染速度和更低的硬件要求，但其重建场景的可见区域往往固定，受限于预设的 TF 配置，严重限制了用户的探索灵活性。
本文提出了一种创新的 NVS 方法 —— 基于高斯投影的反向体渲染（inverse Volume Rendering via Gaussian Splatting, iVR-GS），在显著降低渲染成本的同时，实现了场景编辑与交互式体数据探索。具体而言，我们将多个与基本 TF 对应的 iVR-GS 模型进行组合，每个基本 TF 覆盖体数据中一个不相交的可见子区域，从而实现整个体数据场景的完整可视化。每个基本模型由一组可编辑的三维高斯组成，每个高斯对应一个三维空间点，支持实时场景渲染与编辑。
我们在多个体数据集上将 iVR-GS 与现有 NVS 方法（如 Plenoxels、CCNeRF 和基础 3DGS）进行对比，结果表明 iVR-GS 在重建质量和模型可组合性方面均具有显著优势。
