### UFV-Splatter: Pose-Free Feed-Forward 3D Gaussian Splatting Adapted to Unfavorable Views

This paper presents a pose-free, feed-forward 3D Gaussian Splatting (3DGS) framework designed to handle unfavorable input views. A common rendering setup for training feed-forward approaches places a 3D object at the world origin and renders it from cameras pointed toward the origin -- i.e., from favorable views, limiting the applicability of these models to real-world scenarios involving varying and unknown camera poses. To overcome this limitation, we introduce a novel adaptation framework that enables pretrained pose-free feed-forward 3DGS models to handle unfavorable views. We leverage priors learned from favorable images by feeding recentered images into a pretrained model augmented with low-rank adaptation (LoRA) layers. We further propose a Gaussian adapter module to enhance the geometric consistency of the Gaussians derived from the recentered inputs, along with a Gaussian alignment method to render accurate target views for training. Additionally, we introduce a new training strategy that utilizes an off-the-shelf dataset composed solely of favorable images. Experimental results on both synthetic images from the Google Scanned Objects dataset and real images from the OmniObject3D dataset validate the effectiveness of our method in handling unfavorable input views.

本文提出了一种无姿态、前馈式的三维高斯溅射（3DGS）框架，旨在处理不利输入视角的问题。前馈方法的常见渲染训练设置是将三维物体放置在世界坐标原点，并从指向原点的相机进行渲染，即使用有利视角，这限制了其在涉及多变且未知相机姿态的真实场景中的适用性。为克服这一限制，我们提出了一种新的适配框架，使预训练的无姿态前馈式 3DGS 模型能够处理不利视角。我们通过将重新居中的图像输入到添加了低秩适配（LoRA）层的预训练模型中，利用从有利图像中学习到的先验。此外，我们提出了高斯适配器模块，以增强由重新居中输入生成的高斯在几何上的一致性，并结合高斯对齐方法生成准确的目标视图用于训练。我们还引入了一种新的训练策略，该策略利用仅包含有利图像的现成数据集。基于 Google Scanned Objects 数据集的合成图像和 OmniObject3D 数据集的真实图像的实验结果验证了本方法在处理不利输入视角方面的有效性。
