### Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation

Instance Image-Goal Navigation (IIN) requires autonomous agents to identify and navigate to a target object or location depicted in a reference image captured from any viewpoint. While recent methods leverage powerful novel view synthesis (NVS) techniques, such as three-dimensional Gaussian splatting (3DGS), they typically rely on randomly sampling multiple viewpoints or trajectories to ensure comprehensive coverage of discriminative visual cues. This approach, however, creates significant redundancy through overlapping image samples and lacks principled view selection, substantially increasing both rendering and comparison overhead. In this paper, we introduce a novel IIN framework with a hierarchical scoring paradigm that estimates optimal viewpoints for target matching. Our approach integrates cross-level semantic scoring, utilizing CLIP-derived relevancy fields to identify regions with high semantic similarity to the target object class, with fine-grained local geometric scoring that performs precise pose estimation within promising regions. Extensive evaluations demonstrate that our method achieves state-of-the-art performance on simulated IIN benchmarks and real-world applicability.

实例图像目标导航（Instance Image-Goal Navigation，IIN）要求自主智能体识别并导航至目标对象或目标位置，该目标由任意视角下拍摄的参考图像所描述。尽管近期方法利用了强大的新颖视角合成（Novel View Synthesis，NVS）技术，如三维高斯泼洒（3D Gaussian Splatting，3DGS），但它们通常依赖于从多个视角或轨迹中随机采样，以覆盖尽可能多的判别性视觉线索。这种做法会带来大量冗余图像样本重叠的问题，且缺乏系统性的视角选择策略，显著增加了渲染和比对的开销。
本文提出了一种新颖的 IIN 框架，采用分层评分范式以估计用于目标匹配的最优视角。我们的方法融合了跨层语义评分和细粒度的局部几何评分：前者利用基于 CLIP 的相关性场（relevancy fields）识别与目标对象类别在语义上高度相似的区域；后者则在候选区域中执行精确的姿态估计。大量实验评估表明，我们的方法在模拟的 IIN 基准测试中达到了当前最优性能，并具备良好的真实场景适应能力。
