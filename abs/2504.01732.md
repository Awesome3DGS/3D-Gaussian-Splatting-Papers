### FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking

The development of large-scale 3D scene reconstruction and novel view synthesis methods mostly rely on datasets comprising perspective images with narrow fields of view (FoV). While effective for small-scale scenes, these datasets require large image sets and extensive structure-from-motion (SfM) processing, limiting scalability. To address this, we introduce a fisheye image dataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye lenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoor scenes. Each scene has sparse SfM point clouds and precise LIDAR-derived dense point clouds that can be used as geometric ground-truth, enabling robust benchmarking under challenging conditions such as occlusions and reflections. While the baseline experiments focus on vanilla Gaussian Splatting and NeRF based Nerfacto methods, the dataset supports diverse approaches for scene reconstruction, novel view synthesis, and image-based rendering.

当前大规模三维场景重建与新视角合成方法的发展，主要依赖于由窄视场（FoV）透视图像构建的数据集。这类数据集虽适用于小规模场景，但通常需要大量图像与复杂的结构自运动（SfM）处理流程，限制了其在更大场景中的可扩展性。
为了解决这一问题，本文引入了一个专为场景重建任务设计的鱼眼图像数据集。该数据集使用双 200 度鱼眼镜头，提供对 5 个室内场景与 5 个室外场景的完整 360 度覆盖。每个场景均配备了稀疏 SfM 点云与精确的激光雷达（LIDAR）密集点云，后者可作为几何真值，用于在遮挡、反射等复杂条件下进行稳健评估。
尽管基线实验聚焦于原始高斯喷洒与基于 NeRF 的 Nerfacto 方法，该数据集同时支持多种场景重建、新视角合成与基于图像的渲染方法，为相关研究提供了丰富的测试平台。
