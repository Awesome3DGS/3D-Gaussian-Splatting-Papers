### AbsGS: Recovering Fine Details for 3D Gaussian Splatting

3D Gaussian Splatting (3D-GS) technique couples 3D Gaussian primitives with differentiable rasterization to achieve high-quality novel view synthesis results while providing advanced real-time rendering performance. However, due to the flaw of its adaptive density control strategy in 3D-GS, it frequently suffers from over-reconstruction issue in intricate scenes containing high-frequency details, leading to blurry rendered images. The underlying reason for the flaw has still been under-explored. In this work, we present a comprehensive analysis of the cause of aforementioned artifacts, namely gradient collision, which prevents large Gaussians in over-reconstructed regions from splitting. To address this issue, we propose the novel homodirectional view-space positional gradient as the criterion for densification. Our strategy efficiently identifies large Gaussians in over-reconstructed regions, and recovers fine details by splitting. We evaluate our proposed method on various challenging datasets. The experimental results indicate that our approach achieves the best rendering quality with reduced or similar memory consumption. Our method is easy to implement and can be incorporated into a wide variety of most recent Gaussian Splatting-based methods.


3D高斯飞溅（3D-GS）技术将3D高斯原语与可微光栅化结合起来，实现了高质量的新视角合成结果，同时提供了先进的实时渲染性能。然而，由于其在3D-GS中的自适应密度控制策略存在缺陷，这种方法在包含高频细节的复杂场景中经常出现过度重建问题，导致渲染图像模糊。这一缺陷的根本原因尚未被深入探索。在这项工作中，我们对上述伪影的原因进行了全面分析，即梯度碰撞，这阻止了过度重建区域中的大高斯原语分裂。为了解决这个问题，我们提出了一种新的同向视空间位置梯度作为密集化的标准。我们的策略有效地识别了过度重建区域中的大高斯原语，并通过分裂恢复细节。我们在各种具有挑战性的数据集上评估了我们提出的方法。实验结果表明，我们的方法在减少或相似的内存消耗下实现了最佳的渲染质量。我们的方法易于实现，可以集成到广泛的最新基于高斯飞溅的方法中。
