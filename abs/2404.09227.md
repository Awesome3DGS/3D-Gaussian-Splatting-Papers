### DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation Modeling

Recent progress in text-to-3D creation has been propelled by integrating the potent prior of Diffusion Models from text-to-image generation into the 3D domain. Nevertheless, generating 3D scenes characterized by multiple instances and intricate arrangements remains challenging. In this study, we present DreamScape, a method for creating highly consistent 3D scenes solely from textual descriptions, leveraging the strong 3D representation capabilities of Gaussian Splatting and the complex arrangement abilities of large language models (LLMs). Our approach involves a 3D Gaussian Guide (3DG2) for scene representation, consisting of semantic primitives (objects) and their spatial transformations and relationships derived directly from text prompts using LLMs. This compositional representation allows for local-to-global optimization of the entire scene. A progressive scale control is tailored during local object generation, ensuring that objects of different sizes and densities adapt to the scene, which addresses training instability issue arising from simple blending in the subsequent global optimization stage. To mitigate potential biases of LLM priors, we model collision relationships between objects at the global level, enhancing physical correctness and overall realism. Additionally, to generate pervasive objects like rain and snow distributed extensively across the scene, we introduce a sparse initialization and densification strategy. Experiments demonstrate that DreamScape offers high usability and controllability, enabling the generation of high-fidelity 3D scenes from only text prompts and achieving state-of-the-art performance compared to other methods.

近期文本到3D创作的进展得益于将从文本到图像生成中的强大先验扩散模型集成到3D领域中。然而，生成具有多个实例和复杂布局的3D场景仍然具有挑战性。在这项研究中，我们提出了DreamScape方法，仅从文本描述中创建高度一致的3D场景，利用高斯飞溅的强大3D表现能力和大型语言模型（LLMs）的复杂布局能力。我们的方法涉及使用3D高斯指导（3DG2）进行场景表示，包括语义原语（对象）及其空间变换和关系，这些都是直接从文本提示使用LLMs导出的。这种组合表示允许对整个场景进行从局部到全局的优化。在局部对象生成过程中，我们量身定制了逐步规模控制，确保不同大小和密度的对象适应场景，这解决了后续全局优化阶段由简单混合引起的训练不稳定问题。为了减轻LLM先验的潜在偏见，我们在全球层面上模拟物体之间的碰撞关系，增强物理正确性和整体现实感。此外，为了生成如雨和雪这样广泛分布在场景中的普遍对象，我们引入了稀疏初始化和密集化策略。实验表明，DreamScape提供了高度的可用性和可控性，使得仅从文本提示生成高保真度的3D场景成为可能，并与其他方法相比实现了最先进的性能。
