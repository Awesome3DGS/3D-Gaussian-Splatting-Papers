### Efficient Data-driven Scene Simulation using Robotic Surgery Videos via Physics-embedded 3D Gaussians

Surgical scene simulation plays a crucial role in surgical education and simulator-based robot learning. Traditional approaches for creating these environments with surgical scene involve a labor-intensive process where designers hand-craft tissues models with textures and geometries for soft body simulations. This manual approach is not only time-consuming but also limited in the scalability and realism. In contrast, data-driven simulation offers a compelling alternative. It has the potential to automatically reconstruct 3D surgical scenes from real-world surgical video data, followed by the application of soft body physics. This area, however, is relatively uncharted. In our research, we introduce 3D Gaussian as a learnable representation for surgical scene, which is learned from stereo endoscopic video. To prevent over-fitting and ensure the geometrical correctness of these scenes, we incorporate depth supervision and anisotropy regularization into the Gaussian learning process. Furthermore, we apply the Material Point Method, which is integrated with physical properties, to the 3D Gaussians to achieve realistic scene deformations. Our method was evaluated on our collected in-house and public surgical videos datasets. Results show that it can reconstruct and simulate surgical scenes from endoscopic videos efficiently-taking only a few minutes to reconstruct the surgical scene-and produce both visually and physically plausible deformations at a speed approaching real-time. The results demonstrate great potential of our proposed method to enhance the efficiency and variety of simulations available for surgical education and robot learning.

手术场景仿真在手术教育和基于模拟器的机器人学习中扮演着至关重要的角色。传统的创建手术环境的方法涉及到一个劳动密集型的过程，设计师需要手工制作具有纹理和几何形状的软体模拟组织模型。这种手动方法不仅耗时，而且在可扩展性和真实性上有限。相比之下，数据驱动的仿真提供了一个引人注目的替代方案。它有潜力从现实世界的手术视频数据中自动重建3D手术场景，随后应用软体物理学。然而，这一领域相对未被探索。在我们的研究中，我们引入了3D高斯作为可学习的手术场景表示，该表示从立体内窥镜视频中学习得到。为了防止过拟合并确保这些场景的几何正确性，我们在高斯学习过程中引入了深度监督和各向异性正则化。此外，我们将物理属性与3D高斯集成的材料点方法应用于，以实现真实的场景变形。我们的方法在我们收集的内部和公共手术视频数据集上进行了评估。结果显示，它能够从内窥镜视频中有效重建和模拟手术场景——重建手术场景只需几分钟，并以接近实时的速度产生视觉上和物理上合理的变形。这些结果展示了我们提出的方法在提高手术教育和机器人学习仿真的效率和多样性方面的巨大潜力。
