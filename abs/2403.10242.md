### FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model

Reconstructing detailed 3D objects from single-view images remains a challenging task due to the limited information available. In this paper, we introduce FDGaussian, a novel two-stage framework for single-image 3D reconstruction. Recent methods typically utilize pre-trained 2D diffusion models to generate plausible novel views from the input image, yet they encounter issues with either multi-view inconsistency or lack of geometric fidelity. To overcome these challenges, we propose an orthogonal plane decomposition mechanism to extract 3D geometric features from the 2D input, enabling the generation of consistent multi-view images. Moreover, we further accelerate the state-of-the-art Gaussian Splatting incorporating epipolar attention to fuse images from different viewpoints. We demonstrate that FDGaussian generates images with high consistency across different views and reconstructs high-quality 3D objects, both qualitatively and quantitatively.

从单视图图像重建详细的3D对象仍然是一个具有挑战性的任务，因为可用的信息有限。在本文中，我们引入了FDGaussian，一个用于单图像3D重建的新颖的两阶段框架。最近的方法通常使用预训练的2D扩散模型从输入图像生成可信的新视角图像，但它们遇到了多视图不一致或缺乏几何保真度的问题。为了克服这些挑战，我们提出了一个正交平面分解机制，从2D输入中提取3D几何特征，使得生成一致的多视角图像成为可能。此外，我们进一步通过整合视差注意力来加速最先进的高斯溅射，以融合来自不同视点的图像。我们展示了FDGaussian生成了在不同视角间高度一致的图像，并且定性和定量地重建了高质量的3D对象。
