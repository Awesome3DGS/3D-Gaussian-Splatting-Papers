### Direct Learning of Mesh and Appearance via 3D Gaussian Splatting

Accurately reconstructing a 3D scene including explicit geometry information is both attractive and challenging. Geometry reconstruction can benefit from incorporating differentiable appearance models, such as Neural Radiance Fields and 3D Gaussian Splatting (3DGS). In this work, we propose a learnable scene model that incorporates 3DGS with an explicit geometry representation, namely a mesh. Our model learns the mesh and appearance in an end-to-end manner, where we bind 3D Gaussians to the mesh faces and perform differentiable rendering of 3DGS to obtain photometric supervision. The model creates an effective information pathway to supervise the learning of the scene, including the mesh. Experimental results demonstrate that the learned scene model not only achieves state-of-the-art rendering quality but also supports manipulation using the explicit mesh. In addition, our model has a unique advantage in adapting to scene updates, thanks to the end-to-end learning of both mesh and appearance.

精确重建包括显式几何信息的3D场景既具有吸引力又具有挑战性。几何重建可以通过结合可微分的外观模型来受益，例如神经辐射场和3D高斯喷涂（3DGS）。在这项工作中，我们提出了一个可学习的场景模型，该模型将3DGS与显式的几何表示（即网格）结合在一起。我们的模型以端到端的方式学习网格和外观，其中我们将3D高斯绑定到网格面上，并执行3DGS的可微分渲染以获得光度监督。该模型创建了一个有效的信息通道来监督场景的学习，包括网格。实验结果表明，学习到的场景模型不仅实现了最先进的渲染质量，还支持使用显式网格进行操作。此外，我们的模型在适应场景更新方面具有独特的优势，这得益于网格和外观的端到端学习。
