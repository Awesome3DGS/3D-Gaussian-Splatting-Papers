### FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR

While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic rendering, its vast ecosystem of assets remains incompatible with high-performance LiDAR simulation, a critical tool for robotics and autonomous driving. We present FGGS-LiDAR, a framework that bridges this gap with a truly plug-and-play approach. Our method converts any pretrained 3DGS model into a high-fidelity, watertight mesh without requiring LiDAR-specific supervision or architectural alterations. This conversion is achieved through a general pipeline of volumetric discretization and Truncated Signed Distance Field (TSDF) extraction. We pair this with a highly optimized, GPU-accelerated ray-casting module that simulates LiDAR returns at over 500 FPS. We validate our approach on indoor and outdoor scenes, demonstrating exceptional geometric fidelity; By enabling the direct reuse of 3DGS assets for geometrically accurate depth sensing, our framework extends their utility beyond visualization and unlocks new capabilities for scalable, multimodal simulation.

尽管三维高斯溅射（3D Gaussian Splatting, 3DGS）在真实感渲染方面取得了革命性进展，但其庞大的资产生态系统仍无法兼容高性能的激光雷达（LiDAR）仿真——这一在机器人与自动驾驶领域至关重要的工具。本文提出了 **FGGS-LiDAR**，一个真正意义上的即插即用框架，用以弥合这一鸿沟。我们的方法能够将任意预训练的 3DGS 模型转换为高保真、密闭（watertight）的网格，而无需任何针对 LiDAR 的特定监督或架构修改。该转换通过通用的体素离散化与**截断符号距离场（Truncated Signed Distance Field, TSDF）提取**流程实现。我们进一步配备了一个高效优化、GPU 加速的射线投射模块，可在 **500 FPS 以上**的速度下模拟激光雷达回波。我们在室内与室外场景上对该方法进行了验证，结果显示其在几何保真度方面表现卓越。通过实现对 3DGS 资产在几何精确深度感知任务中的直接复用，该框架不仅扩展了其在可视化之外的应用范围，也为大规模、多模态仿真带来了新的可能性。
