### Vid2Avatar-Pro: Authentic Avatar from Videos in the Wild via Universal Prior

We present Vid2Avatar-Pro, a method to create photorealistic and animatable 3D human avatars from monocular in-the-wild videos. Building a high-quality avatar that supports animation with diverse poses from a monocular video is challenging because the observation of pose diversity and view points is inherently limited. The lack of pose variations typically leads to poor generalization to novel poses, and avatars can easily overfit to limited input view points, producing artifacts and distortions from other views. In this work, we address these limitations by leveraging a universal prior model (UPM) learned from a large corpus of multi-view clothed human performance capture data. We build our representation on top of expressive 3D Gaussians with canonical front and back maps shared across identities. Once the UPM is learned to accurately reproduce the large-scale multi-view human images, we fine-tune the model with an in-the-wild video via inverse rendering to obtain a personalized photorealistic human avatar that can be faithfully animated to novel human motions and rendered from novel views. The experiments show that our approach based on the learned universal prior sets a new state-of-the-art in monocular avatar reconstruction by substantially outperforming existing approaches relying only on heuristic regularization or a shape prior of minimally clothed bodies (e.g., SMPL) on publicly available datasets.

我们提出 Vid2Avatar-Pro，一种从单目自然视频（monocular in-the-wild videos）构建逼真且可动画化的 3D 人体头像的方法。从单目视频中创建支持多种姿势动画的高质量头像具有挑战性，因为其姿势多样性和视角观察 inherently 受限。这种姿势变化的缺乏通常会导致对新姿势的泛化能力较差，而头像模型也容易过拟合于有限的输入视角，从其他视角观察时可能出现伪影和失真。
在本研究中，我们利用从大规模多视角着衣人体表演捕捉数据（multi-view clothed human performance capture data）中学习的通用先验模型（Universal Prior Model, UPM）来克服这些限制。我们的表示构建在具有表达力的 3D 高斯（3D Gaussians）之上，并共享标准化前后视图（canonical front and back maps），以增强跨身份的适用性。
一旦 UPM 学习到准确重现大规模多视角人体图像，我们便通过逆渲染（inverse rendering）对模型进行微调，使其能够从自然视频中构建个性化的逼真 3D 头像，该头像不仅可以逼真地动画化以匹配新的人体动作，还可以从新视角渲染。
实验表明，我们基于学习到的通用先验的单目 3D 头像重建方法，在公开数据集上显著优于仅依赖启发式正则化（heuristic regularization）或最小着衣人体形状先验（如 SMPL）的现有方法，达到了新的最先进水平（state-of-the-art）。
