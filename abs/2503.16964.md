### DroneSplat: 3D Gaussian Splatting for Robust 3D Reconstruction from In-the-Wild Drone Imagery

Drones have become essential tools for reconstructing wild scenes due to their outstanding maneuverability. Recent advances in radiance field methods have achieved remarkable rendering quality, providing a new avenue for 3D reconstruction from drone imagery. However, dynamic distractors in wild environments challenge the static scene assumption in radiance fields, while limited view constraints hinder the accurate capture of underlying scene geometry. To address these challenges, we introduce DroneSplat, a novel framework designed for robust 3D reconstruction from in-the-wild drone imagery. Our method adaptively adjusts masking thresholds by integrating local-global segmentation heuristics with statistical approaches, enabling precise identification and elimination of dynamic distractors in static scenes. We enhance 3D Gaussian Splatting with multi-view stereo predictions and a voxel-guided optimization strategy, supporting high-quality rendering under limited view constraints. For comprehensive evaluation, we provide a drone-captured 3D reconstruction dataset encompassing both dynamic and static scenes. Extensive experiments demonstrate that DroneSplat outperforms both 3DGS and NeRF baselines in handling in-the-wild drone imagery.

无人机凭借其卓越的机动性，已成为重建野外场景的重要工具。近年来，辐射场方法 (Radiance Field) 在渲染质量上取得了显著进展，为基于无人机影像的 3D 重建 提供了新的可能性。然而，野外环境中的动态干扰因素挑战了辐射场的静态场景假设，而视角受限的问题又阻碍了场景几何结构的精确捕捉。
为了解决这些挑战，我们提出 DroneSplat，一个专为野外无人机影像的稳健 3D 重建设计的框架。我们的方法结合局部-全局分割启发式 (local-global segmentation heuristics) 与统计方法，自适应调整掩码阈值，以精准识别并去除静态场景中的动态干扰因素。此外，我们结合多视角立体 (multi-view stereo) 预测 和 体素引导优化 (voxel-guided optimization) 策略，增强 3D 高斯散点 (3DGS) 以支持在视角受限的情况下实现高质量渲染。
为了全面评估，我们构建了一个无人机采集的 3D 重建数据集，涵盖动态场景与静态场景。大量实验表明，DroneSplat 在处理野外无人机影像方面优于 3DGS 和 NeRF 基线方法。
