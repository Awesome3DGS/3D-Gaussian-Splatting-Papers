### VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians

Jointly estimating camera poses and mapping scenes from RGBD images is a fundamental task in simultaneous localization and mapping (SLAM). State-of-the-art methods employ 3D Gaussians to represent a scene, and render these Gaussians through splatting for higher efficiency and better rendering. However, these methods cannot scale up to extremely large scenes, due to the inefficient tracking and mapping strategies that need to optimize all 3D Gaussians in the limited GPU memories throughout the training to maintain the geometry and color consistency to previous RGBD observations. To resolve this issue, we propose novel tracking and mapping strategies to work with a novel 3D representation, dubbed view-tied 3D Gaussians, for RGBD SLAM systems. View-tied 3D Gaussians is a kind of simplified Gaussians, which is tied to depth pixels, without needing to learn locations, rotations, and multi-dimensional variances. Tying Gaussians to views not only significantly saves storage but also allows us to employ many more Gaussians to represent local details in the limited GPU memory. Moreover, our strategies remove the need of maintaining all Gaussians learnable throughout the training, while improving rendering quality, and tracking accuracy. We justify the effectiveness of these designs, and report better performance over the latest methods on the widely used benchmarks in terms of rendering and tracking accuracy and scalability.

从 RGBD 图像中联合估计相机位姿与场景建图是同时定位与地图构建（SLAM）中的一项基础任务。当前最先进的方法采用 3D 高斯来表示场景，并通过 splatting 渲染方式提升渲染效率与质量。然而，这些方法在面对超大规模场景时无法扩展，原因在于：为了保持与先前 RGBD 观测之间的几何与颜色一致性，它们需要在整个训练过程中持续优化所有 3D 高斯，而 GPU 显存有限，导致跟踪与建图策略效率低下。
为解决该问题，本文提出了适用于 RGBD SLAM 系统的新型跟踪与建图策略，并引入一种新的三维表示形式，称为 View-tied 3D Gaussians。这种高斯是一种简化形式，与深度图像像素绑定，不再需要学习其位置、旋转和多维方差。将高斯绑定到视图像素，既大大节省了存储开销，又使我们能够在有限的 GPU 显存中使用更多高斯来表示局部细节。
此外，我们的方法还消除了在整个训练过程中保持所有高斯可学习的需求，同时提升了渲染质量与跟踪精度。我们通过实验证明了该设计的有效性，并在主流基准测试中，在渲染效果、跟踪精度及系统可扩展性方面，均优于最新方法。
