### TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness

3D semantic occupancy has rapidly become a research focus in the fields of robotics and autonomous driving environment perception due to its ability to provide more realistic geometric perception and its closer integration with downstream tasks. By performing occupancy prediction of the 3D space in the environment, the ability and robustness of scene understanding can be effectively improved. However, existing occupancy prediction tasks are primarily modeled using voxel or point cloud-based approaches: voxel-based network structures often suffer from the loss of spatial information due to the voxelization process, while point cloud-based methods, although better at retaining spatial location information, face limitations in representing volumetric structural details. To address this issue, we propose a dual-modal prediction method based on 3D Gaussian sets and sparse points, which balances both spatial location and volumetric structural information, achieving higher accuracy in semantic occupancy prediction. Specifically, our method adopts a Transformer-based architecture, taking 3D Gaussian sets, sparse points, and queries as inputs. Through the multi-layer structure of the Transformer, the enhanced queries and 3D Gaussian sets jointly contribute to the semantic occupancy prediction, and an adaptive fusion mechanism integrates the semantic outputs of both modalities to generate the final prediction results. Additionally, to further improve accuracy, we dynamically refine the point cloud at each layer, allowing for more precise location information during occupancy prediction. We conducted experiments on the Occ3DnuScenes dataset, and the experimental results demonstrate superior performance of the proposed method on IoU based metrics.

3D 语义占据已经迅速成为机器人技术和自动驾驶环境感知领域的研究重点，因其能够提供更真实的几何感知，并与下游任务有更紧密的集成。通过对环境中 3D 空间的占据预测，可以有效提高场景理解的能力和鲁棒性。然而，现有的占据预测任务主要通过体素或点云方法进行建模：基于体素的网络结构通常由于体素化过程而导致空间信息的丢失，而基于点云的方法虽然更好地保留了空间位置信息，但在表示体积结构细节时存在局限性。为了解决这一问题，我们提出了一种基于 3D 高斯集合和稀疏点的双模态预测方法，平衡了空间位置信息和体积结构信息，从而在语义占据预测中实现更高的准确性。具体来说，我们的方法采用基于 Transformer 的架构，输入为 3D 高斯集合、稀疏点和查询。通过 Transformer 的多层结构，增强的查询和 3D 高斯集合共同贡献于语义占据预测，并且一个自适应融合机制将两种模态的语义输出整合起来，生成最终的预测结果。此外，为了进一步提高准确性，我们在每一层动态地细化点云，使占据预测过程中能够获得更精确的位置信息。我们在 Occ3DnuScenes 数据集上进行了实验，实验结果表明，所提出的方法在基于 IoU 的指标上表现出色。
