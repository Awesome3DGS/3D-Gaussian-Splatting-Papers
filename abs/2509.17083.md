### HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis

Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling real-time, high-quality novel view synthesis through explicit, optimizable 3D Gaussians. However, 3DGS suffers from significant memory overhead due to its reliance on per-Gaussian parameters to model view-dependent effects and anisotropic shapes. While recent works propose compressing 3DGS with neural fields, these methods struggle to capture high-frequency spatial variations in Gaussian properties, leading to degraded reconstruction of fine details. We present Hybrid Radiance Fields (HyRF), a novel scene representation that combines the strengths of explicit Gaussians and neural fields. HyRF decomposes the scene into (1) a compact set of explicit Gaussians storing only critical high-frequency parameters and (2) grid-based neural fields that predict remaining properties. To enhance representational capacity, we introduce a decoupled neural field architecture, separately modeling geometry (scale, opacity, rotation) and view-dependent color. Additionally, we propose a hybrid rendering scheme that composites Gaussian splatting with a neural field-predicted background, addressing limitations in distant scene representation. Experiments demonstrate that HyRF achieves state-of-the-art rendering quality while reducing model size by over 20 times compared to 3DGS and maintaining real-time performance.

近年来，三维高斯溅射（3D Gaussian Splatting, 3DGS）作为 NeRF 的强有力替代方案迅速兴起，它通过显式、可优化的三维高斯实现了实时的高质量新视角合成。然而，3DGS 由于依赖于每个高斯的独立参数来建模视角相关效应与各向异性形状，导致了显著的内存开销。尽管近期有研究尝试利用神经场对 3DGS 进行压缩，但这些方法难以捕捉高斯属性中的高频空间变化，从而造成细节重建质量下降。为此，我们提出了 **混合辐射场（Hybrid Radiance Fields, HyRF）**，这是一种结合显式高斯与神经场优势的全新场景表示方式。HyRF 将场景分解为两部分：（1）一组紧凑的显式高斯，用于存储关键的高频参数；（2）基于网格的神经场，用于预测剩余属性。为提升表示能力，我们设计了一种**解耦神经场结构**，分别建模几何属性（尺度、不透明度、旋转）与视角相关颜色。此外，我们提出了一种**混合渲染方案**，将高斯溅射结果与神经场预测的背景进行复合，从而解决了远景场景表示的不足。实验结果表明，HyRF 在保持实时性能的同时，相较于 3DGS 将模型大小减少了 20 倍以上，并在渲染质量上达到了当前最优水平。
