### TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update

Understanding the 3D geometry of transparent objects from RGB images is challenging due to their inherent physical properties, such as reflection and refraction. To address these difficulties, especially in scenarios with sparse views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian Splatting-based depth reconstruction method for transparent objects. Our key insight lies in separating transparent objects from the background, enabling focused optimization of Gaussians corresponding to the object. We mitigate artifacts with an object-aware loss that places Gaussians in obscured regions, ensuring coverage of invisible surfaces while reducing overfitting. Furthermore, we incorporate a physics-based simulation that refines the reconstruction in just a few seconds, effectively handling object removal and chain-reaction movement of remaining objects without the need for rescanning. TRAN-D is evaluated on both synthetic and real-world sequences, and it consistently demonstrated robust improvements over existing GS-based state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean absolute error by over 39% for the synthetic TRansPose sequences. Furthermore, despite being updated using only one image, TRAN-D reaches a δ &lt; 2.5 cm accuracy of 48.46%, over 1.5 times that of baselines, which uses six images.

由于反射和折射等固有物理特性，从 RGB 图像中理解透明物体的三维几何形状是一项具有挑战性的任务。为应对这些困难，特别是在稀疏视图和动态环境场景下，我们提出了 TRAN-D，这是一种基于二维高斯投影（2D Gaussian Splatting）的透明物体深度重建新方法。我们的核心思想是将透明物体与背景分离，从而能够针对物体对应的高斯进行集中优化。我们通过引入物体感知损失（object-aware loss）来缓解伪影问题，该损失会在被遮挡区域放置高斯，以确保对不可见表面的覆盖，同时减少过拟合。此外，我们结合了基于物理的模拟，仅需数秒即可优化重建结果，有效处理物体移除及剩余物体的连锁反应式运动，而无需重新扫描。我们在合成和真实数据序列上对 TRAN-D 进行了评估，其在现有基于高斯投影的最先进方法之上表现出持续且稳健的提升。与基线方法相比，TRAN-D 在合成的 TRansPose 序列上将平均绝对误差降低了 39% 以上。此外，尽管仅使用一张图像进行更新，TRAN-D 在 δ &lt; 2.5 cm 的精度下达到了 48.46%，是使用六张图像的基线方法的 1.5 倍以上。
