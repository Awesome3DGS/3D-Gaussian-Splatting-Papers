### Gaussian Deja-vu: Creating Controllable 3D Gaussian Head-Avatars with Enhanced Generalization and Personalization Abilities

Recent advancements in 3D Gaussian Splatting (3DGS) have unlocked significant potential for modeling 3D head avatars, providing greater flexibility than mesh-based methods and more efficient rendering compared to NeRF-based approaches. Despite these advancements, the creation of controllable 3DGS-based head avatars remains time-intensive, often requiring tens of minutes to hours. To expedite this process, we here introduce the "Gaussian Déjà-vu" framework, which first obtains a generalized model of the head avatar and then personalizes the result. The generalized model is trained on large 2D (synthetic and real) image datasets. This model provides a well-initialized 3D Gaussian head that is further refined using a monocular video to achieve the personalized head avatar. For personalizing, we propose learnable expression-aware rectification blendmaps to correct the initial 3D Gaussians, ensuring rapid convergence without the reliance on neural networks. Experiments demonstrate that the proposed method meets its objectives. It outperforms state-of-the-art 3D Gaussian head avatars in terms of photorealistic quality as well as reduces training time consumption to at least a quarter of the existing methods, producing the avatar in minutes.

3D 高斯分布（3D Gaussian Splatting, 3DGS）的最新进展在建模3D头部头像方面展现了巨大的潜力，提供了比基于网格的方法更大的灵活性，并且相比基于NeRF的方法具有更高的渲染效率。尽管取得了这些进展，基于3DGS的可控头部头像的创建仍然耗时，通常需要几十分钟甚至数小时。为了加速这一过程，我们提出了“Gaussian Déjà-vu”框架，该框架首先获得头部头像的通用模型，然后进行个性化调整。通用模型在大规模二维图像（包括合成和真实图像）数据集上进行训练，该模型提供了一个良好初始化的三维高斯头部，随后通过单目视频进一步优化，以实现个性化头像。在个性化过程中，我们提出了可学习的表情感知校正混合图（expression-aware rectification blendmaps）来修正初始的三维高斯，确保快速收敛，且无需依赖神经网络。实验结果表明，所提出的方法达到了其目标，在写实质量上优于当前最先进的3D高斯头部头像方法，并且将训练时间至少减少到现有方法的四分之一，能够在几分钟内生成头像。
