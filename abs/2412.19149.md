### Generating Editable Head Avatars with 3D Gaussian GANs

Generating animatable and editable 3D head avatars is essential for various applications in computer vision and graphics. Traditional 3D-aware generative adversarial networks (GANs), often using implicit fields like Neural Radiance Fields (NeRF), achieve photorealistic and view-consistent 3D head synthesis. However, these methods face limitations in deformation flexibility and editability, hindering the creation of lifelike and easily modifiable 3D heads. We propose a novel approach that enhances the editability and animation control of 3D head avatars by incorporating 3D Gaussian Splatting (3DGS) as an explicit 3D representation. This method enables easier illumination control and improved editability. Central to our approach is the Editable Gaussian Head (EG-Head) model, which combines a 3D Morphable Model (3DMM) with texture maps, allowing precise expression control and flexible texture editing for accurate animation while preserving identity. To capture complex non-facial geometries like hair, we use an auxiliary set of 3DGS and tri-plane features. Extensive experiments demonstrate that our approach delivers high-quality 3D-aware synthesis with state-of-the-art controllability.

生成可动画和可编辑的三维头部头像在计算机视觉和图形学的各种应用中至关重要。传统的三维感知生成对抗网络（GAN），通常使用神经辐射场（NeRF）等隐式场景表示，实现了照片级逼真和视角一致的三维头部合成。然而，这些方法在变形灵活性和可编辑性方面存在局限，难以创建逼真且易于修改的三维头部模型。
我们提出了一种新方法，通过将三维高斯散射（3D Gaussian Splatting, 3DGS）作为显式三维表示，增强三维头部头像的可编辑性和动画控制能力。该方法支持更简单的光照控制和改进的可编辑性。我们方法的核心是可编辑高斯头部模型（Editable Gaussian Head, EG-Head），它将三维可变形模型（3D Morphable Model, 3DMM）与纹理贴图相结合，允许精确的表情控制和灵活的纹理编辑，从而在保持身份特征的同时实现准确的动画效果。
为了捕获复杂的非面部几何结构（如头发），我们引入了一组辅助的3DGS和三平面特征（tri-plane features）。大量实验表明，我们的方法在高质量的三维感知合成方面表现出色，同时具备当前最先进的可控性。
