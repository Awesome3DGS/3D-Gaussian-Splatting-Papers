### ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos

Creating a photorealistic scene and human reconstruction from a single monocular in-the-wild video figures prominently in the perception of a human-centric 3D world. Recent neural rendering advances have enabled holistic human-scene reconstruction but require pre-calibrated camera and human poses, and days of training time. In this work, we introduce a novel unified framework that simultaneously performs camera tracking, human pose estimation and human-scene reconstruction in an online fashion. 3D Gaussian Splatting is utilized to learn Gaussian primitives for humans and scenes efficiently, and reconstruction-based camera tracking and human pose estimation modules are designed to enable holistic understanding and effective disentanglement of pose and appearance. Specifically, we design a human deformation module to reconstruct the details and enhance generalizability to out-of-distribution poses faithfully. Aiming to learn the spatial correlation between human and scene accurately, we introduce occlusion-aware human silhouette rendering and monocular geometric priors, which further improve reconstruction quality. Experiments on the EMDB and NeuMan datasets demonstrate superior or on-par performance with existing methods in camera tracking, human pose estimation, novel view synthesis and runtime.

从单目野外视频中重建逼真的场景与人物，是实现以人为中心的三维世界感知的关键步骤。尽管近年来神经渲染的进展已推动整体人-场景重建的发展，但这些方法通常依赖于预标定的相机与人体姿态，且训练周期动辄数天，限制了其实用性与推广性。
为此，我们提出了一个新颖的统一框架，可在在线方式下同时完成相机追踪、人体姿态估计与人-场景联合重建。我们采用 3D Gaussian Splatting 高效学习人物与场景的高斯原语，并设计了基于重建的相机追踪与人体姿态估计模块，实现姿态与外观的有效解耦与整体理解。
具体而言，我们引入了一个人体变形模块，可在保持细节重建质量的同时提升对分布外姿态的泛化能力。为准确学习人物与场景之间的空间关系，我们进一步引入了遮挡感知的人体轮廓渲染机制与单目几何先验，显著增强了重建质量。
在 EMDB 与 NeuMan 数据集上的实验结果表明，我们的方法在相机追踪、人体姿态估计、新视角合成与运行时效率等方面均优于或媲美现有技术，展现出在复杂真实场景中的强大适应性与实用性。
