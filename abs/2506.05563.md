### VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction

Recent advancements in camera-based occupancy prediction have focused on the simultaneous prediction of 3D semantics and scene flow, a task that presents significant challenges due to specific difficulties, e.g., occlusions and unbalanced dynamic environments. In this paper, we analyze these challenges and their underlying causes. To address them, we propose a novel regularization framework called VoxelSplat. This framework leverages recent developments in 3D Gaussian Splatting to enhance model performance in two key ways: (i) Enhanced Semantics Supervision through 2D Projection: During training, our method decodes sparse semantic 3D Gaussians from 3D representations and projects them onto the 2D camera view. This provides additional supervision signals in the camera-visible space, allowing 2D labels to improve the learning of 3D semantics. (ii) Scene Flow Learning: Our framework uses the predicted scene flow to model the motion of Gaussians, and is thus able to learn the scene flow of moving objects in a self-supervised manner using the labels of adjacent frames. Our method can be seamlessly integrated into various existing occupancy models, enhancing performance without increasing inference time. Extensive experiments on benchmark datasets demonstrate the effectiveness of VoxelSplat in improving the accuracy of both semantic occupancy and scene flow estimation.

近年来，基于摄像头的占用预测研究逐渐聚焦于同时预测三维语义与场景流，这是一项具有高度挑战性的任务，主要因其面临遮挡、动态环境分布不均等特定难题。本文分析了这些挑战及其根本原因。为应对这些问题，我们提出了一种名为 VoxelSplat 的全新正则化框架。该框架借助最新的 3D 高斯溅射（3D Gaussian Splatting）技术，从两个关键方面提升模型性能：
(i) 通过二维投影增强语义监督：在训练过程中，我们的方法从三维表示中解码出稀疏的语义三维高斯，并将其投影到二维摄像头视角。这一操作在摄像头可见空间中引入了额外的监督信号，使得二维标签能够有效提升三维语义的学习效果。
(ii) 场景流学习：该框架利用预测得到的场景流对高斯运动进行建模，从而能够在相邻帧标签的引导下，以自监督的方式学习移动物体的场景流。
我们的方法可无缝集成至现有多种占用模型中，在不增加推理时间的前提下，显著提升性能。大量基准数据集上的实验证明，VoxelSplat 能够有效提高语义占用预测与场景流估计的准确性。
