### 3D Gaussian Splat Vulnerabilities

With 3D Gaussian Splatting (3DGS) being increasingly used in safety-critical applications, how can an adversary manipulate the scene to cause harm? We introduce CLOAK, the first attack that leverages view-dependent Gaussian appearances - colors and textures that change with viewing angle - to embed adversarial content visible only from specific viewpoints. We further demonstrate DAGGER, a targeted adversarial attack directly perturbing 3D Gaussians without access to underlying training data, deceiving multi-stage object detectors e.g., Faster R-CNN, through established methods such as projected gradient descent. These attacks highlight underexplored vulnerabilities in 3DGS, introducing a new potential threat to robotic learning for autonomous navigation and other safety-critical 3DGS applications.

随着 3D Gaussian Splatting（3DGS） 日益应用于安全关键场景，攻击者是否能操纵场景以造成危害成为一个重要问题。我们提出了 CLOAK，这是首个利用 视角相关高斯外观（view-dependent Gaussian appearances） 实现攻击的方法——即颜色与纹理随视角变化，从而将对抗内容嵌入到特定视角下才可见的场景中。
我们进一步提出了 DAGGER，一种有目标的对抗性攻击方式，直接扰动 3D 高斯，且无需访问底层训练数据。该攻击通过诸如**投影梯度下降（projected gradient descent）**等现有方法，对多阶段目标检测器（如 Faster R-CNN）实施误导。
这些攻击揭示了目前 3DGS 安全性研究中的重要盲区，为机器人导航等安全关键任务中的学习系统带来了新的潜在威胁。
