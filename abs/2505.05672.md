### TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling

Sparse volumetric reconstruction and rendering via 3D Gaussian splatting have recently enabled animatable 3D head avatars that are rendered under arbitrary viewpoints with impressive photorealism. Today, such photoreal avatars are seen as a key component in emerging applications in telepresence, extended reality, and entertainment. Building a photoreal avatar requires estimating the complex non-rigid motion of different facial components as seen in input video images; due to inaccurate motion estimation, animatable models typically present a loss of fidelity and detail when compared to their non-animatable counterparts, built from an individual facial expression. Also, recent state-of-the-art models are often affected by memory limitations that reduce the number of 3D Gaussians used for modeling, leading to lower detail and quality. To address these problems, we present a new high-detail 3D head avatar model that improves upon the state of the art, largely increasing the number of 3D Gaussians and modeling quality for rendering at 4K resolution. Our high-quality model is reconstructed from multiview input video and builds on top of a mesh-based 3D morphable model, which provides a coarse deformation layer for the head. Photoreal appearance is modelled by 3D Gaussians embedded within the continuous UVD tangent space of this mesh, allowing for more effective densification where most needed. Additionally, these Gaussians are warped by a novel UVD deformation field to capture subtle, localized motion. Our key contribution is the novel deformable Gaussian encoding and overall fitting procedure that allows our head model to preserve appearance detail, while capturing facial motion and other transient high-frequency features such as skin wrinkling.

稀疏体积重建与渲染近年来借助三维高斯泼溅（3D Gaussian Splatting）技术，实现了可动画的三维头像，可在任意视角下呈现出令人印象深刻的真实感。如今，这类写实头像已成为远程交互、扩展现实与娱乐等新兴应用中的关键组成部分。
构建高保真头像需准确估计输入视频中面部各部位的复杂非刚性运动。然而，由于运动估计的不准确，可动画模型通常在保真度和细节方面逊于基于静态面部表情构建的非动画模型。此外，当前最先进的方法常受限于显存资源，限制了可用于建模的三维高斯数量，从而影响渲染细节与质量。
为解决上述问题，我们提出了一种新型的高细节三维头像模型，在现有方法基础上实现了显著提升，通过大幅增加三维高斯数量与建模质量，实现了可达 4K 分辨率 的高质量渲染。该模型基于多视角输入视频重建，并建立在三维可变形网格模型（3D Morphable Model）基础上，为头部提供一个粗略的形变层。
写实外观通过嵌入于网格连续 UVD 切线空间中的三维高斯建模，从而能在需要的区域实现更有效的密化。同时，这些高斯通过一个新颖的 UVD 形变场 进行变形，以捕捉局部微妙运动。
我们工作的核心贡献是提出了一种可变形高斯编码方法及其整体拟合流程，使得头像模型在捕捉面部运动与诸如皮肤皱纹等瞬时高频细节的同时，依然保持了极高的外观保真度。
