### High-fidelity 3D Object Generation from Single Image with RGBN-Volume Gaussian Reconstruction Model

Recently single-view 3D generation via Gaussian splatting has emerged and developed quickly. They learn 3D Gaussians from 2D RGB images generated from pre-trained multi-view diffusion (MVD) models, and have shown a promising avenue for 3D generation through a single image. Despite the current progress, these methods still suffer from the inconsistency jointly caused by the geometric ambiguity in the 2D images, and the lack of structure of 3D Gaussians, leading to distorted and blurry 3D object generation. In this paper, we propose to fix these issues by GS-RGBN, a new RGBN-volume Gaussian Reconstruction Model designed to generate high-fidelity 3D objects from single-view images. Our key insight is a structured 3D representation can simultaneously mitigate the afore-mentioned two issues. To this end, we propose a novel hybrid Voxel-Gaussian representation, where a 3D voxel representation contains explicit 3D geometric information, eliminating the geometric ambiguity from 2D images. It also structures Gaussians during learning so that the optimization tends to find better local optima. Our 3D voxel representation is obtained by a fusion module that aligns RGB features and surface normal features, both of which can be estimated from 2D images. Extensive experiments demonstrate the superiority of our methods over prior works in terms of high-quality reconstruction results, robust generalization, and good efficiency.

近年来，基于高斯喷洒的单视图三维生成技术快速发展。这类方法通常利用预训练多视图扩散模型（Multi-View Diffusion, MVD）生成的二维 RGB 图像，学习对应的三维高斯表示，展现出从单张图像生成三维内容的广阔前景。尽管已有一定进展，但当前方法仍存在两个关键问题：一是二维图像中的几何歧义，二是三维高斯缺乏结构约束，这导致生成结果容易出现形变与模糊等问题。
为解决上述问题，本文提出 GS-RGBN，一种用于单视图高保真三维物体生成的 RGBN 体积高斯重建模型。我们的核心观点是：结构化的三维表示能够同时缓解上述两类问题。
具体而言，我们引入了一种新颖的体素-高斯混合表示，其中三维体素表示显式编码了几何结构信息，有效消除了来自二维图像的几何歧义。同时，这种结构化约束也有助于三维高斯在优化过程中收敛到更优的局部最优解。
我们所采用的三维体素表示通过一个融合模块获得，该模块对齐了从二维图像中估计的 RGB 特征与表面法向特征（Normal Features）。
大量实验表明，GS-RGBN 在高质量重建效果、稳健的泛化能力以及运行效率方面，均显著优于现有方法。
