### UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS

3D Gaussian Splatting (3DGS) has become a competitive approach for novel view synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian projection and blending. However, Gaussians are treated equally weighted for rendering in most 3DGS methods, making them prone to overfitting, which is particularly the case in sparse-view scenarios. To address this, we investigate how adaptive weighting of Gaussians affects rendering quality, which is characterised by learned uncertainties proposed. This learned uncertainty serves two key purposes: first, it guides the differentiable update of Gaussian opacity while preserving the 3DGS pipeline integrity; second, the uncertainty undergoes soft differentiable dropout regularisation, which strategically transforms the original uncertainty into continuous drop probabilities that govern the final Gaussian projection and blending process for rendering. Extensive experimental results over widely adopted datasets demonstrate that our method outperforms rivals in sparse-view 3D synthesis, achieving higher quality reconstruction with fewer Gaussians in most datasets compared to existing sparse-view approaches, e.g., compared to DropGaussian, our method achieves 3.27% PSNR improvements on the MipNeRF 360 dataset.

三维高斯溅射（3D Gaussian Splatting, 3DGS）凭借其基于三维高斯投影与混合的高效渲染能力，已成为新视图合成（Novel View Synthesis, NVS）中的一种具有竞争力的方法。然而，大多数 3DGS 方法在渲染时对所有高斯赋予相同权重，这使得模型易于过拟合，尤其是在稀疏视角场景中。为此，我们研究了高斯自适应加权对渲染质量的影响，并提出了基于学习不确定性的加权策略。该学习不确定性具有两个核心作用：第一，它在保持 3DGS 渲染管线完整性的同时，引导高斯不透明度的可微分更新；第二，它经过软可微分的 dropout 正则化处理，将原始不确定性平滑地映射为连续的丢弃概率，从而在渲染过程中调控最终的高斯投影与混合。大量在主流数据集上的实验结果表明，我们的方法在稀疏视角三维合成中优于现有方法，在多数数据集上以更少的高斯实现更高质量的重建。例如，相较于 DropGaussian，我们的方法在 MipNeRF 360 数据集上实现了 3.27% 的 PSNR 提升。
