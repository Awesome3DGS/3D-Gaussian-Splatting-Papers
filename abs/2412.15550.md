### EGSRAL: An Enhanced 3D Gaussian Splatting based Renderer with Automated Labeling for Large-Scale Driving Scene

3D Gaussian Splatting (3D GS) has gained popularity due to its faster rendering speed and high-quality novel view synthesis. Some researchers have explored using 3D GS for reconstructing driving scenes. However, these methods often rely on various data types, such as depth maps, 3D boxes, and trajectories of moving objects. Additionally, the lack of annotations for synthesized images limits their direct application in downstream tasks. To address these issues, we propose EGSRAL, a 3D GS-based method that relies solely on training images without extra annotations. EGSRAL enhances 3D GS's capability to model both dynamic objects and static backgrounds and introduces a novel adaptor for auto labeling, generating corresponding annotations based on existing annotations. We also propose a grouping strategy for vanilla 3D GS to address perspective issues in rendering large-scale, complex scenes. Our method achieves state-of-the-art performance on multiple datasets without any extra annotation. For example, the PSNR metric reaches 29.04 on the nuScenes dataset. Moreover, our automated labeling can significantly improve the performance of 2D/3D detection tasks.

3D高斯点绘（3D Gaussian Splatting, 3D GS）因其快速渲染速度和高质量的新视角合成能力而受到广泛关注。一些研究者已探索将3D GS应用于驾驶场景重建。然而，这些方法通常依赖多种数据类型，例如深度图、3D框以及动态物体的轨迹。此外，合成图像缺乏标注，限制了其在下游任务中的直接应用。
为了解决这些问题，我们提出了一种基于3D GS的新方法 EGSRAL，该方法完全依赖训练图像而无需额外标注。EGSRAL增强了3D GS在建模动态物体和静态背景方面的能力，并引入了一种新颖的自动标注适配器，能够基于已有标注生成相应的注释。此外，我们提出了一种针对基础3D GS的分组策略，用以解决在渲染大规模复杂场景时的透视问题。
我们的方法在多个数据集上实现了最先进的性能，无需额外标注。例如，在 nuScenes 数据集上，PSNR 指标达到了29.04。此外，我们的自动化标注功能显著提高了2D/3D检测任务的性能。
