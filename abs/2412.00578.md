### Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives

3D Gaussian Splatting (3D-GS) is a recent 3D scene reconstruction technique that enables real-time rendering of novel views by modeling scenes as parametric point clouds of differentiable 3D Gaussians. However, its rendering speed and model size still present bottlenecks, especially in resource-constrained settings. In this paper, we identify and address two key inefficiencies in 3D-GS, achieving substantial improvements in rendering speed, model size, and training time. First, we optimize the rendering pipeline to precisely localize Gaussians in the scene, boosting rendering speed without altering visual fidelity. Second, we introduce a novel pruning technique and integrate it into the training pipeline, significantly reducing model size and training time while further raising rendering speed. Our Speedy-Splat approach combines these techniques to accelerate average rendering speed by a drastic 6.71× across scenes from the Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets with 10.6× fewer primitives than 3D-GS.

3D高斯散射（3D Gaussian Splatting, 3D-GS）是一种新兴的3D场景重建技术，通过将场景建模为可微分3D高斯的参数点云，实现了新视角的实时渲染。然而，其渲染速度和模型大小在资源受限的环境中仍然是瓶颈问题。
在本文中，我们识别并解决了3D-GS中的两个关键低效点，从而在渲染速度、模型大小和训练时间方面实现了显著改进。首先，我们优化了渲染管道，精准定位场景中的高斯，提高了渲染速度，同时保持视觉保真度不变。其次，我们引入了一种新颖的剪枝技术，并将其整合到训练管道中，大幅减少了模型大小和训练时间，同时进一步提升了渲染速度。
我们的方法Speedy-Splat结合了上述技术，将平均渲染速度提升了6.71倍，同时所需的高斯基元数量比3D-GS减少了10.6倍。实验在Mip-NeRF 360、Tanks & Temples和Deep Blending数据集上验证了这一性能。
