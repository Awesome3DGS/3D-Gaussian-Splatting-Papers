### econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians

The primary focus of most recent works on open-vocabulary neural fields is extracting precise semantic features from the VLMs and then consolidating them efficiently into a multi-view consistent 3D neural fields representation. However, most existing works over-trusted SAM to regularize image-level CLIP without any further refinement. Moreover, several existing works improved efficiency by dimensionality reduction of semantic features from 2D VLMs before fusing with 3DGS semantic fields, which inevitably leads to multi-view inconsistency. In this work, we propose econSG for open-vocabulary semantic segmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided Regularization (CRR) that mutually refines SAM and CLIP to get the best of both worlds for precise semantic features with complete and precise boundaries. 2) A low dimensional contextual space to enforce 3D multi-view consistency while improving computational efficiency by fusing backprojected multi-view 2D features and follow by dimensional reduction directly on the fused 3D features instead of operating on each 2D view separately. Our econSG shows state-of-the-art performance on four benchmark datasets compared to the existing methods. Furthermore, we are also the most efficient training among all the methods.

当前关于开放词汇神经场的大多数研究主要关注于从视觉语言模型（VLM）中提取精确的语义特征，并高效整合为多视角一致的三维神经场表示。然而，现有方法大多过于依赖 SAM 对图像级 CLIP 特征进行正则化，而未进行进一步细化。此外，一些方法在将二维语义特征融合到 3DGS 语义场之前，通过降维以提升效率，但这一过程往往会导致多视角语义不一致。
在本研究中，我们提出了 econSG，一种用于 3DGS 的开放词汇语义分割方法。econSG 包含一种置信区域引导的正则化机制（Confidence-region Guided Regularization, CRR），通过 SAM 和 CLIP 的相互细化，联合获取更具边界完整性和精确性的语义特征。我们还提出一种低维上下文空间，在融合回投的多视角二维特征后再对三维特征整体进行降维，从而同时提升多视角一致性和计算效率，避免在各个二维视图上分别处理。
在四个基准数据集上的实验结果表明，econSG 相较现有方法在语义分割任务上表现更优，同时也是目前训练效率最高的方法。
