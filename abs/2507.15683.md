### Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing

Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera pose from query images, is fundamental to remote sensing and UAV applications. Existing methods face inherent trade-offs: image-based retrieval and pose regression approaches lack precision, while structure-based methods that register queries to Structure-from-Motion (SfM) models suffer from computational complexity and limited scalability. These challenges are particularly pronounced in remote sensing scenarios due to large-scale scenes, high altitude variations, and domain gaps of existing visual priors. To overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel scene representation that compactly encodes both 3D geometry and appearance. We introduce Hi2-GSLoc, a dual-hierarchical relocalization framework that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting the rich semantic information and geometric constraints inherent in Gaussian primitives. To handle large-scale remote sensing scenarios, we incorporate partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic memory management strategies. Our approach consists of two stages: (1) a sparse stage featuring a Gaussian-specific consistent render-aware sampling strategy and landmark-guided detector for robust and accurate initial pose estimation, and (2) a dense stage that iteratively refines poses through coarse-to-fine dense rasterization matching while incorporating reliability verification. Through comprehensive evaluation on simulation data, public datasets, and real flight experiments, we demonstrate that our method delivers competitive localization accuracy, recall rate, and computational efficiency while effectively filtering unreliable pose estimates. The results confirm the effectiveness of our approach for practical remote sensing applications.

视觉重定位（Visual Relocalization）旨在根据查询图像估计六自由度（6-DoF）相机位姿，是遥感和无人机应用中的关键任务。现有方法存在固有的权衡：基于图像的检索与位姿回归方法精度不足，而基于结构的方法（将查询图像注册到结构自运动 Structure-from-Motion, SfM 模型）则存在计算复杂度高、可扩展性有限的问题。在遥感场景中，这些挑战尤为突出，因为场景规模巨大、高度变化显著，且现有视觉先验存在领域差异。为克服这些限制，我们引入三维高斯点渲染（3D Gaussian Splatting, 3DGS）作为一种新型场景表示方式，能够紧凑地同时编码三维几何与外观信息。我们提出了 Hi2-GSLoc，这是一种双层级重定位框架，遵循由稀到密、由粗到精的范式，充分利用高斯基元所蕴含的丰富语义信息与几何约束。针对大规模遥感场景，我们引入了分区高斯训练、GPU 加速的并行匹配以及动态内存管理策略。该方法包含两个阶段：（1）稀疏阶段，采用特定于高斯的一致渲染感知采样策略与地标引导检测器，以实现稳健且精确的初始位姿估计；（2）稠密阶段，通过由粗到精的稠密光栅化匹配迭代优化位姿，并结合可靠性验证机制。通过在模拟数据、公共数据集以及实飞实验中的全面评估，我们的方法在定位精度、召回率和计算效率方面均表现出竞争力，并能有效筛除不可靠的位姿估计。结果验证了该方法在实际遥感应用中的有效性。
