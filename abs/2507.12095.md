### BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images

Accurate 3D reconstruction of vehicles is vital for applications such as vehicle inspection, predictive maintenance, and urban planning. Existing methods like Neural Radiance Fields and Gaussian Splatting have shown impressive results but remain limited by their reliance on dense input views, which hinders real-world applicability. This paper addresses the challenge of reconstructing vehicles from sparse-view inputs, leveraging depth maps and a robust pose estimation architecture to synthesize novel views and augment training data. Specifically, we enhance Gaussian Splatting by integrating a selective photometric loss, applied only to high-confidence pixels, and replacing standard Structure-from-Motion pipelines with the DUSt3R architecture to improve camera pose estimation. Furthermore, we present a novel dataset featuring both synthetic and real-world public transportation vehicles, enabling extensive evaluation of our approach. Experimental results demonstrate state-of-the-art performance across multiple benchmarks, showcasing the method's ability to achieve high-quality reconstructions even under constrained input conditions.

精确的车辆三维重建对于车辆检测、预测性维护和城市规划等应用至关重要。现有方法（如神经辐射场 Neural Radiance Fields 和高斯投影 Gaussian Splatting）虽然在效果上表现出色，但依赖密集输入视图的特性限制了其在真实场景中的适用性。本文针对稀疏视图输入条件下的车辆重建挑战，利用深度图和鲁棒的位姿估计架构来合成新视角并扩充训练数据。具体而言，我们通过引入选择性光度损失（仅作用于高置信度像素）来增强高斯投影，并用 DUSt3R 架构替代标准的结构自运动（SfM）流程以提升相机位姿估计精度。此外，我们构建了一个包含合成与真实公共交通车辆的新数据集，用于全面评估所提方法。实验结果表明，该方法在多个基准测试中均达到了当前最先进水平，即使在输入受限的条件下，也能实现高质量的重建效果。
