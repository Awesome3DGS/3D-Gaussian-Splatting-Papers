### MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes

While controllable generative models for images and videos have achieved remarkable success, high-quality models for 3D scenes, particularly in unbounded scenarios like autonomous driving, remain underdeveloped due to high data acquisition costs. In this paper, we introduce MagicDrive3D, a novel pipeline for controllable 3D street scene generation that supports multi-condition control, including BEV maps, 3D objects, and text descriptions. Unlike previous methods that reconstruct before training the generative models, MagicDrive3D first trains a video generation model and then reconstructs from the generated data. This innovative approach enables easily controllable generation and static scene acquisition, resulting in high-quality scene reconstruction. To address the minor errors in generated content, we propose deformable Gaussian splatting with monocular depth initialization and appearance modeling to manage exposure discrepancies across viewpoints. Validated on the nuScenes dataset, MagicDrive3D generates diverse, high-quality 3D driving scenes that support any-view rendering and enhance downstream tasks like BEV segmentation. Our results demonstrate the framework's superior performance, showcasing its transformative potential for autonomous driving simulation and beyond.

虽然可控生成模型在图像和视频领域取得了显著的成功，但在无界限场景（如自动驾驶）中，高质量的3D场景模型仍然处于不发达状态，原因是数据获取成本高。在本文中，我们介绍了MagicDrive3D，这是一种新颖的可控3D街景生成流程，支持包括鸟瞰图（BEV）地图、3D对象和文本描述在内的多条件控制。与先前的方法不同，这些方法在训练生成模型之前进行重建，MagicDrive3D首先训练一个视频生成模型，然后从生成的数据进行重建。这种创新方法使得生成控制更加容易，并且能够获取静态场景，从而实现高质量的场景重建。为了解决生成内容中的小错误，我们提出了带有单目深度初始化和外观建模的可变形高斯投影，以管理不同视点之间的曝光差异。在nuScenes数据集上进行验证，MagicDrive3D生成了多样化的高质量3D驾驶场景，支持任意视角渲染，并增强了下游任务，如BEV分割。我们的结果展示了该框架的优越性能，展现了其对自动驾驶仿真及其它领域的变革潜力。

