### GP-GS: Gaussian Processes for Enhanced Gaussian Splatting

3D Gaussian Splatting has emerged as an efficient photorealistic novel view synthesis method. However, its reliance on sparse Structure-from-Motion (SfM) point clouds consistently compromises the scene reconstruction quality. To address these limitations, this paper proposes a novel 3D reconstruction framework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-output Gaussian Process model is developed to achieve adaptive and uncertainty-guided densification of sparse SfM point clouds. Specifically, we propose a dynamic sampling and filtering pipeline that adaptively expands the SfM point clouds by leveraging GP-based predictions to infer new candidate points from the input 2D pixels and depth maps. The pipeline utilizes uncertainty estimates to guide the pruning of high-variance predictions, ensuring geometric consistency and enabling the generation of dense point clouds. The densified point clouds provide high-quality initial 3D Gaussians to enhance reconstruction performance. Extensive experiments conducted on synthetic and real-world datasets across various scales validate the effectiveness and practicality of the proposed framework.

3D高斯溅射（3DGS）已成为一种高效的逼真新视角合成方法。然而，它对稀疏的结构光从运动（SfM）点云的依赖始终会影响场景重建的质量。为了解决这些局限性，本文提出了一种新颖的3D重建框架——高斯过程高斯溅射（GP-GS），在该框架中，开发了一个多输出高斯过程模型，以实现稀疏SfM点云的自适应和不确定性引导的密集化。具体而言，我们提出了一种动态采样和过滤管道，利用基于高斯过程的预测，通过从输入的2D像素和深度图推断新的候选点，自适应地扩展SfM点云。该管道利用不确定性估计来引导高方差预测的修剪，从而确保几何一致性并生成稠密的点云。这些密集化的点云提供了高质量的初始3D高斯，用于增强重建性能。在合成和真实世界数据集上进行的大量实验验证了所提出框架的有效性和实用性。
