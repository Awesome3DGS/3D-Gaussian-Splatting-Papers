### MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction

3D Gaussian Splatting (3DGS) has gained significant attention in streamable dynamic novel view synthesis (DNVS) for its photorealistic rendering capability and computational efficiency. Despite much progress in improving rendering quality and optimization strategies, 3DGS-based streamable dynamic scene reconstruction still suffers from flickering artifacts and storage inefficiency, and struggles to model the emerging objects. To tackle this, we introduce MGStream which employs the motion-related 3D Gaussians (3DGs) to reconstruct the dynamic and the vanilla 3DGs for the static. The motion-related 3DGs are implemented according to the motion mask and the clustering-based convex hull algorithm. The rigid deformation is applied to the motion-related 3DGs for modeling the dynamic, and the attention-based optimization on the motion-related 3DGs enables the reconstruction of the emerging objects. As the deformation and optimization are only conducted on the motion-related 3DGs, MGStream avoids flickering artifacts and improves the storage efficiency. Extensive experiments on real-world datasets N3DV and MeetRoom demonstrate that MGStream surpasses existing streaming 3DGS-based approaches in terms of rendering quality, training/storage efficiency and temporal consistency.

3D Gaussian Splatting（3DGS）因其真实感渲染能力与计算效率，在可流式动态新视角合成（Dynamic Novel View Synthesis, DNVS）领域受到广泛关注。尽管在渲染质量与优化策略方面已有诸多进展，基于 3DGS 的动态场景流式重建仍面临闪烁伪影、存储效率低以及难以建模新出现物体等问题。
为解决上述挑战，本文提出 MGStream，通过引入运动相关 3D 高斯（motion-related 3DGs）与静态 3D 高斯（vanilla 3DGs）实现对动态与静态区域的差异化建模。运动相关 3DGs 是基于运动掩码与基于聚类的凸包算法构建的。对于这些动态区域，高斯点施加刚性变形以建模运动，同时通过基于注意力机制的优化方法对运动相关 3DGs 进行调优，使系统能够有效重建新出现的物体。
由于变形与优化仅在运动相关高斯点上进行，MGStream 能够显著减少闪烁伪影，同时提升存储效率。在 N3DV 和 MeetRoom 等真实世界数据集上的大量实验证明，MGStream 在渲染质量、训练与存储效率以及时间一致性方面均优于现有的流式 3DGS 方法。
