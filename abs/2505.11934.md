### iSegMan: Interactive Segment-and-Manipulate 3D Gaussians

The efficient rendering and explicit nature of 3DGS promote the advancement of 3D scene manipulation. However, existing methods typically encounter challenges in controlling the manipulation region and are unable to furnish the user with interactive feedback, which inevitably leads to unexpected results. Intuitively, incorporating interactive 3D segmentation tools can compensate for this deficiency. Nevertheless, existing segmentation frameworks impose a pre-processing step of scene-specific parameter training, which limits the efficiency and flexibility of scene manipulation. To deliver a 3D region control module that is well-suited for scene manipulation with reliable efficiency, we propose interactive Segment-and-Manipulate 3D Gaussians (iSegMan), an interactive segmentation and manipulation framework that only requires simple 2D user interactions in any view. To propagate user interactions to other views, we propose Epipolar-guided Interaction Propagation (EIP), which innovatively exploits epipolar constraint for efficient and robust interaction matching. To avoid scene-specific training to maintain efficiency, we further propose the novel Visibility-based Gaussian Voting (VGV), which obtains 2D segmentations from SAM and models the region extraction as a voting game between 2D Pixels and 3D Gaussians based on Gaussian visibility. Taking advantage of the efficient and precise region control of EIP and VGV, we put forth a Manipulation Toolbox to implement various functions on selected regions, enhancing the controllability, flexibility and practicality of scene manipulation. Extensive results on 3D scene manipulation and segmentation tasks fully demonstrate the significant advantages of iSegMan.

3D Gaussian Splatting（3DGS）因其高效的渲染能力和显式表示形式，推动了三维场景操控的发展。然而，现有方法通常难以精确控制操控区域，且无法为用户提供交互式反馈，进而容易产生预期之外的结果。直观地，引入交互式三维分割工具有望弥补这一不足。然而，现有分割框架通常需要针对特定场景进行参数预训练，限制了场景操控的效率与灵活性。
为此，我们提出了 iSegMan（interactive Segment-and-Manipulate 3D Gaussians），一个交互式分割与操控框架，仅需用户在任意视角进行简单的二维交互即可完成操作。为将用户交互传播至其他视角，我们引入了极线引导交互传播（Epipolar-guided Interaction Propagation, EIP），创新性地利用极线约束实现高效且鲁棒的交互匹配。为避免因场景特定训练导致效率下降，我们进一步提出了基于可见性的高斯投票机制（Visibility-based Gaussian Voting, VGV），该机制基于 SAM 得到的二维分割结果，将区域提取建模为二维像素与三维高斯之间基于可见性的投票博弈过程。
借助 EIP 与 VGV 所实现的高效精准区域控制能力，我们构建了一个操控工具箱（Manipulation Toolbox），支持在选定区域上执行多种操作，显著提升了三维场景操控的可控性、灵活性与实用性。大量三维场景分割与操控任务的实验结果充分验证了 iSegMan 的显著优势。
