### Online 3D Gaussian Splatting Modeling with Novel View Selection

This study addresses the challenge of generating online 3D Gaussian Splatting (3DGS) models from RGB-only frames. Previous studies have employed dense SLAM techniques to estimate 3D scenes from keyframes for 3DGS model construction. However, these methods are limited by their reliance solely on keyframes, which are insufficient to capture an entire scene, resulting in incomplete reconstructions. Moreover, building a generalizable model requires incorporating frames from diverse viewpoints to achieve broader scene coverage. However, online processing restricts the use of many frames or extensive training iterations. Therefore, we propose a novel method for high-quality 3DGS modeling that improves model completeness through adaptive view selection. By analyzing reconstruction quality online, our approach selects optimal non-keyframes for additional training. By integrating both keyframes and selected non-keyframes, the method refines incomplete regions from diverse viewpoints, significantly enhancing completeness. We also present a framework that incorporates an online multi-view stereo approach, ensuring consistency in 3D information throughout the 3DGS modeling process. Experimental results demonstrate that our method outperforms state-of-the-art methods, delivering exceptional performance in complex outdoor scenes.

本研究针对仅使用 RGB 帧在线生成三维高斯喷溅（3DGS）模型的挑战展开探讨。以往研究多采用稠密 SLAM 技术从关键帧估计三维场景，用于 3DGS 模型构建。然而，这些方法仅依赖关键帧，无法完整覆盖整个场景，导致重建结果不完整。此外，为了构建具有泛化能力的模型，需要引入来自多视角的帧以实现更广的场景覆盖，但在线处理受到帧数量和训练迭代次数的限制。为此，我们提出了一种新方法，通过自适应视角选择提升 3DGS 建模的完整性。该方法在在线过程中分析重建质量，选取最优的非关键帧用于额外训练，并结合关键帧与所选非关键帧，从多视角修复不完整区域，从而显著提升重建完整度。我们还提出了一个结合在线多视图立体的框架，以确保 3DGS 建模过程中三维信息的一致性。实验结果表明，我们的方法优于现有的最新方法，在复杂的户外场景中表现出色。
