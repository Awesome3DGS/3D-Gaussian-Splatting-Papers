### DecompDreamer: Advancing Structured 3D Asset Generation with Multi-Object Decomposition and Gaussian Splatting

Text-to-3D generation saw dramatic advances in recent years by leveraging Text-to-Image models. However, most existing techniques struggle with compositional prompts, which describe multiple objects and their spatial relationships. They often fail to capture fine-grained inter-object interactions. We introduce DecompDreamer, a Gaussian splatting-based training routine designed to generate high-quality 3D compositions from such complex prompts. DecompDreamer leverages Vision-Language Models (VLMs) to decompose scenes into structured components and their relationships. We propose a progressive optimization strategy that first prioritizes joint relationship modeling before gradually shifting toward targeted object refinement. Our qualitative and quantitative evaluations against state-of-the-art text-to-3D models demonstrate that DecompDreamer effectively generates intricate 3D compositions with superior object disentanglement, offering enhanced control and flexibility in 3D generation.

近年来，通过利用文本到图像（Text-to-Image）模型，文本到三维（Text-to-3D）生成取得了显著进展。然而，大多数现有技术在处理组合性提示时存在困难，组合性提示描述了多个物体及其空间关系。这些技术通常难以捕捉物体间的细粒度交互。我们提出了DecompDreamer，一种基于高斯点云渲染的训练流程，旨在从这些复杂的提示中生成高质量的三维组合。DecompDreamer利用视觉语言模型（VLMs）将场景分解为结构化的组件及其关系。我们提出了一种渐进式优化策略，首先优先进行联合关系建模，然后逐步转向目标物体的精细化优化。我们与最先进的文本到三维模型进行了定性和定量评估，结果表明，DecompDreamer能够有效地生成复杂的三维组合，具有优越的物体解耦能力，在三维生成中提供了更强的控制力和灵活性。
