### Polysemous Language Gaussian Splatting via Matching-based Mask Lifting

Lifting 2D open-vocabulary understanding into 3D Gaussian Splatting (3DGS) scenes is a critical challenge. However, mainstream methods suffer from three key flaws: (i) their reliance on costly per-scene retraining prevents plug-and-play application; (ii) their restrictive monosemous design fails to represent complex, multi-concept semantics; and (iii) their vulnerability to cross-view semantic inconsistencies corrupts the final semantic representation. To overcome these limitations, we introduce MUSplat, a training-free framework that abandons feature optimization entirely. Leveraging a pre-trained 2D segmentation model, our pipeline generates and lifts multi-granularity 2D masks into 3D, where we estimate a foreground probability for each Gaussian point to form initial object groups. We then optimize the ambiguous boundaries of these initial groups using semantic entropy and geometric opacity. Subsequently, by interpreting the object's appearance across its most representative viewpoints, a Vision-Language Model (VLM) distills robust textual features that reconciles visual inconsistencies, enabling open-vocabulary querying via semantic matching. By eliminating the costly per-scene training process, MUSplat reduces scene adaptation time from hours to mere minutes. On benchmark tasks for open-vocabulary 3D object selection and semantic segmentation, MUSplat outperforms established training-based frameworks while simultaneously addressing their monosemous limitations.

将二维开放词汇理解提升到三维高斯溅射（3D Gaussian Splatting，3DGS）场景中是一项关键挑战。然而，主流方法存在三大缺陷：（i）依赖于高成本的逐场景重新训练，难以实现即插即用；（ii）受限于单义设计，无法表达复杂的多概念语义；（iii）易受跨视角语义不一致影响，从而破坏最终的语义表示。为克服这些限制，我们提出了 **MUSplat**，一个完全无训练的框架，彻底摒弃了特征优化过程。该方法利用预训练的二维分割模型生成多粒度的二维掩膜，并将其提升到三维空间，在此过程中为每个高斯点估计前景概率，从而形成初始的物体分组。随后，我们基于语义熵与几何不透明度对这些初始分组的模糊边界进行优化。接着，通过分析物体在其最具代表性的多个视角下的外观，视觉语言模型（Vision-Language Model，VLM）提炼出稳健的文本特征，从而协调视觉不一致性，实现基于语义匹配的开放词汇查询。通过消除昂贵的逐场景训练过程，MUSplat 将场景适配时间从数小时缩短至数分钟。在开放词汇三维物体选择与语义分割等基准任务上，MUSplat 在性能上超越了现有的基于训练的方法，同时有效解决了其单义语义限制问题。
