### Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians

Part segmentation and motion estimation are two fundamental problems for articulated object motion analysis. In this paper, we present a method to solve these two problems jointly from a sequence of observed point clouds of a single articulated object. The main challenge in our problem setting is that the point clouds are not assumed to be generated by a fixed set of moving points. Instead, each point cloud in the sequence could be an arbitrary sampling of the object surface at that particular time step. Such scenarios occur when the object undergoes major occlusions, or if the dataset is collected using measurements from multiple sensors asynchronously. In these scenarios, methods that rely on tracking point correspondences are not appropriate. We present an alternative approach based on a compact but effective representation where we represent the object as a collection of simple building blocks modeled as 3D Gaussians. We parameterize the Gaussians with time-dependent rotations, translations, and scales that are shared across all time steps. With our representation, part segmentation can be achieved by building correspondences between the observed points and the Gaussians. Moreover, the transformation of each point across time can be obtained by following the poses of the assigned Gaussian (even when the point is not observed). Experiments show that our method outperforms existing methods that solely rely on finding point correspondences. Additionally, we extend existing datasets to emulate real-world scenarios by considering viewpoint occlusions. We further demonstrate that our method is more robust to missing points as compared to existing approaches on these challenging datasets, even when some parts are completely occluded in some time-steps. Notably, our part segmentation performance outperforms the state-of-the-art method by 13% on point clouds with occlusions.

部件分割和运动估计是解析关节物体运动的两个基本问题。本文提出了一种方法，可从单个关节物体的一系列观测点云中联合解决这两个问题。我们所面临的主要挑战在于：这些点云并不假设来自一组固定移动点的生成。相反，序列中的每一帧点云都可能是该时间点上物体表面的任意采样。这种情况在物体发生大遮挡，或数据由多个异步传感器采集时尤为常见。在这类场景中，依赖点对应关系追踪的方法将难以奏效。为此，我们提出了一种基于紧凑且高效表示的替代方案，即将物体表示为由多个简单构件组成的集合，每个构件建模为一个三维高斯分布。我们使用随时间变化的旋转、平移和缩放参数对这些高斯分布进行建模，这些参数在所有时间步间共享。通过这种表示方式，可通过构建观测点与高斯之间的对应关系实现部件分割。同时，即便某些点在特定时间步中未被观测，也可通过追踪其所归属的高斯的姿态来获得该点的时序变换。实验表明，我们的方法优于仅依赖点对应关系的方法。此外，我们还扩展了现有数据集，通过引入视角遮挡模拟真实场景。进一步实验表明，在这些具有挑战性的数据集中，即便某些部件在某些时间步中完全被遮挡，我们的方法相比现有方法对点缺失更具鲁棒性。值得注意的是，在存在遮挡的点云数据上，我们的部件分割性能相比现有最先进方法提升了 13%。
