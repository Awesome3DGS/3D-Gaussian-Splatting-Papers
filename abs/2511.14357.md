### IBGS: Image-Based Gaussian Splatting

3D Gaussian Splatting (3DGS) has recently emerged as a fast, high-quality method for novel view synthesis (NVS). However, its use of low-degree spherical harmonics limits its ability to capture spatially varying color and view-dependent effects such as specular highlights. Existing works augment Gaussians with either a global texture map, which struggles with complex scenes, or per-Gaussian texture maps, which introduces high storage overhead. We propose Image-Based Gaussian Splatting, an efficient alternative that leverages high-resolution source images for fine details and view-specific color modeling. Specifically, we model each pixel color as a combination of a base color from standard 3DGS rendering and a learned residual inferred from neighboring training images. This promotes accurate surface alignment and enables rendering images of high-frequency details and accurate view-dependent effects. Experiments on standard NVS benchmarks show that our method significantly outperforms prior Gaussian Splatting approaches in rendering quality, without increasing the storage footprint.

三维高斯投影（3D Gaussian Splatting, 3DGS）近期作为一种快速且高质量的新视角合成（Novel View Synthesis, NVS）方法获得广泛关注。然而，3DGS 采用的低阶球谐函数限制了其对空间变化颜色与视角相关效果（如镜面高光）的建模能力。现有方法通常通过全局纹理图进行增强，但在复杂场景中表现不佳；或为每个高斯图元引入独立纹理图，虽能提升表现，但存储开销巨大。为此，我们提出了一种高效替代方案——基于图像的高斯投影（Image-Based Gaussian Splatting）。该方法利用高分辨率原始图像建模细节与视角特有颜色信息。具体而言，我们将每个像素的颜色表示为标准 3DGS 渲染结果与来自相邻训练图像推断的残差项之和。这一机制有助于提升表面对齐精度，并实现高频细节和准确的视角相关效果渲染。在标准 NVS 基准上的实验表明，该方法在不增加存储开销的前提下，显著优于现有高斯投影方法的渲染质量。
