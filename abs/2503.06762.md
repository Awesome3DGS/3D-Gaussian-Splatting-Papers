### Gaussian RBFNet: Gaussian Radial Basis Functions for Fast and Accurate Representation and Reconstruction of Neural Fields

Neural fields such as DeepSDF and Neural Radiance Fields have recently revolutionized novel-view synthesis and 3D reconstruction from RGB images and videos. However, achieving high-quality representation, reconstruction, and rendering requires deep neural networks, which are slow to train and evaluate. Although several acceleration techniques have been proposed, they often trade off speed for memory. Gaussian splatting-based methods, on the other hand, accelerate the rendering time but remain costly in terms of training speed and memory needed to store the parameters of a large number of Gaussians. In this paper, we introduce a novel neural representation that is fast, both at training and inference times, and lightweight. Our key observation is that the neurons used in traditional MLPs perform simple computations (a dot product followed by ReLU activation) and thus one needs to use either wide and deep MLPs or high-resolution and high-dimensional feature grids to parameterize complex nonlinear functions. We show in this paper that by replacing traditional neurons with Radial Basis Function (RBF) kernels, one can achieve highly accurate representation of 2D (RGB images), 3D (geometry), and 5D (radiance fields) signals with just a single layer of such neurons. The representation is highly parallelizable, operates on low-resolution feature grids, and is compact and memory-efficient. We demonstrate that the proposed novel representation can be trained for 3D geometry representation in less than 15 seconds and for novel view synthesis in less than 15 mins. At runtime, it can synthesize novel views at more than 60 fps without sacrificing quality.

神经场（Neural Fields） 技术，如 DeepSDF 和 神经辐射场（Neural Radiance Fields, NeRF），近年来在新视角合成（novel-view synthesis）和三维重建（3D reconstruction）方面取得了突破性进展。然而，要实现高质量的表示、重建和渲染，通常需要依赖深度神经网络，导致训练和推理速度较慢。尽管已有多个加速方法被提出，但它们往往在速度与内存占用之间做出权衡。
相比之下，基于高斯散点（Gaussian Splatting）的方法加速了渲染过程，但仍然存在训练速度慢和存储大量高斯参数所需的内存开销高的问题。
在本文中，我们提出了一种新颖的神经表示方法，在训练和推理阶段均具有高效性，同时占用更少的存储。我们发现，传统的 MLP 神经元执行的计算相对简单（点积 + ReLU 激活），因此通常需要宽且深的 MLP 或 高分辨率高维特征网格 来表示复杂的非线性函数。本文表明，将传统神经元替换为径向基函数（Radial Basis Function, RBF）核，可以在单层神经元的情况下实现高精度的 2D（RGB 图像）、3D（几何）、以及 5D（辐射场）信号表示。
我们的方法高度并行化，可在低分辨率特征网格上运行，并且紧凑且内存高效。实验表明，该方法可在 15 秒内完成 3D 几何训练，在 15 分钟内完成新视角合成训练，并且在运行时能够以 60+ fps 生成新视角，而不会牺牲渲染质量。
