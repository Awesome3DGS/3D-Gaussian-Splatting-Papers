### Realistic and Controllable 3D Gaussian-Guided Object Editing for Driving Video Generation

Corner cases are crucial for training and validating autonomous driving systems, yet collecting them from the real world is often costly and hazardous. Editing objects within captured sensor data offers an effective alternative for generating diverse scenarios, commonly achieved through 3D Gaussian Splatting or image generative models. However, these approaches often suffer from limited visual fidelity or imprecise pose control. To address these issues, we propose G^2Editor, a framework designed for photorealistic and precise object editing in driving videos. Our method leverages a 3D Gaussian representation of the edited object as a dense prior, injected into the denoising process to ensure accurate pose control and spatial consistency. A scene-level 3D bounding box layout is employed to reconstruct occluded areas of non-target objects. Furthermore, to guide the appearance details of the edited object, we incorporate hierarchical fine-grained features as additional conditions during generation. Experiments on the Waymo Open Dataset demonstrate that G^2Editor effectively supports object repositioning, insertion, and deletion within a unified framework, outperforming existing methods in both pose controllability and visual quality, while also benefiting downstream data-driven tasks.

边缘场景对于自动驾驶系统的训练和验证至关重要，但在真实世界中采集此类数据往往代价高昂且存在风险。在已采集的传感器数据中编辑对象是一种生成多样化场景的有效替代方案，通常通过三维高斯点绘（3D Gaussian Splatting）或图像生成模型实现。然而，这些方法常常受到视觉保真度有限或位姿控制不精确的困扰。为解决这些问题，我们提出了 **G^2Editor**，一个用于驾驶视频中逼真且精确对象编辑的框架。我们的方法利用编辑对象的三维高斯表示作为稠密先验，并将其注入去噪过程，从而确保位姿控制的准确性和空间一致性。同时，我们引入场景级三维包围盒布局，用于重建非目标对象的遮挡区域。此外，为了引导编辑对象的外观细节，我们在生成过程中加入了分层细粒度特征作为附加条件。在 Waymo Open Dataset 上的实验表明，G^2Editor 能够在统一框架下有效支持对象的重定位、插入与删除，在位姿可控性和视觉质量方面均优于现有方法，并能进一步促进下游数据驱动任务。
