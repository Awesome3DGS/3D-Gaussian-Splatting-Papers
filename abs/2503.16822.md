### RigGS: Rigging of 3D Gaussians for Modeling Articulated Objects in Videos

This paper considers the problem of modeling articulated objects captured in 2D videos to enable novel view synthesis, while also being easily editable, drivable, and re-posable. To tackle this challenging problem, we propose RigGS, a new paradigm that leverages 3D Gaussian representation and skeleton-based motion representation to model dynamic objects without utilizing additional template priors. Specifically, we first propose skeleton-aware node-controlled deformation, which deforms a canonical 3D Gaussian representation over time to initialize the modeling process, producing candidate skeleton nodes that are further simplified into a sparse 3D skeleton according to their motion and semantic information. Subsequently, based on the resulting skeleton, we design learnable skin deformations and pose-dependent detailed deformations, thereby easily deforming the 3D Gaussian representation to generate new actions and render further high-quality images from novel views. Extensive experiments demonstrate that our method can generate realistic new actions easily for objects and achieve high-quality rendering.

本文探讨了如何建模捕捉到的 2D 视频中的关节化物体，以实现新视角合成，同时使其易于编辑、驱动和重新定位。为了解决这一挑战性问题，我们提出了 RigGS，一种新的方法，它利用 3D 高斯表示 和 基于骨架的运动表示 来建模动态物体，而不需要额外的模板先验。
具体而言，我们首先提出了骨架感知的节点控制形变，该方法随时间对标准 3D 高斯表示进行形变，初始化建模过程，生成候选的骨架节点，这些节点根据其运动和语义信息进一步简化为稀疏的 3D 骨架。接下来，基于得到的骨架，我们设计了可学习的皮肤形变和姿态依赖的详细形变，从而轻松地对 3D 高斯表示进行形变，生成新的动作，并从新的视角渲染出更高质量的图像。
大量实验表明，我们的方法能够轻松生成物体的新动作，并实现高质量渲染。
