### Lumos3D: A Single-Forward Framework for Low-Light 3D Scene Restoration

Restoring 3D scenes captured under low-light con- ditions remains a fundamental yet challenging problem. Most existing approaches depend on precomputed camera poses and scene-specific optimization, which greatly restricts their scala- bility to dynamic real-world environments. To overcome these limitations, we introduce Lumos3D, a generalizable pose-free framework for 3D low-light scene restoration. Trained once on a single dataset, Lumos3D performs inference in a purely feed- forward manner, directly restoring illumination and structure from unposed, low-light multi-view images without any per- scene training or optimization. Built upon a geometry-grounded backbone, Lumos3D reconstructs a normal-light 3D Gaussian representation that restores illumination while faithfully pre- serving structural details. During training, a cross-illumination distillation scheme is employed, where the teacher network is distilled on normal-light ground truth to transfer accurate geometric information, such as depth, to the student model. A dedicated Lumos loss is further introduced to promote photomet- ric consistency within the reconstructed 3D space. Experiments on real-world datasets demonstrate that Lumos3D achieves high- fidelity low-light 3D scene restoration with accurate geometry and strong generalization to unseen cases. Furthermore, the framework naturally extends to handle over-exposure correction, highlighting its versatility for diverse lighting restoration tasks.

在低照度条件下采集的三维场景恢复仍然是一个基础而具有挑战性的问题。现有大多数方法依赖于**预先计算的相机位姿**以及**针对单一场景的优化过程**，这在很大程度上限制了其在动态真实环境中的可扩展性。
为克服这些局限，我们提出了 **Lumos3D**，一种具有良好泛化能力的、**无需位姿**的三维低照度场景恢复框架。Lumos3D 仅需在单一数据集上训练一次，即可在推理阶段以**纯前向传播**的方式工作，直接从**无位姿的低照度多视图图像**中恢复照明与结构，而无需任何逐场景训练或优化。
基于以几何为基础的网络骨干，Lumos3D 重建出一种**正常照度下的三维高斯表示**，在恢复照明的同时忠实地保留结构细节。在训练过程中，我们采用了一种**跨照度蒸馏策略**，即在正常照度真实数据上对教师网络进行蒸馏，将准确的几何信息（如深度）传递给学生模型。此外，我们还引入了一种专门的 **Lumos 损失**，以促进重建三维空间内的**光度一致性**。
在真实世界数据集上的实验表明，Lumos3D 能够实现**高保真的低照度三维场景恢复**，具备准确的几何重建能力，并对未见过的场景表现出很强的**泛化性**。进一步地，该框架还可以自然地扩展用于**过曝光校正**，体现了其在多种照明恢复任务中的通用性与灵活性。
