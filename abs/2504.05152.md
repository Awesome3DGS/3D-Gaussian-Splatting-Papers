### PanoDreamer: Consistent Text to 360-Degree Scene Generation

Automatically generating a complete 3D scene from a text description, a reference image, or both has significant applications in fields like virtual reality and gaming. However, current methods often generate low-quality textures and inconsistent 3D structures. This is especially true when extrapolating significantly beyond the field of view of the reference image. To address these challenges, we propose PanoDreamer, a novel framework for consistent, 3D scene generation with flexible text and image control. Our approach employs a large language model and a warp-refine pipeline, first generating an initial set of images and then compositing them into a 360-degree panorama. This panorama is then lifted into 3D to form an initial point cloud. We then use several approaches to generate additional images, from different viewpoints, that are consistent with the initial point cloud and expand/refine the initial point cloud. Given the resulting set of images, we utilize 3D Gaussian Splatting to create the final 3D scene, which can then be rendered from different viewpoints. Experiments demonstrate the effectiveness of PanoDreamer in generating high-quality, geometrically consistent 3D scenes.

从文本描述、参考图像，或两者结合中自动生成完整的三维场景，在虚拟现实和游戏等领域具有广泛的应用前景。然而，当前的方法往往存在纹理质量差、三维结构不一致等问题，尤其在对参考图像视野范围外区域进行外推时更为明显。
为应对这些挑战，我们提出了 PanoDreamer——一个支持文本与图像灵活控制的全新框架，旨在实现一致性的三维场景生成。该方法采用大语言模型结合“变形-细化”流程，首先生成初始图像集，并将其合成为360度全景图。该全景图随后被“升维”成三维初始点云。
接着，系统使用多种策略，从不同视角生成与初始点云一致的附加图像，以进一步扩展并细化点云。最终，我们利用3D Gaussian Splatting将生成图像转换为最终的三维场景，可从多个视角进行渲染。
实验结果表明，PanoDreamer 能有效生成高质量且几何一致的三维场景，展现出强大的跨模态场景生成能力。
