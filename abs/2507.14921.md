### Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction

Generalizable 3D Gaussian Splatting reconstruction showcases advanced Image-to-3D content creation but requires substantial computational resources and large datasets, posing challenges to training models from scratch. Current methods usually entangle the prediction of 3D Gaussian geometry and appearance, which rely heavily on data-driven priors and result in slow regression speeds. To address this, we propose  Stereo-GS, a disentangled framework for efficient 3D Gaussian prediction. Our method extracts features from local image pairs using a stereo vision backbone and fuses them via global attention blocks. Dedicated point and Gaussian prediction heads generate multi-view point-maps for geometry and Gaussian features for appearance, combined as GS-maps to represent the 3DGS object. A refinement network enhances these GS-maps for high-quality reconstruction. Unlike existing methods that depend on camera parameters, our approach achieves pose-free 3D reconstruction, improving robustness and practicality. By reducing resource demands while maintaining high-quality outputs,  Stereo-GS provides an efficient, scalable solution for real-world 3D content generation.

具有泛化能力的三维高斯点渲染（3D Gaussian Splatting, 3DGS）重建展示了先进的图像到三维内容生成能力，但其训练通常需要大量计算资源和海量数据集，这对从零开始训练模型带来了挑战。现有方法通常将三维高斯的几何与外观预测耦合在一起，过度依赖数据驱动的先验，并导致回归速度缓慢。为此，我们提出了 Stereo-GS，这是一种高效的三维高斯解耦预测框架。该方法利用双目视觉骨干网络从局部图像对中提取特征，并通过全局注意力模块进行融合；专用的点预测头与高斯预测头分别生成用于几何的多视角点图（point-maps）和用于外观的高斯特征，这些特征组合成 GS-maps 以表示 3DGS 对象。随后，精化网络对 GS-maps 进行增强，以实现高质量重建。与依赖相机参数的现有方法不同，我们的方法能够实现无位姿的三维重建，从而提升了鲁棒性与实用性。在降低资源需求的同时保持高质量输出，Stereo-GS 为现实世界的三维内容生成提供了一种高效且可扩展的解决方案。
