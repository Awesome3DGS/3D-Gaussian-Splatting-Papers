### CUS-GS: A Compact Unified Structured Gaussian Splatting Framework for Multimodal Scene Representation

Recent advances in Gaussian Splatting based 3D scene representation have shown two major trends: semantics-oriented approaches that focus on high-level understanding but lack explicit 3D geometry modeling, and structure-oriented approaches that capture spatial structures yet provide limited semantic abstraction. To bridge this gap, we present CUS-GS, a compact unified structured Gaussian Splatting representation, which connects multimodal semantic features with structured 3D geometry. Specifically, we design a voxelized anchor structure that constructs a spatial scaffold, while extracting multimodal semantic features from a set of foundation models (e.g., CLIP, DINOv2, SEEM). Moreover, we introduce a multimodal latent feature allocation mechanism to unify appearance, geometry, and semantics across heterogeneous feature spaces, ensuring a consistent representation across multiple foundation models. Finally, we propose a feature-aware significance evaluation strategy to dynamically guide anchor growing and pruning, effectively removing redundant or invalid anchors while maintaining semantic integrity. Extensive experiments show that CUS-GS achieves competitive performance compared to state-of-the-art methods using as few as 6M parameters - an order of magnitude smaller than the closest rival at 35M - highlighting the excellent trade off between performance and model efficiency of the proposed framework.

近年来，基于高斯溅射的三维场景表示研究呈现出两大趋势：一类是以语义为导向的方法，侧重高层次理解但缺乏显式的三维几何建模；另一类则是以结构为导向的方法，注重空间结构捕捉但语义抽象能力有限。为弥合这一差距，我们提出了 CUS-GS（紧凑统一结构化高斯溅射表示），该方法将多模态语义特征与结构化三维几何进行融合。具体而言，我们设计了一种体素化锚点结构，作为空间骨架，并从一系列基础模型（如 CLIP、DINOv2、SEEM）中提取多模态语义特征。同时，我们引入了一种多模态潜特征分配机制，实现对外观、几何和语义在异构特征空间中的统一编码，确保跨模型表示的一致性。最后，我们提出了一种感知特征重要性的锚点评估策略，可动态引导锚点的生长与裁剪，有效剔除冗余或无效锚点，同时保持语义完整性。大量实验结果表明，CUS-GS 在仅使用 600 万参数的情况下即可达到与最先进方法相媲美的性能——相比之下，最接近的对比方法需使用 3500 万参数，凸显了该框架在性能与模型效率之间的卓越平衡。
