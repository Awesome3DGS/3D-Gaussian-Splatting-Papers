### Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular Videos

Modern 3D engines and graphics pipelines require mesh as a memory-efficient representation, which allows efficient rendering, geometry processing, texture editing, and many other downstream operations. However, it is still highly difficult to obtain high-quality mesh in terms of structure and detail from monocular visual observations. The problem becomes even more challenging for dynamic scenes and objects. To this end, we introduce Dynamic Gaussians Mesh (DG-Mesh), a framework to reconstruct a high-fidelity and time-consistent mesh given a single monocular video. Our work leverages the recent advancement in 3D Gaussian Splatting to construct the mesh sequence with temporal consistency from a video. Building on top of this representation, DG-Mesh recovers high-quality meshes from the Gaussian points and can track the mesh vertices over time, which enables applications such as texture editing on dynamic objects. We introduce the Gaussian-Mesh Anchoring, which encourages evenly distributed Gaussians, resulting better mesh reconstruction through mesh-guided densification and pruning on the deformed Gaussians. By applying cycle-consistent deformation between the canonical and the deformed space, we can project the anchored Gaussian back to the canonical space and optimize Gaussians across all time frames. During the evaluation on different datasets, DG-Mesh provides significantly better mesh reconstruction and rendering than baselines.

现代三维引擎和图形管线需要使用网格作为一种存储高效的表现形式，这使得渲染、几何处理、纹理编辑以及许多其他下游操作变得更加高效。然而，从单目视觉观察中获得高质量的网格在结构和细节上仍然是非常困难的。这个问题在动态场景和对象上尤其具有挑战性。为此，我们引入了动态高斯网格（Dynamic Gaussians Mesh，简称 DG-Mesh）框架，该框架可以基于单个单目视频重建出高保真且时间连贯的网格。我们的工作利用了最新的三维高斯喷溅技术（3D Gaussian Splatting），从视频中构建具有时间一致性的网格序列。在这种表现形式的基础上，DG-Mesh 从高斯点恢复出高质量的网格，并能够随时间追踪网格顶点，这使得它能够应用于动态对象的纹理编辑。我们引入了高斯-网格锚定技术，该技术鼓励高斯点均匀分布，通过对变形高斯的网格引导的密集化和修剪，实现更好的网格重建。通过在规范空间和变形空间之间应用循环一致的变形，我们可以将锚定的高斯点投影回规范空间，并在所有时间帧上优化高斯点。在不同数据集上的评估中，DG-Mesh 在网格重建和渲染方面比基准模型表现出显著的改进。
