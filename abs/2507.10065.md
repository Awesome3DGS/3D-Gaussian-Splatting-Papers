### MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second

We present MoVieS, a novel feed-forward model that synthesizes 4D dynamic novel views from monocular videos in one second. MoVieS represents dynamic 3D scenes using pixel-aligned grids of Gaussian primitives, explicitly supervising their time-varying motion. This allows, for the first time, the unified modeling of appearance, geometry and motion, and enables view synthesis, reconstruction and 3D point tracking within a single learning-based framework. By bridging novel view synthesis with dynamic geometry reconstruction, MoVieS enables large-scale training on diverse datasets with minimal dependence on task-specific supervision. As a result, it also naturally supports a wide range of zero-shot applications, such as scene flow estimation and moving object segmentation. Extensive experiments validate the effectiveness and efficiency of MoVieS across multiple tasks, achieving competitive performance while offering several orders of magnitude speedups.

我们提出了 MoVieS，这是一种新型前馈式模型，能够在一秒内从单目视频合成四维动态新视角。MoVieS 使用与像素对齐的高斯基元网格表示动态三维场景，并显式监督其随时间变化的运动。这首次实现了在单一的学习框架中对外观、几何与运动的统一建模，并支持视图合成、重建与三维点跟踪。通过将新视角合成与动态几何重建相结合，MoVieS 能够在多样化数据集上进行大规模训练，并且对特定任务的监督依赖极低。因此，它还能自然地支持多种零样本应用，如场景流估计和运动物体分割。大量实验证明，MoVieS 在多个任务中都具有高效且有效的表现，在保持竞争性性能的同时实现了数量级的速度提升。
