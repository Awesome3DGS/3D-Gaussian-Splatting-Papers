### ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos

Achieving truly practical dynamic 3D reconstruction requires online operation, global pose and map consistency, detailed appearance modeling, and the flexibility to handle both RGB and RGB-D inputs. However, existing SLAM methods typically merely remove the dynamic parts or require RGB-D input, while offline methods are not scalable to long video sequences, and current transformer-based feedforward methods lack global consistency and appearance details. To this end, we achieve online dynamic scene reconstruction by disentangling the static and dynamic parts within a SLAM system. The poses are tracked robustly with a novel motion masking strategy, and dynamic parts are reconstructed leveraging a progressive adaptation of a Motion Scaffolds graph. Our method yields novel view renderings competitive to offline methods and achieves on-par tracking with state-of-the-art dynamic SLAM methods.

要实现真正实用的动态三维重建，需要具备在线处理能力、全局位姿与地图一致性、精细的外观建模，以及同时兼容 RGB 与 RGB-D 输入的灵活性。然而，现有的 SLAM 方法通常仅简单地去除动态部分或依赖于 RGB-D 输入；而离线方法无法扩展到长视频序列，当前基于 Transformer 的前馈方法又缺乏全局一致性与外观细节。为此，我们通过在 SLAM 系统中解耦静态与动态部分，实现了在线动态场景重建。我们提出了一种新的运动遮罩策略以实现稳健的位姿跟踪，并利用逐步自适应的运动支架图（Motion Scaffolds Graph）对动态部分进行重建。实验结果表明，我们的方法在新视图渲染质量上可与离线方法相媲美，并在跟踪性能上达到当前动态 SLAM 最先进水平。
