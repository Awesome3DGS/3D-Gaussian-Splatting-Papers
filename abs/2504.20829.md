### GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion

As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene representation and novel view synthesis, its rapid adoption in safety-critical domains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of potential security vulnerabilities. This paper presents the first systematic study of backdoor threats in 3DGS pipelines. We identify that adversaries may implant backdoor views to induce malicious scene confusion during inference, potentially leading to environmental misperception in autonomous navigation or spatial distortion in immersive environments. To uncover this risk, we propose GuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap injects malicious views at specific attack viewpoints while preserving high-quality rendering in non-target views, ensuring minimal detectability and maximizing potential harm. Specifically, the proposed method consists of a three-stage pipeline (attack, stabilization, and normal training) to implant stealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing attack efficacy and perceptual realism to expose security risks in 3D rendering. Extensive experiments on both synthetic and real-world datasets demonstrate that GuassTrap can effectively embed imperceptible yet harmful backdoor views while maintaining high-quality rendering in normal views, validating its robustness, adaptability, and practical applicability.

随着三维高斯泼溅（3D Gaussian Splatting, 3DGS）作为场景表示与新视角合成领域的突破性技术迅速兴起，其在自动驾驶系统、增强现实/虚拟现实（AR/VR）等安全关键领域的快速应用也引发了对潜在安全漏洞的紧迫关注。本文首次对 3DGS 流水线中的后门攻击威胁进行了系统性研究。
我们发现，攻击者可能通过植入后门视角，在推理阶段诱发恶意场景混淆，从而在自动导航中导致环境误感知，或在沉浸式环境中引发空间畸变。为揭示这一风险，本文提出 GuassTrap，一种针对 3DGS 模型的全新投毒攻击方法。GuassTrap 在特定攻击视角注入恶意视图，同时在非目标视角保持高质量渲染，确保攻击隐蔽性最大化并实现潜在危害最大化。
具体而言，该方法包括三个阶段的流水线：攻击阶段、稳定阶段和正常训练阶段，以在 3DGS 表示中植入隐蔽、视角一致的投毒渲染结果。该方法联合优化攻击效果与感知真实感，揭示了 3D 渲染中的安全风险。
在合成与真实数据集上的大量实验证明，GuassTrap 能够有效嵌入不可察觉但具破坏性的后门视图，同时维持正常视角下的高质量渲染，验证了其鲁棒性、适应性和实际应用价值。
