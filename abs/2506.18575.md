### 2D Triangle Splatting for Direct Differentiable Mesh Training

Differentiable rendering with 3D Gaussian primitives has emerged as a powerful method for reconstructing high-fidelity 3D scenes from multi-view images. While it offers improvements over NeRF-based methods, this representation still encounters challenges with rendering speed and advanced rendering effects, such as relighting and shadow rendering, compared to mesh-based models. In this paper, we propose 2D Triangle Splatting (2DTS), a novel method that replaces 3D Gaussian primitives with 2D triangle facelets. This representation naturally forms a discrete mesh-like structure while retaining the benefits of continuous volumetric modeling. By incorporating a compactness parameter into the triangle primitives, we enable direct training of photorealistic meshes. Our experimental results demonstrate that our triangle-based method, in its vanilla version (without compactness tuning), achieves higher fidelity compared to state-of-the-art Gaussian-based methods. Furthermore, our approach produces reconstructed meshes with superior visual quality compared to existing mesh reconstruction methods.

基于三维高斯基元的可微渲染已成为从多视图图像重建高保真三维场景的有力方法。尽管相比基于 NeRF 的方法有所提升，这种表示在渲染速度以及再光照、阴影渲染等高级渲染效果方面，仍不及基于网格的模型。本文提出了一种全新的方法——**二维三角溅射（2D Triangle Splatting, 2DTS）**，将三维高斯基元替换为二维三角面元。该表示形式天然构成离散的类网格结构，同时保留了连续体积建模的优点。通过在三角基元中引入**紧致度参数**，我们能够直接训练出照片级真实感的网格模型。实验结果表明，在未进行紧致度调优的基础版本中，我们的基于三角形的方法在保真度上优于当前最先进的基于高斯的方法。此外，与现有的网格重建方法相比，我们的方法生成的重建网格在视觉质量上也更为优越。
