### PromptVFX: Text-Driven Fields for Open-World 3D Gaussian Animation

Visual effects (VFX) are key to immersion in modern films, games, and AR/VR. Creating 3D effects requires specialized expertise and training in 3D animation software and can be time consuming. Generative solutions typically rely on computationally intense methods such as diffusion models which can be slow at 4D inference. We reformulate 3D animation as a field prediction task and introduce a text-driven framework that infers a time-varying 4D flow field acting on 3D Gaussians. By leveraging large language models (LLMs) and vision-language models (VLMs) for function generation, our approach interprets arbitrary prompts (e.g., "make the vase glow orange, then explode") and instantly updates color, opacity, and positions of 3D Gaussians in real time. This design avoids overheads such as mesh extraction, manual or physics-based simulations and allows both novice and expert users to animate volumetric scenes with minimal effort on a consumer device even in a web browser. Experimental results show that simple textual instructions suffice to generate compelling time-varying VFX, reducing the manual effort typically required for rigging or advanced modeling. We thus present a fast and accessible pathway to language-driven 3D content creation that can pave the way to democratize VFX further.

视觉特效（VFX）是现代电影、游戏和 AR/VR 中沉浸感的关键。然而，3D 特效的制作通常依赖于专业的 3D 动画软件和复杂的操作流程，需要大量专业知识与训练，耗时且成本高。现有生成式解决方案大多依赖计算密集型方法（如扩散模型），在执行 4D 推理时速度较慢。
本文将 3D 动画重新表述为一个场预测任务，并提出一个文本驱动的框架，可对作用于 3D 高斯的时变 4D 流场进行推理。该方法利用大语言模型（LLMs）与视觉语言模型（VLMs）进行函数生成，能够理解任意自然语言提示（如：“让花瓶变成橙色发光，然后爆炸”），并实时更新 3D 高斯的颜色、不透明度和位置。
该设计规避了网格提取、手工建模或基于物理的模拟等传统开销，使得无论是初学者还是专家用户，都能在消费级设备（甚至是网页浏览器中）以最小成本创建体积动画场景。
实验结果表明，仅凭简单的文本指令即可生成令人信服的时变视觉特效，大幅降低了以往对绑定骨骼（rigging）或高级建模的手动依赖。因此，我们提供了一种快速且易用的语言驱动 3D 内容创作路径，为视觉特效的普及与民主化铺平了道路。
