### iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion

Recent trends in SLAM and visual navigation have embraced 3D Gaussians as the preferred scene representation, highlighting the importance of estimating camera poses from a single image using a pre-built Gaussian model. However, existing approaches typically rely on an iterative \textit{render-compare-refine} loop, where candidate views are first rendered using NeRF or Gaussian Splatting, then compared against the target image, and finally, discrepancies are used to update the pose. This multi-round process incurs significant computational overhead, hindering real-time performance in robotics. In this paper, we propose iGaussian, a two-stage feed-forward framework that achieves real-time camera pose estimation through direct 3D Gaussian inversion. Our method first regresses a coarse 6DoF pose using a Gaussian Scene Prior-based Pose Regression Network with spatial uniform sampling and guided attention mechanisms, then refines it through feature matching and multi-model fusion. The key contribution lies in our cross-correlation module that aligns image embeddings with 3D Gaussian attributes without differentiable rendering, coupled with a Weighted Multiview Predictor that fuses features from Multiple strategically sampled viewpoints. Experimental results on the NeRF Synthetic, Mip-NeRF 360, and T\&T+DB datasets demonstrate a significant performance improvement over previous methods, reducing median rotation errors to 0.2° while achieving 2.87 FPS tracking on mobile robots, which is an impressive 10 times speedup compared to optimization-based approaches.

近年来，SLAM 与视觉导航领域日益采用三维高斯作为首选的场景表示方式，这凸显了基于预构建高斯模型从单张图像估计相机位姿的重要性。然而，现有方法普遍依赖迭代式的“渲染-比较-优化（render-compare-refine）”流程：先使用 NeRF 或 Gaussian Splatting 渲染候选视角图像，再与目标图像进行比较，最后根据差异迭代更新相机位姿。这种多轮循环计算开销巨大，严重限制了机器人系统中的实时性能。本文提出 iGaussian，一种两阶段前馈式框架，通过直接的三维高斯反演实现实时相机位姿估计。第一阶段中，我们利用结合空间均匀采样与引导注意力机制的高斯场景先验位姿回归网络，预测粗略的 6 自由度（6DoF）位姿；第二阶段则通过特征匹配与多模型融合进一步细化位姿估计。核心创新在于设计了一种无需可微渲染的跨相关模块，可将图像特征嵌入与三维高斯属性进行对齐，同时结合加权多视图预测器（Weighted Multiview Predictor），融合来自多个策略性采样视角的特征信息。我们在 NeRF Synthetic、Mip-NeRF 360 与 T\&T+DB 数据集上的实验表明，iGaussian 显著优于现有方法，将中位数旋转误差降低至 0.2°，并在移动机器人上实现了 2.87 FPS 的追踪速度，相较于基于优化的方法，获得了 10 倍的速度提升。
