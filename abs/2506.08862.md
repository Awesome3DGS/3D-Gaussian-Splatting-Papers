### StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams

Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-world applications. However, existing methods struggle to jointly address three key challenges: 1) processing uncalibrated inputs in real time, 2) accurately modeling dynamic scene evolution, and 3) maintaining long-term stability and computational efficiency. To this end, we introduce StreamSplat, the first fully feed-forward framework that transforms uncalibrated video streams of arbitrary length into dynamic 3D Gaussian Splatting (3DGS) representations in an online manner, capable of recovering scene dynamics from temporally local observations. We propose two key technical innovations: a probabilistic sampling mechanism in the static encoder for 3DGS position prediction, and a bidirectional deformation field in the dynamic decoder that enables robust and efficient dynamic modeling. Extensive experiments on static and dynamic benchmarks demonstrate that StreamSplat consistently outperforms prior works in both reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams.

从未经标定的视频流中实时重建动态三维场景对于众多现实应用至关重要。然而，现有方法难以同时解决三个关键挑战：(1) 实时处理未经标定的输入，(2) 准确建模动态场景的演化过程，以及 (3) 保持长期稳定性与计算效率。为此，我们提出了 **StreamSplat**，这是首个可将任意长度的未经标定视频流在线转换为动态三维高斯溅射（3DGS）表示的全前馈框架，能够仅依赖时间局部观测恢复场景动态。我们提出了两项关键技术创新：(1) 在静态编码器中引入用于 3DGS 位置预测的概率采样机制；(2) 在动态解码器中引入双向形变场，以实现稳健且高效的动态建模。在静态与动态基准测试上的大量实验表明，**StreamSplat** 在重建质量和动态场景建模方面均显著优于现有方法，并且独特地支持任意长度视频流的在线重建。
