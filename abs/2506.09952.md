### UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting

The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones.

点云数据的尺度多样性给三维视觉中统一表征学习技术的发展带来了巨大挑战。目前，统一的三维模型屈指可数，且尚无预训练方法能够在物体级与场景级点云上同时保持同等高效。本文提出 **UniPre3D**，这是首个可无缝应用于任意尺度点云及任意架构三维模型的统一预训练方法。我们将预测高斯基元作为预训练任务，并利用可微分的高斯溅射进行图像渲染，从而实现精确的像素级监督与端到端优化。为进一步调控预训练任务的复杂性并引导模型关注几何结构，我们引入来自预训练图像模型的二维特征，以融入成熟的纹理先验知识。我们在多种物体级与场景级任务上，以及基于不同点云模型的骨干网络上进行了大量实验，验证了所提方法的通用有效性。
