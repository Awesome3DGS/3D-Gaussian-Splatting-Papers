### FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction

Reconstructing high-fidelity animatable human avatars from monocular videos remains challenging due to insufficient geometric information in single-view observations. While recent 3D Gaussian Splatting methods have shown promise, they struggle with surface detail preservation due to the free-form nature of 3D Gaussian primitives. To address both the representation limitations and information scarcity, we propose a novel method, \textbf{FMGS-Avatar}, that integrates two key innovations. First, we introduce Mesh-Guided 2D Gaussian Splatting, where 2D Gaussian primitives are attached directly to template mesh faces with constrained position, rotation, and movement, enabling superior surface alignment and geometric detail preservation. Second, we leverage foundation models trained on large-scale datasets, such as Sapiens, to complement the limited visual cues from monocular videos. However, when distilling multi-modal prior knowledge from foundation models, conflicting optimization objectives can emerge as different modalities exhibit distinct parameter sensitivities. We address this through a coordinated training strategy with selective gradient isolation, enabling each loss component to optimize its relevant parameters without interference. Through this combination of enhanced representation and coordinated information distillation, our approach significantly advances 3D monocular human avatar reconstruction. Experimental evaluation demonstrates superior reconstruction quality compared to existing methods, with notable gains in geometric accuracy and appearance fidelity while providing rich semantic information. Additionally, the distilled prior knowledge within a shared canonical space naturally enables spatially and temporally consistent rendering under novel views and poses.

从单目视频重建高保真、可动画化的人体头像仍然是一项极具挑战的任务，原因在于单视角观测所提供的几何信息有限。尽管近期的三维高斯溅射（3D Gaussian Splatting, 3DGS）方法展现了潜力，但由于三维高斯基元的自由形式特征，其在表面细节保留方面仍存在不足。为同时解决表示能力受限与信息不足的问题，我们提出了一种全新的方法——**FMGS-Avatar**，其核心包含两项创新设计。首先，我们提出了**基于网格引导的二维高斯溅射（Mesh-Guided 2D Gaussian Splatting）**，将二维高斯基元直接附着于模板网格的面片上，并在位置、旋转与运动上施加约束，从而实现更优的表面对齐与几何细节保持。其次，我们利用在大规模数据集（如 Sapiens）上训练的基础模型，弥补单目视频视觉线索不足的问题。然而，在从基础模型蒸馏多模态先验知识的过程中，不同模态的参数敏感性差异会导致优化目标冲突。针对这一问题，我们设计了一种**选择性梯度隔离的协同训练策略**，使得各个损失项仅优化其对应的相关参数，避免相互干扰。通过增强的表示方式与协调的信息蒸馏机制，我们的方法在单目人体头像重建方面取得了显著进展。实验结果表明，所提方法在几何精度与外观保真度上均优于现有方法，并能提供丰富的语义信息。此外，在共享的规范化空间中蒸馏的先验知识，使得在新视角与新姿态下的渲染在空间与时间上都具有良好一致性。
