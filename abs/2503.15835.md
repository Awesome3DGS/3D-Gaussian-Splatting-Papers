### BARD-GS: Blur-Aware Reconstruction of Dynamic Scenes via Gaussian Splatting

3D Gaussian Splatting (3DGS) has shown remarkable potential for static scene reconstruction, and recent advancements have extended its application to dynamic scenes. However, the quality of reconstructions depends heavily on high-quality input images and precise camera poses, which are not that trivial to fulfill in real-world scenarios. Capturing dynamic scenes with handheld monocular cameras, for instance, typically involves simultaneous movement of both the camera and objects within a single exposure. This combined motion frequently results in image blur that existing methods cannot adequately handle. To address these challenges, we introduce BARD-GS, a novel approach for robust dynamic scene reconstruction that effectively handles blurry inputs and imprecise camera poses. Our method comprises two main components: 1) camera motion deblurring and 2) object motion deblurring. By explicitly decomposing motion blur into camera motion blur and object motion blur and modeling them separately, we achieve significantly improved rendering results in dynamic regions. In addition, we collect a real-world motion blur dataset of dynamic scenes to evaluate our approach. Extensive experiments demonstrate that BARD-GS effectively reconstructs high-quality dynamic scenes under realistic conditions, significantly outperforming existing methods.

3D 高斯散点 (3DGS) 在静态场景重建方面展现出卓越的潜力，并且近期的研究已将其应用扩展到动态场景。然而，重建质量高度依赖于高质量的输入图像和精确的相机位姿，而在现实世界场景中，这些要求往往难以满足。例如，使用手持单目相机捕捉动态场景通常会导致相机与场景中的物体在同一曝光时间内同时运动。这种复合运动往往会导致图像模糊，而现有方法无法有效处理这一问题。
为了解决这些挑战，我们提出了一种用于稳健动态场景重建的新方法——BARD-GS，该方法能够有效处理模糊输入和不精确的相机位姿。我们的方法主要包括两个核心组件：1）相机运动去模糊；2）物体运动去模糊。通过显式地将运动模糊分解为相机运动模糊和物体运动模糊，并分别建模处理，我们在动态区域的渲染质量上实现了显著提升。此外，我们构建了一个包含真实世界动态场景运动模糊的数据集，用于评估我们的方法。大量实验表明，BARD-GS 能够在现实条件下高质量地重建动态场景，显著优于现有方法。
