### Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization

Visual localization is the task of estimating a camera pose in a known environment. In this paper, we utilize 3D Gaussian Splatting (3DGS)-based representations for accurate and privacy-preserving visual localization. We propose Gaussian Splatting Feature Fields (GSFFs), a scene representation for visual localization that combines an explicit geometry model (3DGS) with an implicit feature field. We leverage the dense geometric information and differentiable rasterization algorithm from 3DGS to learn robust feature representations grounded in 3D. In particular, we align a 3D scale-aware feature field and a 2D feature encoder in a common embedding space through a contrastive framework. Using a 3D structure-informed clustering procedure, we further regularize the representation learning and seamlessly convert the features to segmentations, which can be used for privacy-preserving visual localization. Pose refinement, which involves aligning either feature maps or segmentations from a query image with those rendered from the GSFFs scene representation, is used to achieve localization. The resulting privacy- and non-privacy-preserving localization pipelines, evaluated on multiple real-world datasets, show state-of-the-art performances.

视觉定位的任务是在已知环境中估计相机姿态。本文利用基于三维高斯溅射（3DGS）的表示来实现精确且隐私保护的视觉定位。我们提出了高斯溅射特征场（GSFFs），这是一种将显式几何模型（3DGS）与隐式特征场相结合的视觉定位场景表示方法。我们利用 3DGS 所提供的稠密几何信息和可微光栅化算法，学习以三维为基础的鲁棒特征表示。具体而言，我们通过对比学习框架，将三维尺度感知特征场与二维特征编码器对齐到一个共同的嵌入空间。利用三维结构感知的聚类过程，我们进一步正则化特征表示学习，并将特征无缝转换为可用于隐私保护视觉定位的分割结果。在定位阶段，我们通过姿态优化，将查询图像的特征图或分割结果与由 GSFFs 场景表示渲染得到的结果进行对齐，从而实现定位。基于多种真实世界数据集的评估结果表明，无论是隐私保护还是非隐私保护的定位流程，我们的方法均达到了当前最优性能。
