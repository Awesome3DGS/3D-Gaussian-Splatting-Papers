### Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels

Inferring the physical properties of 3D scenes from visual information is a critical yet challenging task for creating interactive and realistic virtual worlds. While humans intuitively grasp material characteristics such as elasticity or stiffness, existing methods often rely on slow, per-scene optimization, limiting their generalizability and application. To address this problem, we introduce PIXIE, a novel method that trains a generalizable neural network to predict physical properties across multiple scenes from 3D visual features purely using supervised losses. Once trained, our feed-forward network can perform fast inference of plausible material fields, which coupled with a learned static scene representation like Gaussian Splatting enables realistic physics simulation under external forces. To facilitate this research, we also collected PIXIEVERSE, one of the largest known datasets of paired 3D assets and physic material annotations. Extensive evaluations demonstrate that PIXIE is about 1.46-4.39x better and orders of magnitude faster than test-time optimization methods. By leveraging pretrained visual features like CLIP, our method can also zero-shot generalize to real-world scenes despite only ever been trained on synthetic data.

从视觉信息中推断三维场景的物理属性是构建交互式和逼真虚拟世界的关键任务，但同时也极具挑战性。人类能够直观理解材料特性，如弹性或刚度，而现有方法往往依赖于缓慢的逐场景优化，限制了其泛化性与应用性。为解决这一问题，我们提出了 PIXIE，这是一种新颖的方法，通过纯粹的监督损失训练可泛化的神经网络，从三维视觉特征中预测跨场景的物理属性。一旦训练完成，我们的前馈网络即可快速推理出合理的材料场，并结合三维高斯溅射等静态场景表示，在外力作用下实现逼真的物理模拟。为推动相关研究，我们还收集了 PIXIEVERSE，这是迄今已知规模最大的配对三维资产与物理材料标注数据集之一。大量评估结果表明，PIXIE 的性能比测试时优化方法高出约 1.46-4.39 倍，且速度快出若干个数量级。通过利用如 CLIP 等预训练视觉特征，我们的方法还能够在仅使用合成数据训练的情况下实现对真实场景的零样本泛化。
