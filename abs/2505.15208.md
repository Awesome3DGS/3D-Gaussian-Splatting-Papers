### GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting

Transferring 2D textures to 3D modalities is of great significance for improving the efficiency of multimedia content creation. Existing approaches have rarely focused on transferring image textures onto 3D representations. 3D style transfer methods are capable of transferring abstract artistic styles to 3D scenes. However, these methods often overlook the geometric information of the scene, which makes it challenging to achieve high-quality 3D texture transfer results. In this paper, we present GT^2-GS, a geometry-aware texture transfer framework for gaussian splitting. From the perspective of matching texture features with geometric information in rendered views, we identify the issue of insufficient texture features and propose a geometry-aware texture augmentation module to expand the texture feature set. Moreover, a geometry-consistent texture loss is proposed to optimize texture features into the scene representation. This loss function incorporates both camera pose and 3D geometric information of the scene, enabling controllable texture-oriented appearance editing. Finally, a geometry preservation strategy is introduced. By alternating between the texture transfer and geometry correction stages over multiple iterations, this strategy achieves a balance between learning texture features and preserving geometric integrity. Extensive experiments demonstrate the effectiveness and controllability of our method. Through geometric awareness, our approach achieves texture transfer results that better align with human visual perception.

将二维纹理迁移至三维模态对于提升多媒体内容创作效率具有重要意义。然而，现有方法鲜有关注将图像纹理有效地迁移到三维表示上。虽然已有的三维风格迁移方法能够将抽象的艺术风格迁移至三维场景中，但这些方法往往忽略了场景中的几何信息，从而难以实现高质量的三维纹理迁移效果。本文提出了一种面向高斯投影的几何感知纹理迁移框架 GT²-GS。我们从在渲染视图中匹配纹理特征与几何信息的角度出发，发现现有方法存在纹理特征不足的问题。为此，我们设计了一个几何感知纹理增强模块，用于扩展纹理特征集合。此外，我们提出了一种几何一致性纹理损失函数，将纹理特征有效优化到场景表示中。该损失函数结合了相机位姿和场景的三维几何信息，从而实现可控的、面向纹理的外观编辑。最后，我们引入了一种几何保持策略，在多个迭代中交替执行纹理迁移与几何修正阶段，在学习纹理特征与保持几何结构完整性之间实现平衡。大量实验验证了本方法在纹理迁移效果与可控性方面的有效性。通过引入几何感知机制，我们的方法实现了更符合人类视觉感知的纹理迁移结果。
