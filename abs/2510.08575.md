### ReSplat: Learning Recurrent Gaussian Splats

While feed-forward Gaussian splatting models provide computational efficiency and effectively handle sparse input settings, their performance is fundamentally limited by the reliance on a single forward pass during inference. We propose ReSplat, a feed-forward recurrent Gaussian splatting model that iteratively refines 3D Gaussians without explicitly computing gradients. Our key insight is that the Gaussian splatting rendering error serves as a rich feedback signal, guiding the recurrent network to learn effective Gaussian updates. This feedback signal naturally adapts to unseen data distributions at test time, enabling robust generalization. To initialize the recurrent process, we introduce a compact reconstruction model that operates in a 16× subsampled space, producing 16× fewer Gaussians than previous per-pixel Gaussian models. This substantially reduces computational overhead and allows for efficient Gaussian updates. Extensive experiments across varying of input views (2, 8, 16), resolutions (256×256 to 540×960), and datasets (DL3DV and RealEstate10K) demonstrate that our method achieves state-of-the-art performance while significantly reducing the number of Gaussians and improving the rendering speed.

虽然前馈式高斯泼溅模型在计算效率方面表现出色，并能有效处理稀疏输入设置，但其性能受限于推理时仅执行一次前向传播的结构性限制。为突破这一瓶颈，我们提出了 ReSplat——一种前馈式循环高斯泼溅模型，可在不显式计算梯度的情况下迭代优化三维高斯表示。我们的关键洞察是：高斯泼溅渲染误差本身可作为富含信息的反馈信号，引导循环网络学习有效的高斯更新策略。该反馈机制可自然适应测试时未见过的数据分布，从而实现强泛化能力。为初始化循环过程，我们设计了一种紧凑的重建模型，其在 16 倍下采样的空间中运行，生成的高斯数量比以往每像素高斯模型少 16 倍，显著降低了计算开销并支持高效的高斯更新。我们在不同输入视角数量（2、8、16）、图像分辨率（256×256 至 540×960）和数据集（DL3DV 和 RealEstate10K）上的大量实验证明：ReSplat 在大幅减少高斯数量与加快渲染速度的同时，仍实现了当前最优的性能。
