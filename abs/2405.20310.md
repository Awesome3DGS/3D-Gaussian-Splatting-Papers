### A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction

Learning 3D scene representation from a single-view image is a long-standing fundamental problem in computer vision, with the inherent ambiguity in predicting contents unseen from the input view. Built on the recently proposed 3D Gaussian Splatting (3DGS), the Splatter Image method has made promising progress on fast single-image novel view synthesis via learning a single 3D Gaussian for each pixel based on the U-Net feature map of an input image. However, it has limited expressive power to represent occluded components that are not observable in the input view. To address this problem, this paper presents a Hierarchical Splatter Image method in which a pixel is worth more than one 3D Gaussians. Specifically,
each pixel is represented by a parent 3D Gaussian and a small number of child 3D Gaussians. Parent 3D Gaussians are learned as done in the vanilla Splatter Image. Child 3D Gaussians are learned via a lightweight Multi-Layer Perceptron (MLP) which takes as input the projected image features of a parent 3D Gaussian and the embedding of a target camera view. Both parent and child 3D Gaussians are learned end-to-end in a stage-wise way. The joint condition of input image features from eyes of the parent Gaussians and the target camera position facilitates learning to allocate child Gaussians to "see the unseen", recovering the occluded details that are often missed by parent Gaussians.
In experiments, the proposed method is tested on the ShapeNet-SRN and CO3D datasets with state-of-the-art performance obtained, especially showing promising capabilities of reconstructing occluded contents in the input view.

从单视图图像学习三维场景表示是计算机视觉中一个长期存在的基本问题，其固有的挑战在于预测从输入视图中看不见的内容。基于最近提出的三维高斯溅射（3DGS），Splatter Image方法通过基于输入图像的U-Net特征图为每个像素学习一个单独的三维高斯体，对快速单图像新视角合成取得了有希望的进展。然而，它在表示输入视图中不可观测的被遮挡组件方面具有有限的表达能力。为了解决这个问题，本文提出了一个分层Splatter Image方法，其中一个像素由多个三维高斯体表示。具体来说，每个像素由一个父三维高斯体和少量子三维高斯体组成。父三维高斯体的学习与传统的Splatter Image中的方法相同。子三维高斯体通过一个轻量级的多层感知机（MLP）学习，该MLP以一个父三维高斯体的投影图像特征和目标摄像机视图的嵌入为输入。父子三维高斯体均通过分阶段的方式端到端学习。输入图像特征与目标摄像机位置的联合条件有助于学习分配子高斯体以“看见未见”，恢复经常被父高斯体遗漏的被遮挡细节。
在实验中，所提出的方法在ShapeNet-SRN和CO3D数据集上进行了测试，获得了最先进的性能，特别是在重构输入视图中被遮挡内容的能力方面表现出了有希望的能力。
