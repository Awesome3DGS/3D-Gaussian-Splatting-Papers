### MotionGS : Compact Gaussian Splatting SLAM by Motion Filter

With their high-fidelity scene representation capability, the attention of SLAM field is deeply attracted by the Neural Radiation Field (NeRF) and 3D Gaussian Splatting (3DGS). Recently, there has been a Surge in NeRF-based SLAM, while 3DGS-based SLAM is sparse. A novel 3DGS-based SLAM approach with a fusion of deep visual feature, dual keyframe selection and 3DGS is presented in this paper. Compared with the existing methods, the proposed selectively tracking is achieved by feature extraction and motion filter on each frame. The joint optimization of pose and 3D Gaussian runs through the entire mapping process. Additionally, the coarse-to-fine pose estimation and compact Gaussian scene representation are implemented by dual keyfeature selection and novel loss functions. Experimental results demonstrate that the proposed algorithm not only outperforms the existing methods in tracking and mapping, but also has less memory usage.


凭借其高保真场景表示能力，神经辐射场（NeRF）和3D高斯喷溅（3DGS）深深吸引了SLAM领域的注意。最近，基于NeRF的SLAM出现了激增，而基于3DGS的SLAM则较为稀少。本文提出了一种新颖的基于3DGS的SLAM方法，该方法融合了深度视觉特征、双关键帧选择和3DGS。与现有方法相比，所提出的选择性跟踪是通过对每帧进行特征提取和运动滤波来实现的。姿态和3D高斯的联合优化贯穿整个映射过程。此外，通过双关键特征选择和新颖的损失函数实现了从粗到细的姿态估计和紧凑的高斯场景表示。实验结果表明，所提出的算法不仅在跟踪和映射方面优于现有方法，而且还具有较低的内存使用率。
