### RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection

4D millimeter-wave radar has emerged as a promising sensor for autonomous driving, but effective 3D object detection from both 4D radar and monocular images remains a challenge. Existing fusion approaches typically rely on either instance-based proposals or dense BEV grids, which either lack holistic scene understanding or are limited by rigid grid structures. To address these, we propose RaGS, the first framework to leverage 3D Gaussian Splatting (GS) as representation for fusing 4D radar and monocular cues in 3D object detection. 3D GS naturally suits 3D object detection by modeling the scene as a field of Gaussians, dynamically allocating resources on foreground objects and providing a flexible, resource-efficient solution. RaGS uses a cascaded pipeline to construct and refine the Gaussian field. It starts with the Frustum-based Localization Initiation (FLI), which unprojects foreground pixels to initialize coarse 3D Gaussians positions. Then, the Iterative Multimodal Aggregation (IMA) fuses semantics and geometry, refining the limited Gaussians to the regions of interest. Finally, the Multi-level Gaussian Fusion (MGF) renders the Gaussians into multi-level BEV features for 3D object detection. By dynamically focusing on sparse objects within scenes, RaGS enable object concentrating while offering comprehensive scene perception. Extensive experiments on View-of-Delft, TJ4DRadSet, and OmniHD-Scenes benchmarks demonstrate its state-of-the-art performance. Code will be released.

四维毫米波雷达作为自动驾驶中极具潜力的传感器正受到越来越多的关注，但如何将四维雷达与单目图像结合，实现高效的三维目标检测，仍然是一大挑战。现有融合方法通常依赖于基于实例的候选区域或稠密的 BEV 网格，这些方法要么缺乏整体场景理解能力，要么受制于刚性网格结构的限制。为此，我们提出了 RaGS，这是首个利用三维高斯点渲染（3D Gaussian Splatting, GS）作为表示，将四维雷达与单目信息融合用于三维目标检测的框架。3D GS 天然适用于三维目标检测，因为它将场景建模为高斯场，能够动态将资源分配到前景目标上，提供灵活且资源高效的解决方案。RaGS 采用级联式流程构建并优化高斯场：首先通过基于视锥的定位初始化（Frustum-based Localization Initiation, FLI），将前景像素反投影以初始化粗略的三维高斯位置；随后利用迭代多模态聚合（Iterative Multimodal Aggregation, IMA）融合语义与几何信息，将有限的高斯精炼到感兴趣区域；最后通过多级高斯融合（Multi-level Gaussian Fusion, MGF）将高斯渲染为多级 BEV 特征，用于三维目标检测。通过在场景中动态聚焦稀疏目标，RaGS 在实现目标集中的同时，兼顾了全局场景感知能力。在 View-of-Delft、TJ4DRadSet 和 OmniHD-Scenes 基准上的大量实验表明，RaGS 在性能上达到了当前最先进水平。代码将会开源。
