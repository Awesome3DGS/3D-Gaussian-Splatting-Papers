### SEGA: Drivable 3D Gaussian Head Avatar from a Single Image

Creating photorealistic 3D head avatars from limited input has become increasingly important for applications in virtual reality, telepresence, and digital entertainment. While recent advances like neural rendering and 3D Gaussian splatting have enabled high-quality digital human avatar creation and animation, most methods rely on multiple images or multi-view inputs, limiting their practicality for real-world use. In this paper, we propose SEGA, a novel approach for Single-imagE-based 3D drivable Gaussian head Avatar creation that combines generalized prior models with a new hierarchical UV-space Gaussian Splatting framework. SEGA seamlessly combines priors derived from large-scale 2D datasets with 3D priors learned from multi-view, multi-expression, and multi-ID data, achieving robust generalization to unseen identities while ensuring 3D consistency across novel viewpoints and expressions. We further present a hierarchical UV-space Gaussian Splatting framework that leverages FLAME-based structural priors and employs a dual-branch architecture to disentangle dynamic and static facial components effectively. The dynamic branch encodes expression-driven fine details, while the static branch focuses on expression-invariant regions, enabling efficient parameter inference and precomputation. This design maximizes the utility of limited 3D data and achieves real-time performance for animation and rendering. Additionally, SEGA performs person-specific fine-tuning to further enhance the fidelity and realism of the generated avatars. Experiments show our method outperforms state-of-the-art approaches in generalization ability, identity preservation, and expression realism, advancing one-shot avatar creation for practical applications.

从有限输入中创建逼真的三维头部头像在虚拟现实、远程呈现和数字娱乐等应用中变得日益重要。尽管神经渲染和 3D Gaussian Splatting 等技术的最新进展已经实现了高质量数字人像的生成与动画，但现有方法大多依赖多张图像或多视角输入，限制了其在真实场景中的应用。
本文提出了一种新方法 SEGA，用于基于单张图像的三维可驱动高斯头像生成（Single-imagE-based 3D drivable Gaussian head Avatar），结合了通用先验模型和一种新颖的层次化 UV 空间高斯投影框架。SEGA 无缝融合了来源于大规模二维数据集的先验信息与从多视角、多表情和多身份三维数据中学习到的三维先验，能够在保持三维一致性的同时，实现对未见身份的强泛化能力。
我们进一步提出了一种层次化 UV 空间高斯投影框架，该框架结合了基于 FLAME 的结构先验，并采用双分支结构，有效解耦面部的动态与静态部分。动态分支编码由表情驱动的细节特征，静态分支则关注于表情不变区域，从而支持高效的参数推理与预计算。该设计最大程度地利用了有限的三维数据，实现了动画与渲染的实时性能。
此外，SEGA 还支持基于个体的精调，以进一步提升生成头像的保真度与真实感。实验表明，该方法在泛化能力、身份保持性和表情真实度方面均优于当前最先进的方法，推动了一次性头像生成技术在实际应用中的发展。
