### UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D Generation

High-fidelity 3D asset generation is crucial for various industries. While recent 3D pretrained models show strong capability in producing realistic content, most are built upon diffusion models and follow a two-stage pipeline that first generates geometry and then synthesizes appearance. Such a decoupled design tends to produce geometry-texture misalignment and non-negligible cost. In this paper, we propose UniLat3D, a unified framework that encodes geometry and appearance in a single latent space, enabling direct single-stage generation. Our key contribution is a geometry-appearance Unified VAE, which compresses high-resolution sparse features into a compact latent representation -- UniLat. UniLat integrates structural and visual information into a dense low-resolution latent, which can be efficiently decoded into diverse 3D formats, e.g., 3D Gaussians and meshes. Based on this unified representation, we train a single flow-matching model to map Gaussian noise directly into UniLat, eliminating redundant stages. Trained solely on public datasets, UniLat3D produces high-quality 3D assets in seconds from a single image, achieving superior appearance fidelity and geometric quality.

高保真三维资产生成在多个行业中具有关键重要性。尽管近年来的三维预训练模型在生成逼真内容方面展现出强大能力，但大多数方法基于扩散模型，并采用“几何生成—外观合成”两阶段流程。这种解耦式设计容易导致几何与纹理不对齐，并带来显著的计算开销。为此，我们提出了 **UniLat3D**，一个在单一潜空间中联合编码几何与外观信息的统一框架，实现直接的一阶段生成。我们的核心创新在于 **几何-外观统一变分自编码器（Unified VAE）**，该模型将高分辨率稀疏特征压缩为紧凑的潜表示——**UniLat**。UniLat 将结构信息与视觉信息融合为密集、低分辨率的潜特征，可高效解码为多种三维形式，例如三维高斯（3D Gaussians）和网格（meshes）。基于这种统一表示，我们训练了一个单一的流匹配模型（flow-matching model），能够将高斯噪声直接映射到 UniLat，从而消除冗余阶段。该模型仅基于公开数据集进行训练，能够在数秒内从单张图像生成高质量的三维资产，在外观逼真度与几何精度上均显著优于现有方法。
