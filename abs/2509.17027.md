### Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic Views

Surgical simulation is essential for medical training, enabling practitioners to develop crucial skills in a risk-free environment while improving patient safety and surgical outcomes. However, conventional methods for building simulation environments are cumbersome, time-consuming, and difficult to scale, often resulting in poor details and unrealistic simulations. In this paper, we propose a Gaussian Splatting-based framework to directly reconstruct interactive surgical scenes from endoscopic data while ensuring efficiency, rendering quality, and realism. A key challenge in this data-driven simulation paradigm is the restricted movement of endoscopic cameras, which limits viewpoint diversity. As a result, the Gaussian Splatting representation overfits specific perspectives, leading to reduced geometric accuracy. To address this issue, we introduce a novel virtual camera-based regularization method that adaptively samples virtual viewpoints around the scene and incorporates them into the optimization process to mitigate overfitting. An effective depth-based regularization is applied to both real and virtual views to further refine the scene geometry. To enable fast deformation simulation, we propose a sparse control node-based Material Point Method, which integrates physical properties into the reconstructed scene while significantly reducing computational costs. Experimental results on representative surgical data demonstrate that our method can efficiently reconstruct and simulate surgical scenes from sparse endoscopic views. Notably, our method takes only a few minutes to reconstruct the surgical scene and is able to produce physically plausible deformations in real-time with user-defined interactions.

外科手术模拟对于医学培训至关重要，它能够帮助医生在无风险的环境中培养关键技能，从而提升患者安全性并改善手术效果。然而，传统的手术仿真环境构建方法过程繁琐、耗时且难以扩展，往往导致细节不足和仿真逼真度低。本文提出了一种基于高斯溅射（Gaussian Splatting）的框架，可直接从内窥镜数据中高效重建交互式手术场景，同时兼顾效率、渲染质量与真实感。该数据驱动的仿真范式面临的核心挑战在于内窥镜相机运动范围受限，导致视角多样性不足，从而使高斯溅射表示在特定视角上过拟合，削弱几何精度。为此，我们提出了一种新的基于虚拟相机的正则化方法，自适应地在场景周围采样虚拟视角，并将其引入优化过程以缓解过拟合问题。同时，我们在真实与虚拟视角中均引入了基于深度的有效正则化，以进一步优化场景几何结构。为实现快速的变形仿真，我们提出了一种基于稀疏控制节点的材料点法（Material Point Method, MPM），在显著降低计算开销的同时，将物理属性融入重建场景中。基于典型外科数据的实验结果表明，我们的方法能够从稀疏的内窥镜视角中高效重建并模拟手术场景。值得注意的是，本方法仅需数分钟即可完成手术场景重建，并能够在用户交互下实现实时且物理合理的变形模拟。
