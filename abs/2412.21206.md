### PERSE: Personalized 3D Generative Avatars from A Single Portrait

We present PERSE, a method for building an animatable personalized generative avatar from a reference portrait. Our avatar model enables facial attribute editing in a continuous and disentangled latent space to control each facial attribute, while preserving the individual's identity. To achieve this, our method begins by synthesizing large-scale synthetic 2D video datasets, where each video contains consistent changes in the facial expression and viewpoint, combined with a variation in a specific facial attribute from the original input. We propose a novel pipeline to produce high-quality, photorealistic 2D videos with facial attribute editing. Leveraging this synthetic attribute dataset, we present a personalized avatar creation method based on the 3D Gaussian Splatting, learning a continuous and disentangled latent space for intuitive facial attribute manipulation. To enforce smooth transitions in this latent space, we introduce a latent space regularization technique by using interpolated 2D faces as supervision. Compared to previous approaches, we demonstrate that PERSE generates high-quality avatars with interpolated attributes while preserving identity of reference person.

我们提出了 PERSE，一种从参考肖像生成可动画化个性化生成头像的方法。该头像模型允许在连续且解耦的潜在空间中编辑面部属性，从而精确控制各个面部属性，同时保持个体身份的一致性。
为实现这一目标，我们的方法首先通过生成大规模的合成二维视频数据集入手，其中每个视频包含面部表情和视角的连续变化，并结合特定面部属性的变化，这些变化基于原始输入。我们提出了一种新颖的管道，用于生成高质量、真实感强的二维视频，同时实现面部属性编辑。
利用这一合成属性数据集，我们基于 3D 高斯喷射（Gaussian Splatting）提出了一种个性化头像创建方法，通过学习连续且解耦的潜在空间，实现直观的面部属性操控。为了在潜在空间中实现平滑过渡，我们引入了一种潜在空间正则化技术，通过插值的二维面部图像进行监督。
与现有方法相比，我们证明了 PERSE 能够生成具有高质量属性插值的头像，同时保持参考人物的身份一致性。
