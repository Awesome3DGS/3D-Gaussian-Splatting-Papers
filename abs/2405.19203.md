### E3Gen: Efficient, Expressive and Editable Avatars Generation

This paper aims to introduce 3D Gaussian for efficient, expressive, and editable digital avatar generation. This task faces two major challenges: (1) The unstructured nature of 3D Gaussian makes it incompatible with current generation pipelines; (2) the expressive animation of 3D Gaussian in a generative setting that involves training with multiple subjects remains unexplored. In this paper, we propose a novel avatar generation method named E3Gen, to effectively address these challenges. First, we propose a novel generative UV features plane representation that encodes unstructured 3D Gaussian onto a structured 2D UV space defined by the SMPL-X parametric model. This novel representation not only preserves the representation ability of the original 3D Gaussian but also introduces a shared structure among subjects to enable generative learning of the diffusion model. To tackle the second challenge, we propose a part-aware deformation module to achieve robust and accurate full-body expressive pose control. Extensive experiments demonstrate that our method achieves superior performance in avatar generation and enables expressive full-body pose control and editing.

本文旨在引入三维高斯技术，以实现高效、富有表现力且可编辑的数字化化身生成。这一任务面临两大挑战：（1）三维高斯的非结构化特性使其与当前的生成流水线不兼容；（2）在涉及多主体训练的生成环境中，三维高斯的表现性动画仍未被探索。为了有效应对这些挑战，我们提出了一种名为 E3Gen 的新颖化身生成方法。首先，我们提出了一种新颖的生成UV特征平面表征，该表征将非结构化的三维高斯编码到由SMPL-X参数模型定义的结构化的二维UV空间中。这种新颖的表征不仅保留了原始三维高斯的表征能力，还引入了在主体之间共享的结构，以支持扩散模型的生成学习。为了应对第二个挑战，我们提出了一个部分感知的变形模块，以实现稳健且准确的全身表情姿态控制。广泛的实验表明，我们的方法在化身生成中实现了卓越的性能，并能够实现表现力强的全身姿态控制和编辑。


