### Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians

Current learning-based methods predict NeRF or 3D Gaussians from point clouds to achieve photo-realistic rendering but still depend on categorical priors, dense point clouds, or additional refinements. Hence, we introduce a novel point cloud rendering method by predicting 2D Gaussians from point clouds. Our method incorporates two identical modules with an entire-patch architecture enabling the network to be generalized to multiple datasets. The module normalizes and initializes the Gaussians utilizing the point cloud information including normals, colors and distances. Then, splitting decoders are employed to refine the initial Gaussians by duplicating them and predicting more accurate results, making our methodology effectively accommodate sparse point clouds as well. Once trained, our approach exhibits direct generalization to point clouds across different categories. The predicted Gaussians are employed directly for rendering without additional refinement on the rendered images, retaining the benefits of 2D Gaussians. We conduct extensive experiments on various datasets, and the results demonstrate the superiority and generalization of our method, which achieves SOTA performance.

当前基于学习的方法通常从点云中预测 NeRF 或三维高斯，以实现逼真的图像渲染，但这些方法仍依赖于类别先验、稠密点云或额外的后处理步骤。为此，我们提出了一种新颖的点云渲染方法：从点云中预测二维高斯（2D Gaussians）。
我们的方法采用两个结构相同的模块，并基于整块图像区域（entire-patch）架构设计，使网络具有良好的跨数据集泛化能力。该模块利用点云的法向量、颜色和深度信息对高斯分布进行归一化和初始化。随后，我们引入分裂解码器（splitting decoders），通过复制初始高斯并预测更精确的参数，对其进行细化，从而使该方法同样适用于稀疏点云场景。
在训练完成后，我们的方法能够直接泛化至不同类别的点云数据，并且可直接使用预测得到的高斯进行渲染，无需对渲染图像进行额外优化，保留了二维高斯的高效特性。
我们在多个数据集上进行了广泛实验，结果表明该方法在精度和泛化能力方面均优于现有方法，达到了当前最优性能（SOTA）。
