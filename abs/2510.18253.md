### OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion

Understanding 3D scenes is pivotal for autonomous driving, robotics, and augmented reality. Recent semantic Gaussian Splatting approaches leverage large-scale 2D vision models to project 2D semantic features onto 3D scenes. However, they suffer from two major limitations: (1) insufficient contextual cues for individual masks during preprocessing and (2) inconsistencies and missing details when fusing multi-view features from these 2D models. In this paper, we introduce OpenInsGaussian, an Open-vocabulary Ins}tance Gaussian segmentation framework with Context-aware Cross-view Fusion. Our method consists of two modules: Context-Aware Feature Extraction, which augments each mask with rich semantic context, and Attention-Driven Feature Aggregation, which selectively fuses multi-view features to mitigate alignment errors and incompleteness. Through extensive experiments on benchmark datasets, OpenInsGaussian achieves state-of-the-art results in open-vocabulary 3D Gaussian segmentation, outperforming existing baselines by a large margin. These findings underscore the robustness and generality of our proposed approach, marking a significant step forward in 3D scene understanding and its practical deployment across diverse real-world scenarios.

三维场景理解对于自动驾驶、机器人技术以及增强现实具有关键意义。近年来的语义高斯投影方法利用大规模二维视觉模型，将二维语义特征投影至三维场景中。然而，这类方法存在两个主要局限：(1) 在预处理阶段，个体掩膜缺乏足够的上下文信息；(2) 在融合多视角特征时，容易出现不一致和细节缺失的问题。本文提出了**OpenInsGaussian**，一个基于上下文感知跨视角融合的**开放词汇实例高斯分割框架**。该方法由两个模块组成：上下文感知特征提取模块，为每个掩膜引入丰富语义上下文；注意力驱动特征聚合模块，有选择地融合多视角特征以缓解对齐误差和信息缺失。通过在多个基准数据集上的广泛实验证明，OpenInsGaussian在开放词汇三维高斯分割任务中取得了当前最优的性能，远超现有基线方法。上述结果充分展示了所提方法的鲁棒性与泛化能力，为三维场景理解及其在多种现实应用场景中的部署迈出了重要一步。
