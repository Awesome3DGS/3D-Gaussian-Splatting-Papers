### ADGaussian: Generalizable Gaussian Splatting for Autonomous Driving with Multi-modal Inputs

We present a novel approach, termed ADGaussian, for generalizable street scene reconstruction. The proposed method enables high-quality rendering from single-view input. Unlike prior Gaussian Splatting methods that primarily focus on geometry refinement, we emphasize the importance of joint optimization of image and depth features for accurate Gaussian prediction. To this end, we first incorporate sparse LiDAR depth as an additional input modality, formulating the Gaussian prediction process as a joint learning framework of visual information and geometric clue. Furthermore, we propose a multi-modal feature matching strategy coupled with a multi-scale Gaussian decoding model to enhance the joint refinement of multi-modal features, thereby enabling efficient multi-modal Gaussian learning. Extensive experiments on two large-scale autonomous driving datasets, Waymo and KITTI, demonstrate that our ADGaussian achieves state-of-the-art performance and exhibits superior zero-shot generalization capabilities in novel-view shifting.

我们提出了一种新颖的方法——ADGaussian，用于具有泛化能力的街景重建。该方法支持从单视图输入实现高质量渲染。与以往主要侧重于几何细化的Gaussian Splatting方法不同，我们强调图像特征与深度特征的联合优化对于准确高斯预测的重要性。
为此，我们首先引入稀疏LiDAR深度作为额外的输入模态，将高斯预测过程表述为一个融合视觉信息与几何线索的联合学习框架。此外，我们提出了一种多模态特征匹配策略，结合多尺度高斯解码模型，以增强多模态特征的联合细化能力，从而实现高效的多模态高斯学习。
在两个大规模自动驾驶数据集——Waymo和KITTI——上的大量实验证明，我们的ADGaussian方法不仅实现了当前最先进的性能，还在新视角切换任务中展现出卓越的零样本泛化能力。
