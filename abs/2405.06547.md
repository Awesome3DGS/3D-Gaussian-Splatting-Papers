### OneTo3D: One Image to Re-editable Dynamic 3D Model and Video Generation

One image to editable dynamic 3D model and video generation is novel direction and change in the research area of single image to 3D representation or 3D reconstruction of image. Gaussian Splatting has demonstrated its advantages in implicit 3D reconstruction, compared with the original Neural Radiance Fields. As the rapid development of technologies and principles, people tried to used the Stable Diffusion models to generate targeted models with text instructions. However, using the normal implicit machine learning methods is hard to gain the precise motions and actions control, further more, it is difficult to generate a long content and semantic continuous 3D video. To address this issue, we propose the OneTo3D, a method and theory to used one single image to generate the editable 3D model and generate the targeted semantic continuous time-unlimited 3D video. We used a normal basic Gaussian Splatting model to generate the 3D model from a single image, which requires less volume of video memory and computer calculation ability. Subsequently, we designed an automatic generation and self-adaptive binding mechanism for the object armature. Combined with the re-editable motions and actions analyzing and controlling algorithm we proposed, we can achieve a better performance than the SOTA projects in the area of building the 3D model precise motions and actions control, and generating a stable semantic continuous time-unlimited 3D video with the input text instructions. Here we will analyze the detailed implementation methods and theories analyses. Relative comparisons and conclusions will be presented.

从单一图像到可编辑的动态3D模型和视频生成是单图像到3D表示或图像3D重建研究领域的新方向和变革。高斯喷涂已经在隐式3D重建中展示了其优势，与原始的神经辐射场相比。随着技术和原理的快速发展，人们尝试使用稳定扩散模型根据文本指令生成目标模型。然而，使用常规的隐式机器学习方法难以精确控制运动和动作，更难以生成长内容和语义连续的3D视频。为了解决这一问题，我们提出了OneTo3D方法和理论，使用单一图像生成可编辑的3D模型，并生成目标语义连续的不限时长的3D视频。我们使用了一个基本的高斯喷涂模型从单一图像生成3D模型，这种方法需要较少的视频内存和计算能力。随后，我们设计了一个自动化生成和自适应绑定机制来处理对象骨架。结合我们提出的可重新编辑的动作分析和控制算法，我们可以在建立精确的3D模型动作控制和生成稳定的语义连续的不限时长3D视频方面，实现比现有最佳技术更好的性能。在这里，我们将分析详细的实施方法和理论分析。相关比较和结论将被提出。

