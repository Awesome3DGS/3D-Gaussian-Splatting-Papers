### PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction

Recent advances in 3D Gaussian Splatting (3DGS) have enabled high-quality, real-time novel-view synthesis from multi-view images. However, most existing methods assume the object is captured in a single, static pose, resulting in incomplete reconstructions that miss occluded or self-occluded regions. We introduce PFGS, a pose-aware 3DGS framework that addresses the practical challenge of reconstructing complete objects from multi-pose image captures. Given images of an object in one main pose and several auxiliary poses, PFGS iteratively fuses each auxiliary set into a unified 3DGS representation of the main pose. Our pose-aware fusion strategy combines global and local registration to merge views effectively and refine the 3DGS model. While recent advances in 3D foundation models have improved registration robustness and efficiency, they remain limited by high memory demands and suboptimal accuracy. PFGS overcomes these challenges by incorporating them more intelligently into the registration process: it leverages background features for per-pose camera pose estimation and employs foundation models for cross-pose registration. This design captures the best of both approaches while resolving background inconsistency issues. Experimental results demonstrate that PFGS consistently outperforms strong baselines in both qualitative and quantitative evaluations, producing more complete reconstructions and higher-fidelity 3DGS models.

三维高斯散射（3D Gaussian Splatting，简称 3DGS）领域的最新进展，使得基于多视图图像的高质量、实时新视角合成成为可能。然而，现有大多数方法假设目标物体处于单一静态姿态，从而导致重建结果不完整，遗漏了被遮挡或自遮挡的区域。为了解决从多姿态图像中重建完整物体的实际挑战，我们提出了 PFGS —— 一种姿态感知的 3DGS 框架。给定一个物体在一个主姿态和若干辅助姿态下的图像，PFGS 通过迭代方式将每个辅助姿态的信息融合到主姿态对应的统一 3DGS 表示中。我们提出的姿态感知融合策略结合了全局与局部配准方法，能够有效整合各视角信息，并细化最终的 3DGS 模型。尽管近期的三维基础模型在配准的鲁棒性与效率方面取得了进展，但仍受限于高内存消耗和精度不佳的问题。PFGS 通过更智能地将这些基础模型引入配准流程，有效克服了上述挑战：它利用背景特征进行每个姿态的相机位姿估计，同时使用基础模型实现跨姿态的配准操作。该设计兼顾两种方法的优势，并解决了背景不一致的问题。实验结果表明，PFGS 在定性与定量评估中均显著优于强基线，能够实现更完整的重建效果与更高保真度的 3DGS 模型。
