### Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations

Learning effective multi-modal 3D representations of objects is essential for numerous applications, such as augmented reality and robotics. Existing methods often rely on task-specific embeddings that are tailored either for semantic understanding or geometric reconstruction. As a result, these embeddings typically cannot be decoded into explicit geometry and simultaneously reused across tasks. In this paper, we propose Object-X, a versatile multi-modal object representation framework capable of encoding rich object embeddings (e.g. images, point cloud, text) and decoding them back into detailed geometric and visual reconstructions. Object-X operates by geometrically grounding the captured modalities in a 3D voxel grid and learning an unstructured embedding fusing the information from the voxels with the object attributes. The learned embedding enables 3D Gaussian Splatting-based object reconstruction, while also supporting a range of downstream tasks, including scene alignment, single-image 3D object reconstruction, and localization. Evaluations on two challenging real-world datasets demonstrate that Object-X produces high-fidelity novel-view synthesis comparable to standard 3D Gaussian Splatting, while significantly improving geometric accuracy. Moreover, Object-X achieves competitive performance with specialized methods in scene alignment and localization. Critically, our object-centric descriptors require 3-4 orders of magnitude less storage compared to traditional image- or point cloud-based approaches, establishing Object-X as a scalable and highly practical solution for multi-modal 3D scene representation.

学习有效的多模态三维物体表征对于增强现实和机器人等众多应用至关重要。现有方法通常依赖于特定任务的嵌入，这些嵌入要么面向语义理解，要么面向几何重建。因此，这类嵌入通常既无法解码为显式几何结构，也难以跨任务复用。
本文提出了 Object-X，一个通用的多模态物体表征框架，能够编码丰富的物体嵌入（如图像、点云、文本），并将其解码为细致的几何和视觉重建结果。Object-X 的核心思路是将采集到的多模态信息几何对齐到三维体素网格中，并学习一种非结构化嵌入，将体素中的信息与物体属性进行融合。
所学习的嵌入不仅支持基于 3D Gaussian Splatting 的物体重建，还可用于多种下游任务，包括场景对齐、单张图像的三维物体重建以及定位任务。我们在两个具有挑战性的真实世界数据集上进行了评估，结果表明：Object-X 在新视角合成方面可达到与标准 3D Gaussian Splatting 相当的高保真度，同时显著提升了几何精度。
此外，在场景对齐和定位任务中，Object-X 也展现出与专用方法相媲美的性能。更重要的是，与传统基于图像或点云的方法相比，我们提出的以物体为中心的描述子在存储需求上降低了 3~4 个数量级，使得 Object-X 成为一种可扩展且高度实用的多模态三维场景表示方案。
