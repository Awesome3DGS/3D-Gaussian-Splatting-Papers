### DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion

We present DriveGen3D, a novel framework for generating high-quality and highly controllable dynamic 3D driving scenes that addresses critical limitations in existing methodologies. Current approaches to driving scene synthesis either suffer from prohibitive computational demands for extended temporal generation, focus exclusively on prolonged video synthesis without 3D representation, or restrict themselves to static single-scene reconstruction. Our work bridges this methodological gap by integrating accelerated long-term video generation with large-scale dynamic scene reconstruction through multimodal conditional control. DriveGen3D introduces a unified pipeline consisting of two specialized components: FastDrive-DiT, an efficient video diffusion transformer for high-resolution, temporally coherent video synthesis under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a feed-forward reconstruction module that rapidly builds 3D Gaussian representations across time, ensuring spatial-temporal consistency. Together, these components enable real-time generation of extended driving videos (up to 424×800 at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining parameter efficiency.

我们提出了DriveGen3D，一种新颖的框架，旨在生成高质量、高可控性的动态三维驾驶场景，解决现有方法中的关键瓶颈。目前主流的驾驶场景合成方法要么在长时间序列生成上计算成本过高，要么仅关注视频合成而不具备三维表示能力，或者仅限于静态单场景的重建。DriveGen3D通过多模态条件控制，将加速的长期视频生成与大规模动态场景重建相融合，有效弥合了这一方法学断层。
该框架引入了一个统一流程，由两个专用模块构成：FastDrive-DiT，是一个高效的视频扩散Transformer，可在文本和俯视图（BEV）布局引导下，合成高分辨率、时序连贯的视频；FastRecon3D，是一个前馈式三维重建模块，能够快速在时间序列上构建三维高斯表示，确保时空一致性。两者协同运行，实现了实时生成长时间驾驶视频（分辨率达424×800，帧率达12 FPS）及其对应的动态三维场景。在新视图合成任务中，该框架取得了SSIM 0.811 和 PSNR 22.84 的出色表现，同时保持了参数高效性。
