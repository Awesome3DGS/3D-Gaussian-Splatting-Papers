### DarkGS: Learning Neural Illumination and 3D Gaussians Relighting for Robotic Exploration in the Dark

Humans have the remarkable ability to construct consistent mental models of an environment, even under limited or varying levels of illumination. We wish to endow robots with this same capability. In this paper, we tackle the challenge of constructing a photorealistic scene representation under poorly illuminated conditions and with a moving light source. We approach the task of modeling illumination as a learning problem, and utilize the developed illumination model to aid in scene reconstruction. We introduce an innovative framework that uses a data-driven approach, Neural Light Simulators (NeLiS), to model and calibrate the camera-light system. Furthermore, we present DarkGS, a method that applies NeLiS to create a relightable 3D Gaussian scene model capable of real-time, photorealistic rendering from novel viewpoints. We show the applicability and robustness of our proposed simulator and system in a variety of real-world environments.

人类具有在有限或变化的照明条件下构建环境一致心理模型的非凡能力。我们希望赋予机器人同样的能力。在本文中，我们应对在光照不足条件下以及有移动光源时构建真实感场景表示的挑战。我们将照明建模任务视为一个学习问题，并利用开发的照明模型来帮助场景重建。我们引入了一个创新框架，使用数据驱动方法，即神经光模拟器（NeLiS），来模型化和校准相机-光系统。此外，我们提出了DarkGS方法，该方法应用NeLiS创建一个可重新照明的3D高斯场景模型，能够从新的视角进行实时、真实感渲染。我们展示了我们提出的模拟器和系统在各种真实世界环境中的适用性和稳健性。
