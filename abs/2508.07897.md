### NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction

Computer vision-based technologies significantly enhance surgical automation by advancing tool tracking, detection, and localization. However, Current data-driven approaches are data-voracious, requiring large, high-quality labeled image datasets, which limits their application in surgical data science. Our Work introduces a novel dynamic Gaussian Splatting technique to address the data scarcity in surgical image datasets. We propose a dynamic Gaussian model to represent dynamic surgical scenes, enabling the rendering of surgical instruments from unseen viewpoints and deformations with real tissue backgrounds. We utilize a dynamic training adjustment strategy to address challenges posed by poorly calibrated camera poses from real-world scenarios. Additionally, we propose a method based on dynamic Gaussians for automatically generating annotations for our synthetic data. For evaluation, we constructed a new dataset featuring seven scenes with 14,000 frames of tool and camera motion and tool jaw articulation, with a background of an ex-vivo porcine model. Using this dataset, we synthetically replicate the scene deformation from the ground truth data, allowing direct comparisons of synthetic image quality. Experimental results illustrate that our method generates photo-realistic labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio (29.87). We further evaluate the performance of medical-specific neural networks trained on real and synthetic images using an unseen real-world image dataset. Our results show that the performance of models trained on synthetic images generated by the proposed method outperforms those trained with state-of-the-art standard data augmentation by 10%, leading to an overall improvement in model performances by nearly 15%.

计算机视觉技术通过提升手术工具的跟踪、检测与定位能力，显著推动了手术自动化的发展。然而，当前的数据驱动方法对数据依赖极大，需要大规模且高质量的标注图像数据集，这限制了其在手术数据科学中的应用。本文提出了一种新颖的动态高斯溅射技术，以解决手术图像数据集稀缺的问题。我们提出了一种动态高斯模型，用于表示动态手术场景，使得能够在真实组织背景下从未见过的视角和形变中渲染手术器械。我们采用动态训练调整策略，以应对现实场景中相机位姿校准不佳带来的挑战。此外，我们基于动态高斯提出了一种自动生成合成数据标注的方法。为验证该方法，我们构建了一个包含七个场景的新数据集，涵盖14,000帧工具与相机运动及工具钳口开合，并以离体猪模型作为背景。在该数据集上，我们从真实数据中合成复现了场景形变，从而能够直接比较合成图像的质量。实验结果表明，该方法生成的逼真标注图像数据集在峰值信噪比（PSNR）上达到29.87的最高值。进一步地，我们在未见过的真实图像数据集上评估了使用真实与合成图像训练的医学专用神经网络。结果显示，使用本文方法生成的合成图像训练的模型性能比使用最新标准数据增强训练的模型提升了10%，整体性能提高接近15%。
