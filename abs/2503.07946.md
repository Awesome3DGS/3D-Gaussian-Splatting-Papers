### 7DGS: Unified Spatial-Temporal-Angular Gaussian Splatting

Real-time rendering of dynamic scenes with view-dependent effects remains a fundamental challenge in computer graphics. While recent advances in Gaussian Splatting have shown promising results separately handling dynamic scenes (4DGS) and view-dependent effects (6DGS), no existing method unifies these capabilities while maintaining real-time performance. We present 7D Gaussian Splatting (7DGS), a unified framework representing scene elements as seven-dimensional Gaussians spanning position (3D), time (1D), and viewing direction (3D). Our key contribution is an efficient conditional slicing mechanism that transforms 7D Gaussians into view- and time-conditioned 3D Gaussians, maintaining compatibility with existing 3D Gaussian Splatting pipelines while enabling joint optimization. Experiments demonstrate that 7DGS outperforms prior methods by up to 7.36 dB in PSNR while achieving real-time rendering (401 FPS) on challenging dynamic scenes with complex view-dependent effects.

实时渲染具有视角相关效应的动态场景仍然是计算机图形学中的一项基本挑战。尽管高斯投影（Gaussian Splatting）技术的最新进展分别在处理动态场景（4DGS）和视角相关效应（6DGS）方面取得了显著成果，但目前尚无方法能够在保持实时性能的同时统一这两种能力。我们提出 7D 高斯投影（7D Gaussian Splatting, 7DGS），这是一种统一框架，将场景元素表示为七维高斯，涵盖 位置（3D）、时间（1D）和视角方向（3D）。我们的核心贡献是一种高效的 条件切片机制（conditional slicing mechanism），能够将 7D 高斯转换为 视角-时间条件化的 3D 高斯，从而在兼容现有 3D 高斯投影流水线的同时，实现联合优化。实验结果表明，7DGS 在 PSNR 方面比现有方法最高提升 7.36 dB，同时在具有复杂视角相关效应的动态场景中实现了实时渲染（401 FPS）。
