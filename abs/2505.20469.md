### CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting

Recent advances in 3D reconstruction techniques and vision-language models have fueled significant progress in 3D semantic understanding, a capability critical to robotics, autonomous driving, and virtual/augmented reality. However, methods that rely on 2D priors are prone to a critical challenge: cross-view semantic inconsistencies induced by occlusion, image blur, and view-dependent variations. These inconsistencies, when propagated via projection supervision, deteriorate the quality of 3D Gaussian semantic fields and introduce artifacts in the rendered outputs. To mitigate this limitation, we propose CCL-LGS, a novel framework that enforces view-consistent semantic supervision by integrating multi-view semantic cues. Specifically, our approach first employs a zero-shot tracker to align a set of SAM-generated 2D masks and reliably identify their corresponding categories. Next, we utilize CLIP to extract robust semantic encodings across views. Finally, our Contrastive Codebook Learning (CCL) module distills discriminative semantic features by enforcing intra-class compactness and inter-class distinctiveness. In contrast to previous methods that directly apply CLIP to imperfect masks, our framework explicitly resolves semantic conflicts while preserving category discriminability. Extensive experiments demonstrate that CCL-LGS outperforms previous state-of-the-art methods.

近年来，三维重建技术与视觉-语言模型的快速发展，极大推动了三维语义理解的进步，这一能力对于机器人、自主驾驶以及虚拟/增强现实等领域至关重要。然而，依赖二维先验的方法普遍面临一个关键挑战：由遮挡、图像模糊及视角依赖变化所导致的跨视角语义不一致性。这些不一致性在投影监督过程中被传递，会严重影响三维高斯语义场的质量，并在渲染结果中引入伪影。
为缓解这一问题，我们提出了 CCL-LGS，一种通过融合多视角语义信息实现视角一致语义监督的新型框架。具体而言，我们首先使用零样本追踪器对一组由 SAM 生成的二维掩码进行对齐，并可靠地识别其所属类别。随后，利用 CLIP 提取跨视角的稳健语义编码。最后，我们引入对比式码本学习（Contrastive Codebook Learning, CCL）模块，通过增强类内聚合与类间分离，提炼判别性语义特征。
与以往直接将 CLIP 应用于不完美掩码的方法不同，我们的框架显式地解决了语义冲突问题，同时保留了类别区分性。大量实验证明，CCL-LGS 在各项指标上均优于现有的最新方法。
