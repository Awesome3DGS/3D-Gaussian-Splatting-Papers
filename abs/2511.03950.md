### Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization

Reconstructing real-world objects from multi-view images is essential for applications in 3D editing, AR/VR, and digital content creation. Existing methods typically prioritize either geometric accuracy (Multi-View Stereo) or photorealistic rendering (Novel View Synthesis), often decoupling geometry and appearance optimization, which hinders downstream editing tasks. This paper advocates an unified treatment on geometry and appearance optimization for seamless Gaussian-mesh joint optimization. More specifically, we propose a novel framework that simultaneously optimizes mesh geometry (vertex positions and faces) and vertex colors via Gaussian-guided mesh differentiable rendering, leveraging photometric consistency from input images and geometric regularization from normal and depth maps. The obtained high-quality 3D reconstruction can be further exploit in down-stream editing tasks, such as relighting and shape deformation.

从多视角图像中重建真实世界的物体对于三维编辑、增强现实/虚拟现实（AR/VR）以及数字内容创作等应用至关重要。现有方法通常倾向于在几何精度（如多视图立体重建）或照片级真实渲染（如新视角合成）之间做权衡，往往将几何与外观优化过程解耦，这在很大程度上限制了后续的编辑任务。本文倡导对几何与外观优化进行统一处理，实现高斯与网格的联合优化。具体而言，我们提出了一个新颖的框架，能够通过高斯引导的可微分网格渲染同时优化网格几何（顶点位置与面片）和顶点颜色，该框架利用输入图像的光度一致性以及法线图与深度图提供的几何正则信息。最终获得的高质量三维重建结果可以进一步用于后续的编辑任务，例如重光照和形状变形。
