### HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian Splatting

Generating high-quality novel view renderings of 3D Gaussian Splatting (3DGS) in scenes featuring transient objects is challenging. We propose a novel hybrid representation, termed as HybridGS, using 2D Gaussians for transient objects per image and maintaining traditional 3D Gaussians for the whole static scenes. Note that, the 3DGS itself is better suited for modeling static scenes that assume multi-view consistency, but the transient objects appear occasionally and do not adhere to the assumption, thus we model them as planar objects from a single view, represented with 2D Gaussians. Our novel representation decomposes the scene from the perspective of fundamental viewpoint consistency, making it more reasonable. Additionally, we present a novel multi-view regulated supervision method for 3DGS that leverages information from co-visible regions, further enhancing the distinctions between the transients and statics. Then, we propose a straightforward yet effective multi-stage training strategy to ensure robust training and high-quality view synthesis across various settings. Experiments on benchmark datasets show our state-of-the-art performance of novel view synthesis in both indoor and outdoor scenes, even in the presence of distracting elements.

在包含瞬态物体的场景中生成高质量的新视角渲染是三维高斯散点（3D Gaussian Splatting, 3DGS）的一个挑战。本文提出了一种新颖的混合表示方法，称为HybridGS，利用二维高斯表示每幅图像中的瞬态物体，同时保持传统的三维高斯表示整个静态场景。
需要注意的是，3DGS更适合建模具有多视图一致性的静态场景，而瞬态物体偶尔出现且不符合多视图一致性的假设。因此，我们将它们建模为单视图平面物体，用二维高斯表示。我们的新表示方法从基本视角一致性的角度对场景进行分解，使其更加合理。
此外，我们提出了一种新颖的多视图调控监督方法，用于3DGS，通过利用共视区域的信息进一步增强瞬态物体和静态场景之间的区分。随后，我们设计了一种简单但有效的多阶段训练策略，以确保在各种设置下实现稳健的训练和高质量的视角合成。
在基准数据集上的实验表明，HybridGS在室内和室外场景的新视角合成中表现出色，即使在存在干扰元素的情况下，仍能实现最先进的性能。这表明该方法在同时处理动态和静态场景元素方面具有显著优势。
