### LUCAS: Layered Universal Codec Avatars

Photorealistic 3D head avatar reconstruction faces critical challenges in modeling dynamic face-hair interactions and achieving cross-identity generalization, particularly during expressions and head movements. We present LUCAS, a novel Universal Prior Model (UPM) for codec avatar modeling that disentangles face and hair through a layered representation. Unlike previous UPMs that treat hair as an integral part of the head, our approach separates the modeling of the hairless head and hair into distinct branches. LUCAS is the first to introduce a mesh-based UPM, facilitating real-time rendering on devices. Our layered representation also improves the anchor geometry for precise and visually appealing Gaussian renderings. Experimental results indicate that LUCAS outperforms existing single-mesh and Gaussian-based avatar models in both quantitative and qualitative assessments, including evaluations on held-out subjects in zero-shot driving scenarios. LUCAS demonstrates superior dynamic performance in managing head pose changes, expression transfer, and hairstyle variations, thereby advancing the state-of-the-art in 3D head avatar reconstruction.

逼真的 3D 头像重建在建模动态面部-头发交互以及实现跨身份泛化方面面临关键挑战，特别是在表情变化和头部运动时。为此，我们提出 LUCAS，一种用于编解码头像建模（codec avatar modeling）的通用先验模型（Universal Prior Model, UPM），其核心创新在于通过**分层表示（layered representation）**实现面部与头发的解耦。
与以往将头发视为头部整体一部分的 UPM 方法不同，我们的方法将无发头部与头发建模为独立分支，分别处理。这一方法首次引入基于网格（mesh-based）的 UPM，从而实现设备端的实时渲染。此外，我们的分层表示还优化了锚点几何（anchor geometry），提升了**高斯渲染（Gaussian renderings）**的精度和视觉效果。
实验结果表明，LUCAS 在单网格（single-mesh）和基于高斯的头像模型中均表现优异，在零样本（zero-shot）驱动场景下，对未见过的测试对象进行评估，展现了卓越的定量和定性优势。LUCAS 在头部姿态变化、表情迁移和发型变化等动态场景中的表现显著优于现有方法，推动了 3D 头像重建的最前沿技术发展。
