### Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction

The 3D occupancy prediction task has witnessed remarkable progress in recent years, playing a crucial role in vision-based autonomous driving systems. While traditional methods are limited to fixed semantic categories, recent approaches have moved towards predicting text-aligned features to enable open-vocabulary text queries in real-world scenes. However, there exists a trade-off in text-aligned scene modeling: sparse Gaussian representation struggles to capture small objects in the scene, while dense representation incurs significant computational overhead. To address these limitations, we present PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables open-vocabulary 3D occupancy prediction. Our framework employs progressive online densification, a feed-forward strategy that gradually enhances the 3D Gaussian representation to capture fine-grained scene details. By iteratively enhancing the representation, the framework achieves increasingly precise and detailed scene understanding. Another key contribution is the introduction of an anisotropy-aware sampling strategy with spatio-temporal fusion, which adaptively assigns receptive fields to Gaussians at different scales and stages, enabling more effective feature aggregation and richer scene information capture. Through extensive evaluations, we demonstrate that PG-Occ achieves state-of-the-art performance with a relative 14.3% mIoU improvement over the previous best performing method.

近年来，三维占据预测任务取得了显著进展，在基于视觉的自动驾驶系统中发挥着关键作用。传统方法通常局限于固定的语义类别，而最新研究则逐渐转向预测与文本对齐的特征，以支持真实场景中的开放词汇查询。然而，文本对齐的场景建模存在权衡：稀疏的高斯表示难以捕捉场景中的小物体，而稠密表示则带来较高的计算开销。为了解决这一问题，我们提出了 PG-Occ——一种创新的渐进式高斯变换器框架，用于实现开放词汇的三维占据预测。该框架采用渐进式在线加密策略，这是一种前馈式方法，能够逐步增强三维高斯表示，从而捕捉细粒度的场景细节。通过迭代式表示增强，模型实现了越来越精细且精准的场景理解。另一个关键贡献是引入了具备各向异性感知能力的采样策略，并结合时空融合机制，能够在不同尺度与阶段自适应地分配高斯的感受野，从而实现更有效的特征聚合与更丰富的场景信息捕捉。大量评估结果表明，PG-Occ 在性能上达到当前最先进水平，相较于此前最优方法，mIoU 提升达 14.3%。
