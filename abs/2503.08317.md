### Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for Dynamic Driving Scenarios

Ensuring the safety of autonomous vehicles necessitates comprehensive simulation of multi-sensor data, encompassing inputs from both cameras and LiDAR sensors, across various dynamic driving scenarios. Neural rendering techniques, which utilize collected raw sensor data to simulate these dynamic environments, have emerged as a leading methodology. While NeRF-based approaches can uniformly represent scenes for rendering data from both camera and LiDAR, they are hindered by slow rendering speeds due to dense sampling. Conversely, Gaussian Splatting-based methods employ Gaussian primitives for scene representation and achieve rapid rendering through rasterization. However, these rasterization-based techniques struggle to accurately model non-linear optical sensors. This limitation restricts their applicability to sensors beyond pinhole cameras. To address these challenges and enable unified representation of dynamic driving scenarios using Gaussian primitives, this study proposes a novel hybrid approach. Our method utilizes rasterization for rendering image data while employing Gaussian ray-tracing for LiDAR data rendering. Experimental results on public datasets demonstrate that our approach outperforms current state-of-the-art methods. This work presents a unified and efficient solution for realistic simulation of camera and LiDAR data in autonomous driving scenarios using Gaussian primitives, offering significant advancements in both rendering quality and computational efficiency.

确保 自动驾驶车辆的安全性 需要对 多传感器数据 进行全面模拟，包括 摄像头（cameras） 和 LiDAR 传感器 在 各种动态驾驶场景 下的输入。近年来，神经渲染（neural rendering） 技术利用采集的原始传感器数据来模拟这些动态环境，已成为主要方法之一。
基于 NeRF 的方法 可以 统一表示场景，以同时渲染来自摄像头和 LiDAR 的数据，但由于 需要密集采样（dense sampling），其渲染速度较慢。相比之下，基于高斯投影（Gaussian Splatting）的方法 通过 高斯原语（Gaussian primitives） 进行场景表示，并利用 光栅化（rasterization） 实现快速渲染。然而，这些 基于光栅化的技术难以准确建模非线性光学传感器（non-linear optical sensors），从而限制了其在 针孔相机（pinhole cameras）以外的传感器 上的适用性。
为了解决这些挑战，并实现 使用高斯原语对动态驾驶场景的统一表示，本研究提出了一种 新型混合方法（hybrid approach）。我们的方法采用 光栅化（rasterization） 来渲染 图像数据（image data），同时利用 高斯光线追踪（Gaussian ray-tracing） 进行 LiDAR 数据渲染。
在 公开数据集 上的实验结果表明，我们的方法 优于当前最先进的（state-of-the-art）方法。本研究提出了一种 统一且高效的解决方案，可用于 自动驾驶场景中的摄像头和 LiDAR 数据的真实感模拟，在 渲染质量 和 计算效率 方面均取得了重要进展。
