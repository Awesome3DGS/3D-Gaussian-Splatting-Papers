### IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes

Reconstructing dynamic driving scenes is essential for developing autonomous systems through sensor-realistic simulation. Although recent methods achieve high-fidelity reconstructions, they either rely on costly human annotations for object trajectories or use time-varying representations without explicit object-level decomposition, leading to intertwined static and dynamic elements that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian Splatting framework that reconstructs dynamic scenes with explicit instance decomposition and learnable motion trajectories, without requiring human annotations. Our key insight is to model dynamic objects as coherent instances undergoing rigid transformations, rather than unstructured time-varying primitives. For instance decomposition, we employ zero-shot, language-grounded video tracking anchored to 3D using lidar, and estimate consistent poses via feature correspondences. We introduce a coordinated-turn smoothing scheme to obtain temporally and physically consistent motion trajectories, mitigating pose misalignments and tracking failures, followed by joint optimization of object poses and Gaussian parameters. Experiments on the Waymo Open Dataset demonstrate that our method achieves competitive reconstruction quality while maintaining instance-level decomposition and generalizes across diverse sequences and view densities without retraining, making it practical for large-scale autonomous driving applications.

动态驾驶场景的重建对于通过传感器真实感模拟发展自动驾驶系统至关重要。尽管近期方法已能实现高保真重建，但它们往往依赖昂贵的人工标注以获取物体轨迹，或采用不具备显式实例级分解的时变表示，从而导致静态与动态元素相互交织，难以实现清晰的场景分离。我们提出 IDSplat，一种自监督的三维高斯溅射框架，能够在无需人工标注的前提下，实现具有显式实例分解与可学习运动轨迹的动态场景重建。其核心思想是将动态物体建模为执行刚性变换的连贯实例，而非非结构化的时变基元。在实例分解方面，我们结合激光雷达数据，利用零样本、语言引导的视频跟踪方法将对象锚定于三维空间，并通过特征匹配估计一致的姿态。我们还提出了协同转向平滑机制，以获得时间上与物理上均一致的运动轨迹，从而缓解姿态误差与跟踪失败问题，并进一步联合优化物体姿态与高斯参数。在 Waymo Open Dataset 上的实验证明，IDSplat 在保持实例级分解的同时，实现了有竞争力的重建质量，且在不同序列和视角密度条件下具备良好的泛化能力，无需重新训练，展现出其在大规模自动驾驶应用中的实用性。
