### GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition

We propose a unified solution for mesh reconstruction and material decomposition from multi-view images based on 3D Gaussian Splatting, referred to as GS-2M. Previous works handle these tasks separately and struggle to reconstruct highly reflective surfaces, often relying on priors from external models to enhance the decomposition results. Conversely, our method addresses these two problems by jointly optimizing attributes relevant to the quality of rendered depth and normals, maintaining geometric details while being resilient to reflective surfaces. Although contemporary works effectively solve these tasks together, they often employ sophisticated neural components to learn scene properties, which hinders their performance at scale. To further eliminate these neural components, we propose a novel roughness supervision strategy based on multi-view photometric variation. When combined with a carefully designed loss and optimization process, our unified framework produces reconstruction results comparable to state-of-the-art methods, delivering triangle meshes and their associated material components for downstream tasks. We validate the effectiveness of our approach with widely used datasets from previous works and qualitative comparisons with state-of-the-art surface reconstruction methods.

我们提出了一种基于三维高斯溅射（3D Gaussian Splatting）的统一解决方案，用于从多视图图像中同时进行网格重建与材质分解，称为 **GS-2M**。以往的研究通常将这两项任务分开处理，并且在重建高反射表面时表现不佳，往往依赖外部模型的先验知识来提升分解效果。相反，我们的方法通过联合优化影响渲染深度与法线质量的属性，在保持几何细节的同时，对高反射表面具有更强的鲁棒性。尽管一些当代方法能够同时解决这两项任务，但它们往往采用复杂的神经组件来学习场景属性，从而限制了大规模场景下的性能。为进一步消除对这些神经组件的依赖，我们提出了一种基于多视图光度变化的新型粗糙度监督策略。结合精心设计的损失函数与优化过程，我们的统一框架能够生成与当前最先进方法相当的重建结果，同时输出可用于下游任务的三角网格及其对应的材质组件。我们通过多个常用基准数据集及与主流表面重建方法的定性比较验证了该方法的有效性。
