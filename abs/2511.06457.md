### Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360° Scenes

Despite recent advances in single-object front-facing inpainting using NeRF and 3D Gaussian Splatting (3DGS), inpainting in complex 360° scenes remains largely underexplored. This is primarily due to three key challenges: (i) identifying target objects in the 3D field of 360° environments, (ii) dealing with severe occlusions in multi-object scenes, which makes it hard to define regions to inpaint, and (iii) maintaining consistent and high-quality appearance across views effectively. To tackle these challenges, we propose Inpaint360GS, a flexible 360° editing framework based on 3DGS that supports multi-object removal and high-fidelity inpainting in 3D space. By distilling 2D segmentation into 3D and leveraging virtual camera views for contextual guidance, our method enables accurate object-level editing and consistent scene completion. We further introduce a new dataset tailored for 360° inpainting, addressing the lack of ground truth object-free scenes. Experiments demonstrate that Inpaint360GS outperforms existing baselines and achieves state-of-the-art performance.

尽管近年来基于 NeRF 和三维高斯溅射（3D Gaussian Splatting，3DGS）的单目标正面视角修复取得了显著进展，但在复杂的 360° 场景中进行修复仍然缺乏系统性的研究。这主要源于三项关键挑战：（i）在 360° 环境的三维场中准确识别目标物体；（ii）多物体场景中普遍存在的严重遮挡问题，使得待修复区域难以精确定义；以及（iii）如何在不同视角之间有效地保持一致且高质量的外观。为应对上述挑战，我们提出了 Inpaint360GS，一种基于 3DGS 的灵活 360° 编辑框架，支持多目标移除以及三维空间中的高保真修复。通过将二维分割结果蒸馏至三维表示，并利用虚拟相机视角提供上下文引导，我们的方法实现了精确的物体级编辑与一致的场景补全。此外，我们还引入了一个专为 360° 修复任务设计的新数据集，以弥补缺乏无目标真实场景真值数据的问题。实验结果表明，Inpaint360GS 优于现有基线方法，并达到了当前最先进的性能水平。
