### LiDAR-enhanced 3D Gaussian Splatting Mapping

This paper introduces LiGSM, a novel LiDAR-enhanced 3D Gaussian Splatting (3DGS) mapping framework that improves the accuracy and robustness of 3D scene mapping by integrating LiDAR data. LiGSM constructs joint loss from images and LiDAR point clouds to estimate the poses and optimize their extrinsic parameters, enabling dynamic adaptation to variations in sensor alignment. Furthermore, it leverages LiDAR point clouds to initialize 3DGS, providing a denser and more reliable starting points compared to sparse SfM points. In scene rendering, the framework augments standard image-based supervision with depth maps generated from LiDAR projections, ensuring an accurate scene representation in both geometry and photometry. Experiments on public and self-collected datasets demonstrate that LiGSM outperforms comparative methods in pose tracking and scene rendering.

本文提出 LiGSM，一种基于 LiDAR 增强的 3D 高斯散点 (LiDAR-enhanced 3D Gaussian Splatting, 3DGS) 映射框架，通过融合 LiDAR 数据来提升三维场景映射的精度和鲁棒性。
LiGSM 通过图像和 LiDAR 点云构建联合损失 (Joint Loss)，用于位姿估计 (Pose Estimation) 并优化其外参 (Extrinsic Parameters)，从而能够动态适应传感器对齐的变化。此外，该方法利用LiDAR 点云初始化 3DGS，相比稀疏的结构光测绘 (Structure-from-Motion, SfM) 点云，提供更密集、更可靠的初始点。
在场景渲染方面，该框架结合标准的基于图像监督与由 LiDAR 投影生成的深度图 (Depth Maps)，确保几何和光度上的精确场景表示。
在多个公开数据集和自采集数据集上的实验表明，LiGSM 在位姿跟踪 (Pose Tracking) 和场景渲染 (Scene Rendering) 方面均优于现有方法，展现了其优越的性能和应用潜力。
