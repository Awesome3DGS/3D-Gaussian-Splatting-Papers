### From Flight to Insight: Semantic 3D Reconstruction for Aerial Inspection via Gaussian Splatting and Language-Guided Segmentation

High-fidelity 3D reconstruction is critical for aerial inspection tasks such as infrastructure monitoring, structural assessment, and environmental surveying. While traditional photogrammetry techniques enable geometric modeling, they lack semantic interpretability, limiting their effectiveness for automated inspection workflows. Recent advances in neural rendering and 3D Gaussian Splatting (3DGS) offer efficient, photorealistic reconstructions but similarly lack scene-level understanding.
In this work, we present a UAV-based pipeline that extends Feature-3DGS for language-guided 3D segmentation. We leverage LSeg-based feature fields with CLIP embeddings to generate heatmaps in response to language prompts. These are thresholded to produce rough segmentations, and the highest-scoring point is then used as a prompt to SAM or SAM2 for refined 2D segmentation on novel view renderings. Our results highlight the strengths and limitations of various feature field backbones (CLIP-LSeg, SAM, SAM2) in capturing meaningful structure in large-scale outdoor environments. We demonstrate that this hybrid approach enables flexible, language-driven interaction with photorealistic 3D reconstructions, opening new possibilities for semantic aerial inspection and scene understanding.

高保真三维重建在基础设施监测、结构评估与环境勘测等无人机空中巡检任务中具有关键作用。尽管传统的摄影测量技术能够实现几何建模，但其缺乏语义可解释性，限制了其在自动化巡检流程中的应用效果。近年来，神经渲染与三维高斯散点（3D Gaussian Splatting, 3DGS）技术的进展，使得高效、照片级真实感的重建成为可能，但同样缺乏对场景层级的理解。
在本研究中，我们提出了一条基于无人机的处理流程，将 Feature-3DGS 扩展用于语言引导的三维语义分割。该方法利用基于 LSeg 的特征场与 CLIP 嵌入，将语言提示词映射为响应热力图。通过阈值处理获得粗略分割区域，并以得分最高的点作为提示，引导 SAM 或 SAM2 在新视角渲染图像上进行精细的二维分割。
实验结果展示了不同特征场骨干（如 CLIP-LSeg、SAM、SAM2）在捕捉大规模户外场景中语义结构方面的优劣。我们表明，该混合方法支持灵活的、基于语言的人机交互方式，能够在照片级三维重建结果上实现语义引导的巡检与场景理解，为语义化空中巡检带来了新的可能性。
