### EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events

Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over traditional SLAM methods, enabling photorealistic 3D reconstruction that conventional approaches often struggle to achieve. However, existing GS-SLAM systems perform poorly under persistent and severe motion blur commonly encountered in real-world scenarios, leading to significantly degraded tracking accuracy and compromised 3D reconstruction quality. To address this limitation, we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D inputs to simultaneously reduce motion blur in images and compensate for the sparse and discrete nature of event streams, enabling robust tracking and high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system explicitly models the camera's continuous trajectory during exposure, supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian Splatting scene. Furthermore, we introduce a learnable camera response function to align the dynamic ranges of events and images, along with a no-event loss to suppress ringing artifacts during reconstruction. We validate our approach on a new dataset comprising synthetic and real-world sequences with significant motion blur. Extensive experimental results demonstrate that EGS-SLAM consistently outperforms existing GS-SLAM systems in both trajectory accuracy and photorealistic 3D Gaussian Splatting reconstruction.

高斯溅射SLAM（GS-SLAM）相较于传统SLAM方法具有显著提升，能够实现传统方法难以达到的逼真三维重建。然而，现有的GS-SLAM系统在真实场景中常见的持续性和严重运动模糊条件下表现不佳，导致跟踪精度大幅下降，三维重建质量受损。为解决这一局限，我们提出了EGS-SLAM，这是一种新颖的GS-SLAM框架，将事件数据与RGB-D输入融合，在减少图像运动模糊的同时，弥补事件流稀疏和离散的特性，从而实现稳健的跟踪和高保真三维高斯溅射重建。具体而言，我们的系统显式建模了曝光期间相机的连续轨迹，支持在统一的三维高斯溅射场景中进行事件感知与模糊感知的跟踪和建图。此外，我们引入了可学习的相机响应函数，用于对齐事件与图像的动态范围，并提出了无事件损失（no-event loss），以抑制重建过程中的振铃伪影。我们在包含显著运动模糊的合成和真实序列的新数据集上验证了该方法。大量实验结果表明，EGS-SLAM在轨迹精度和逼真三维高斯溅射重建方面均稳定优于现有的GS-SLAM系统。
