### FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers

Despite significant progress in 3D avatar reconstruction, it still faces challenges such as high time complexity, sensitivity to data quality, and low data utilization. We propose FastAvatar, a feedforward 3D avatar framework capable of flexibly leveraging diverse daily recordings (e.g., a single image, multi-view observations, or monocular video) to reconstruct a high-quality 3D Gaussian Splatting (3DGS) model within seconds, using only a single unified model. FastAvatar's core is a Large Gaussian Reconstruction Transformer featuring three key designs: First, a variant VGGT-style transformer architecture aggregating multi-frame cues while injecting initial 3D prompt to predict an aggregatable canonical 3DGS representation; Second, multi-granular guidance encoding (camera pose, FLAME expression, head pose) mitigating animation-induced misalignment for variable-length inputs; Third, incremental Gaussian aggregation via landmark tracking and sliced fusion losses. Integrating these features, FastAvatar enables incremental reconstruction, i.e., improving quality with more observations, unlike prior work wasting input data. This yields a quality-speed-tunable paradigm for highly usable avatar modeling. Extensive experiments show that FastAvatar has higher quality and highly competitive speed compared to existing methods.

尽管三维虚拟人重建已取得显著进展，但仍面临计算复杂度高、对数据质量敏感、数据利用率低等挑战。我们提出了 **FastAvatar**，一个前馈式三维虚拟人框架，能够灵活利用多样化的日常记录（如单张图像、多视角观测或单目视频），在数秒内利用单一统一模型重建出高质量的三维高斯点绘（3D Gaussian Splatting, 3DGS）模型。FastAvatar 的核心是一个 **大型高斯重建 Transformer**，具有三个关键设计：第一，VGGT 风格的变体 Transformer 架构，在引入初始三维提示的同时聚合多帧信息，以预测可聚合的规范化 3DGS 表示；第二，多粒度引导编码（相机位姿、FLAME 表情、头部姿态），缓解动画引起的错位问题，适配可变长度输入；第三，通过基于关键点跟踪和切片融合损失的增量高斯聚合机制实现逐步优化。通过整合这些特性，FastAvatar 实现了增量式重建，即随着观测数量的增加提升重建质量，而不同于以往方法对输入数据的浪费。这为虚拟人建模带来了一个质量与速度可调的高实用性范式。大量实验结果表明，FastAvatar 相比现有方法具有更高的质量和极具竞争力的速度。
