### VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion

Recent success in legged robot locomotion is attributed to the integration of reinforcement learning and physical simulators. However, these policies often encounter challenges when deployed in real-world environments due to sim-to-real gaps, as simulators typically fail to replicate visual realism and complex real-world geometry. Moreover, the lack of realistic visual rendering limits the ability of these policies to support high-level tasks requiring RGB-based perception like ego-centric navigation. This paper presents a Real-to-Sim-to-Real framework that generates photorealistic and physically interactive "digital twin" simulation environments for visual navigation and locomotion learning. Our approach leverages 3D Gaussian Splatting (3DGS) based scene reconstruction from multi-view images and integrates these environments into simulations that support ego-centric visual perception and mesh-based physical interactions. To demonstrate its effectiveness, we train a reinforcement learning policy within the simulator to perform a visual goal-tracking task. Extensive experiments show that our framework achieves RGB-only sim-to-real policy transfer. Additionally, our framework facilitates the rapid adaptation of robot policies with effective exploration capability in complex new environments, highlighting its potential for applications in households and factories.

最近，四足机器人运动的成功归功于强化学习与物理仿真器的结合。然而，这些策略在部署到实际环境时常常面临挑战，因为仿真器通常无法真实再现视觉效果和复杂的现实世界几何形状，这导致了模拟与现实之间的差距。此外，缺乏逼真的视觉渲染限制了这些策略支持高层任务（如基于RGB的自我导航）的能力。本文提出了一种“现实-仿真-现实”框架，生成逼真且物理互动的“数字孪生”仿真环境，用于视觉导航和运动学习。我们的方法利用基于3D高斯溅射（3DGS）的多视角图像场景重建，并将这些环境集成到支持自我中心视觉感知和基于网格的物理交互的仿真中。为了验证其有效性，我们在仿真器中训练了一个强化学习策略，执行视觉目标跟踪任务。大量实验表明，我们的框架实现了仅基于RGB的模拟到现实策略转移。此外，我们的框架还促进了机器人策略在复杂新环境中的快速适应，并具有有效的探索能力，突显了其在家庭和工厂应用中的潜力。
