### RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions

Feedforward 3D Gaussian Splatting (3DGS) overcomes the limitations of optimization-based 3DGS by enabling fast and high-quality reconstruction without the need for per-scene optimization. However, existing feedforward approaches typically assume that input multi-view images are clean and high-quality. In real-world scenarios, images are often captured under challenging conditions such as noise, low light, or rain, resulting in inaccurate geometry and degraded 3D reconstruction. To address these challenges, we propose a general and efficient multi-view feature enhancement module, RobustGS, which substantially improves the robustness of feedforward 3DGS methods under various adverse imaging conditions, enabling high-quality 3D reconstruction. The RobustGS module can be seamlessly integrated into existing pretrained pipelines in a plug-and-play manner to enhance reconstruction robustness. Specifically, we introduce a novel component, Generalized Degradation Learner, designed to extract generic representations and distributions of multiple degradations from multi-view inputs, thereby enhancing degradation-awareness and improving the overall quality of 3D reconstruction. In addition, we propose a novel semantic-aware state-space model. It first leverages the extracted degradation representations to enhance corrupted inputs in the feature space. Then, it employs a semantic-aware strategy to aggregate semantically similar information across different views, enabling the extraction of fine-grained cross-view correspondences and further improving the quality of 3D representations. Extensive experiments demonstrate that our approach, when integrated into existing methods in a plug-and-play manner, consistently achieves state-of-the-art reconstruction quality across various types of degradations.

前向三维高斯溅射（Feedforward 3D Gaussian Splatting，3DGS）通过实现无需逐场景优化的快速高质量重建，克服了基于优化的 3DGS 方法的局限性。然而，现有前向方法通常假设输入的多视图图像是干净且高质量的。在实际场景中，图像常常是在噪声、低光照或雨天等具有挑战性的条件下采集的，从而导致几何不准确和三维重建质量下降。为应对这些挑战，我们提出了一个通用且高效的多视图特征增强模块——RobustGS，它能在多种不利成像条件下显著提升前向 3DGS 方法的鲁棒性，从而实现高质量的三维重建。RobustGS 模块可以以即插即用的方式无缝集成到现有的预训练管线中，从而增强重建的鲁棒性。具体而言，我们引入了一个新组件——广义退化学习器（Generalized Degradation Learner），用于从多视图输入中提取多种退化的通用表征与分布，从而提升退化感知能力并改善整体三维重建质量。此外，我们提出了一种新的语义感知状态空间模型：该模型首先利用提取的退化表征在特征空间中增强受损输入；随后，采用语义感知策略聚合跨视图中语义相似的信息，从而提取精细的跨视图对应关系，进一步提升三维表示质量。大量实验表明，当以即插即用的方式集成到现有方法中时，我们的方法在多种退化类型下均能稳定实现最先进的重建质量。
