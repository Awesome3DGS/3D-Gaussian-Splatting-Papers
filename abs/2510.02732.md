### From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting

Dynamic 3D reconstruction from monocular videos remains difficult due to the ambiguity inferring 3D motion from limited views and computational demands of modeling temporally varying scenes. While recent sparse control methods alleviate computation by reducing millions of Gaussians to thousands of control points, they suffer from a critical limitation: they allocate points purely by geometry, leading to static redundancy and dynamic insufficiency. We propose a motion-adaptive framework that aligns control density with motion complexity. Leveraging semantic and motion priors from vision foundation models, we establish patch-token-node correspondences and apply motion-adaptive compression to concentrate control points in dynamic regions while suppressing redundancy in static backgrounds. Our approach achieves flexible representational density adaptation through iterative voxelization and motion tendency scoring, directly addressing the fundamental mismatch between control point allocation and motion complexity. To capture temporal evolution, we introduce spline-based trajectory parameterization initialized by 2D tracklets, replacing MLP-based deformation fields to achieve smoother motion representation and more stable optimization. Extensive experiments demonstrate significant improvements in reconstruction quality and efficiency over existing state-of-the-art methods.

从单目视频中进行动态三维重建仍然是一项具有挑战性的任务，原因在于从有限视角中推理三维运动存在固有歧义，同时对时变场景建模的计算开销巨大。尽管近期的稀疏控制方法通过将百万级高斯点压缩为数千个控制点，从而缓解了计算负担，但它们存在一个关键问题：控制点的分配仅基于几何信息，导致静态区域出现冗余、动态区域控制不足。为此，我们提出了一种运动自适应框架，使控制点密度与运动复杂度相匹配。该方法借助视觉基础模型中的语义和运动先验，构建 patch-token-node 的对应关系，并引入运动自适应压缩策略，将控制点聚焦于动态区域，同时压缩静态背景中的冗余。通过迭代体素化与运动趋势评分，我们实现了灵活的表示密度自适应，有效解决了控制点分配与运动复杂度不匹配的问题。为了更好地捕捉时间演化过程，我们提出基于样条的轨迹参数化方法，以二维跟踪点为初始化，替代基于 MLP 的变形场，进而实现更平滑的运动表达和更稳定的优化过程。大量实验表明，本文方法在重建质量与效率方面均显著优于现有最先进方法。
