### DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring

In this paper, we propose the first Structure-from-Motion (SfM)-free deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat. We address the motion-deblurring problem in two ways. First, we leverage the pretrained capability of the dense stereo module (DUSt3R) to directly obtain accurate initial point clouds from blurred images. Without calculating camera poses as an intermediate result, we avoid the cumulative errors transfer from inaccurate camera poses to the initial point clouds' positions. Second, we introduce the event stream into the deblur pipeline for its high sensitivity to dynamic change. By decoding the latent sharp images from the event stream and blurred images, we can provide a fine-grained supervision signal for scene reconstruction optimization. Extensive experiments across a range of scenes demonstrate that DeblurSplat not only excels in generating high-fidelity novel views but also achieves significant rendering efficiency compared to the SOTAs in deblur 3D-GS.

本文提出了首个基于事件相机的无 SfM（Structure-from-Motion）去模糊三维高斯溅射方法，命名为 DeblurSplat。我们从两个方面解决运动去模糊问题。首先，利用密集立体匹配模块（DUSt3R）的预训练能力，直接从模糊图像中获得精确的初始点云。在不需要计算相机位姿作为中间结果的情况下，我们有效避免了由位姿估计误差传递至初始点云位置的累积误差。其次，我们将事件流引入去模糊流程中，利用其对动态变化的高敏感性。通过结合事件流与模糊图像解码潜在清晰图像，我们能够为场景重建优化提供细粒度的监督信号。在多种场景下的大量实验表明，DeblurSplat 不仅在生成高保真新视图方面表现出色，还在去模糊三维高斯溅射（deblur 3D-GS）任务中相较现有最先进方法（SOTAs）显著提升了渲染效率。
