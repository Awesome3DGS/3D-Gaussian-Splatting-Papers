### ZPressor: Bottleneck-Aware Compression for Scalable Feed-Forward 3DGS

Feed-forward 3D Gaussian Splatting (3DGS) models have recently emerged as a promising solution for novel view synthesis, enabling one-pass inference without the need for per-scene 3DGS optimization. However, their scalability is fundamentally constrained by the limited capacity of their encoders, leading to degraded performance or excessive memory consumption as the number of input views increases. In this work, we analyze feed-forward 3DGS frameworks through the lens of the Information Bottleneck principle and introduce ZPressor, a lightweight architecture-agnostic module that enables efficient compression of multi-view inputs into a compact latent state Z that retains essential scene information while discarding redundancy. Concretely, ZPressor enables existing feed-forward 3DGS models to scale to over 100 input views at 480P resolution on an 80GB GPU, by partitioning the views into anchor and support sets and using cross attention to compress the information from the support views into anchor views, forming the compressed latent state Z. We show that integrating ZPressor into several state-of-the-art feed-forward 3DGS models consistently improves performance under moderate input views and enhances robustness under dense view settings on two large-scale benchmarks DL3DV-10K and RealEstate10K.

前馈式的 3D 高斯投影（3D Gaussian Splatting，3DGS）模型近年来成为新视角合成的一种有前景的解决方案，能够在无需对每个场景单独优化的情况下实现一次性推理。然而，这类方法的可扩展性受到其编码器容量的根本限制——当输入视图数量增加时，要么性能下降，要么内存消耗剧增。
在本研究中，我们从信息瓶颈（Information Bottleneck）原理的角度对前馈式 3DGS 框架进行了分析，并提出了 ZPressor：一个轻量级、与架构无关的模块，能够将多视图输入有效压缩为一个紧凑的潜在状态 $Z$，在保留关键信息的同时去除冗余内容。
具体来说，ZPressor 通过将输入视图划分为锚视图（anchor views）和支撑视图（support views），并利用**跨注意力机制（cross attention）**将支撑视图中的信息压缩到锚视图中，从而形成潜在状态 $Z$。借助 ZPressor，现有前馈式 3DGS 模型可以在单个 80GB 显存的 GPU 上扩展到处理 超过 100 张 480P 输入图像。
实验表明，在多个先进的前馈式 3DGS 模型中集成 ZPressor，能够在中等视图数量条件下显著提升性能，并在密集视图设置下增强模型鲁棒性。我们在两个大规模基准数据集——DL3DV-10K 和 RealEstate10K 上验证了这一点。
