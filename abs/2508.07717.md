### Touch-Augmented Gaussian Splatting for Enhanced 3D Scene Reconstruction

This paper presents a multimodal framework that integrates touch signals (contact points and surface normals) into 3D Gaussian Splatting (3DGS). Our approach enhances scene reconstruction, particularly under challenging conditions like low lighting, limited camera viewpoints, and occlusions. Different from the visual-only method, the proposed approach incorporates spatially selective touch measurements to refine both the geometry and appearance of the 3D Gaussian representation. To guide the touch exploration, we introduce a two-stage sampling scheme that initially probes sparse regions and then concentrates on high-uncertainty boundaries identified from the reconstructed mesh. A geometric loss is proposed to ensure surface smoothness, resulting in improved geometry. Experimental results across diverse scenarios show consistent improvements in geometric accuracy. In the most challenging case with severe occlusion, the Chamfer Distance is reduced by over 15x, demonstrating the effectiveness of integrating touch cues into 3D Gaussian Splatting. Furthermore, our approach maintains a fully online pipeline, underscoring its feasibility in visually degraded environments.

本文提出了一种多模态框架，将触觉信号（接触点与表面法向）融入三维高斯溅射（3DGS）。该方法增强了场景重建能力，尤其适用于光照不足、摄像机视角有限以及存在遮挡等复杂环境。不同于纯视觉方法，本文提出的方法引入了空间选择性的触觉测量，用于优化三维高斯表示的几何与外观。为引导触觉探索，我们设计了一个两阶段采样方案，先在稀疏区域进行探测，再聚焦于由重建网格识别出的高不确定性边界。我们提出了一种几何损失，用以保证表面平滑性，从而提升几何质量。在多种场景下的实验结果表明，该方法在几何精度方面均有显著提升。在最具挑战性的严重遮挡场景中，Chamfer 距离降低了超过15倍，证明了触觉信息融入三维高斯溅射的有效性。此外，该方法保持了全在线处理流程，凸显了其在视觉退化环境下的可行性。
