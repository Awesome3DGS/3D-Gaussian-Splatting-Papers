### ForestSplats: Deformable transient field for Gaussian Splatting in the Wild

Recently, 3D Gaussian Splatting (3D-GS) has emerged, showing real-time rendering speeds and high-quality results in static scenes. Although 3D-GS shows effectiveness in static scenes, their performance significantly degrades in real-world environments due to transient objects, lighting variations, and diverse levels of occlusion. To tackle this, existing methods estimate occluders or transient elements by leveraging pre-trained models or integrating additional transient field pipelines. However, these methods still suffer from two defects: 1) Using semantic features from the Vision Foundation model (VFM) causes additional computational costs. 2) The transient field requires significant memory to handle transient elements with per-view Gaussians and struggles to define clear boundaries for occluders, solely relying on photometric errors. To address these problems, we propose ForestSplats, a novel approach that leverages the deformable transient field and a superpixel-aware mask to efficiently represent transient elements in the 2D scene across unconstrained image collections and effectively decompose static scenes from transient distractors without VFM. We designed the transient field to be deformable, capturing per-view transient elements. Furthermore, we introduce a superpixel-aware mask that clearly defines the boundaries of occluders by considering photometric errors and superpixels. Additionally, we propose uncertainty-aware densification to avoid generating Gaussians within the boundaries of occluders during densification. Through extensive experiments across several benchmark datasets, we demonstrate that ForestSplats outperforms existing methods without VFM and shows significant memory efficiency in representing transient elements.

最近，三维高斯散点（3D Gaussian Splatting，3D-GS）技术兴起，在静态场景中展现了实时渲染速度和高质量的效果。尽管 3D-GS 在静态场景中表现出色，但在真实世界环境下，其性能会因瞬态物体、光照变化和不同程度的遮挡而显著下降。为了解决这一问题，现有方法通常利用预训练模型或集成额外的瞬态场景建模管线来估计遮挡物或瞬态元素。然而，这些方法仍然存在两个主要缺陷：1）依赖视觉基础模型（Vision Foundation Model，VFM）提取语义特征会导致额外的计算开销；2）瞬态场景建模需要大量内存来处理基于视角的高斯表示，并且仅依赖光度误差难以明确划定遮挡物的边界。
针对这些问题，我们提出 ForestSplats，一种新颖的方法，它结合可变形瞬态场景建模和 超像素感知掩码（superpixel-aware mask），能够高效地在无约束图像集合中表示 2D 场景中的瞬态元素，并在不依赖 VFM 的情况下有效地将静态场景从瞬态干扰中分离。我们设计的瞬态场景建模是可变形的，可以捕捉基于视角的瞬态元素。此外，我们引入了超像素感知掩码，综合考虑光度误差和超像素信息，从而清晰地定义遮挡物的边界。此外，我们提出了不确定性感知加密策略（uncertainty-aware densification），在加密过程中避免在遮挡物边界内生成高斯点。
通过在多个基准数据集上的广泛实验，我们证明 ForestSplats 在不依赖 VFM 的情况下优于现有方法，并在瞬态元素的表示上展现出显著的内存效率。

