### DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting

Recent advances in 3D Gaussian Splatting (3D-GS) have shown remarkable success in representing 3D scenes and generating high-quality, novel views in real-time. However, 3D-GS and its variants assume that input images are captured based on pinhole imaging and are fully in focus. This assumption limits their applicability, as real-world images often feature shallow depth-of-field (DoF). In this paper, we introduce DoF-Gaussian, a controllable depth-of-field method for 3D-GS. We develop a lens-based imaging model based on geometric optics principles to control DoF effects. To ensure accurate scene geometry, we incorporate depth priors adjusted per scene, and we apply defocus-to-focus adaptation to minimize the gap in the circle of confusion. We also introduce a synthetic dataset to assess refocusing capabilities and the model's ability to learn precise lens parameters. Our framework is customizable and supports various interactive applications. Extensive experiments confirm the effectiveness of our method. Our project is available at this https URL.

近年来，3D Gaussian Splatting (3D-GS) 在三维场景表示和实时高质量新视角生成方面取得了显著成功。然而，现有的 3D-GS 及其变体 通常假设输入图像基于针孔成像模型，且完全处于焦点内。这一假设限制了其在真实场景中的应用，因为现实世界的图像往往具有浅景深（Depth-of-Field, DoF）效应。
为了解决这一问题，我们提出 DoF-Gaussian，一种可控景深的 3D-GS 方法。我们基于几何光学原理构建了基于透镜的成像模型，从而能够控制景深效应。为了确保准确的场景几何，我们在每个场景中引入深度先验（depth priors）并进行散焦-聚焦（defocus-to-focus）自适应优化，以最小化弥散圆（circle of confusion）带来的误差。
此外，我们构建了一个合成数据集，用于评估重聚焦能力及模型对镜头参数的学习能力。我们的框架高度可定制，支持多种交互式应用。大量实验结果验证了我们方法的有效性。
