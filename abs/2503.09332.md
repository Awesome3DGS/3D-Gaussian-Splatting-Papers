### SDD-4DGS: Static-Dynamic Aware Decoupling in Gaussian Splatting for 4D Scene Reconstruction

Dynamic and static components in scenes often exhibit distinct properties, yet most 4D reconstruction methods treat them indiscriminately, leading to suboptimal performance in both cases. This work introduces SDD-4DGS, the first framework for static-dynamic decoupled 4D scene reconstruction based on Gaussian Splatting. Our approach is built upon a novel probabilistic dynamic perception coefficient that is naturally integrated into the Gaussian reconstruction pipeline, enabling adaptive separation of static and dynamic components. With carefully designed implementation strategies to realize this theoretical framework, our method effectively facilitates explicit learning of motion patterns for dynamic elements while maintaining geometric stability for static structures. Extensive experiments on five benchmark datasets demonstrate that SDD-4DGS consistently outperforms state-of-the-art methods in reconstruction fidelity, with enhanced detail restoration for static structures and precise modeling of dynamic motions.

在 4D 场景中，动态与静态组件通常表现出不同的特性，然而，大多数 4D 重建方法未加区分地处理它们，导致整体性能受限。为了解决这一问题，我们提出 SDD-4DGS，这是首个基于高斯溅射（Gaussian Splatting）的 静态-动态解耦（Static-Dynamic Decoupled）4D 场景重建 框架。
我们的方法基于一种新颖的 概率动态感知系数（probabilistic dynamic perception coefficient），该系数自然集成到高斯重建管道中，使得静态与动态组件能够自适应分离。通过精心设计的实现策略，我们的框架能够显式学习动态元素的运动模式，同时保持静态结构的几何稳定性。
在五个基准数据集上的大量实验表明，SDD-4DGS 在重建保真度方面始终优于当前最先进（state-of-the-art）方法，不仅增强了静态结构的细节恢复，还实现了动态运动的精准建模。

