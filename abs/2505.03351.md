### GUAVA: Generalizable Upper Body 3D Gaussian Avatar

Reconstructing a high-quality, animatable 3D human avatar with expressive facial and hand motions from a single image has gained significant attention due to its broad application potential. 3D human avatar reconstruction typically requires multi-view or monocular videos and training on individual IDs, which is both complex and time-consuming. Furthermore, limited by SMPLX's expressiveness, these methods often focus on body motion but struggle with facial expressions. To address these challenges, we first introduce an expressive human model (EHM) to enhance facial expression capabilities and develop an accurate tracking method. Based on this template model, we propose GUAVA, the first framework for fast animatable upper-body 3D Gaussian avatar reconstruction. We leverage inverse texture mapping and projection sampling techniques to infer Ubody (upper-body) Gaussians from a single image. The rendered images are refined through a neural refiner. Experimental results demonstrate that GUAVA significantly outperforms previous methods in rendering quality and offers significant speed improvements, with reconstruction times in the sub-second range (0.1s), and supports real-time animation and rendering.

从单张图像中重建具有面部与手部表情的高质量可动画三维人体头像，因其广泛的应用潜力而受到广泛关注。传统的三维人体头像重建方法通常依赖多视角或单目视频，并需针对每个个体进行训练，过程复杂且耗时。此外，受限于 SMPLX 模型的表达能力，此类方法虽能处理躯干运动，但在面部表情建模方面表现不足。
为解决上述问题，我们首先提出了一个增强面部表达能力的 EHM（Expressive Human Model），并在此基础上开发了精确的追踪方法。基于该模板模型，我们进一步提出 GUAVA，首个面向快速可动画上半身三维高斯头像重建的框架。
GUAVA 利用反向纹理映射与投影采样技术，从单张图像中推理出上半身（Ubody）高斯图元，并通过神经细化器对渲染结果进行优化。实验结果表明，GUAVA 在渲染质量上显著优于现有方法，重建速度达到亚秒级（0.1 秒），支持实时动画与渲染。
