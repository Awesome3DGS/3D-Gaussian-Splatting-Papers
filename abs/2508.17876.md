### Camera Pose Refinement via 3D Gaussian Splatting

Camera pose refinement aims at improving the accuracy of initial pose estimation for applications in 3D computer vision. Most refinement approaches rely on 2D-3D correspondences with specific descriptors or dedicated networks, requiring reconstructing the scene again for a different descriptor or fully retraining the network for each scene. Some recent methods instead infer pose from feature similarity, but their lack of geometry constraints results in less accuracy. To overcome these limitations, we propose a novel camera pose refinement framework leveraging 3D Gaussian Splatting (3DGS), referred to as GS-SMC. Given the widespread usage of 3DGS, our method can employ an existing 3DGS model to render novel views, providing a lightweight solution that can be directly applied to diverse scenes without additional training or fine-tuning. Specifically, we introduce an iterative optimization approach, which refines the camera pose using epipolar geometric constraints among the query and multiple rendered images. Our method allows flexibly choosing feature extractors and matchers to establish these constraints. Extensive empirical evaluations on the 7-Scenes and the Cambridge Landmarks datasets demonstrate that our method outperforms state-of-the-art camera pose refinement approaches, achieving 53.3% and 56.9% reductions in median translation and rotation errors on 7-Scenes, and 40.7% and 53.2% on Cambridge.

相机位姿优化旨在提升三维计算机视觉应用中初始位姿估计的准确性。大多数优化方法依赖于结合特定描述符或专用网络的二维-三维对应关系，这通常需要针对不同描述符重新重建场景，或为每个场景完全重新训练网络。近期一些方法则尝试基于特征相似性推断位姿，但由于缺乏几何约束，其精度往往不足。为克服这些局限，我们提出了一种利用三维高斯点绘（3D Gaussian Splatting, 3DGS）的新型相机位姿优化框架，称为 **GS-SMC**。鉴于 3DGS 的广泛应用，我们的方法可以直接利用现有的 3DGS 模型生成新视角图像，从而提供一种无需额外训练或微调、可直接应用于多种场景的轻量化解决方案。具体而言，我们引入了一种迭代优化方法，通过在查询图像与多个渲染图像之间引入极线几何约束来优化相机位姿。该方法允许灵活选择特征提取器和匹配器来建立这些约束。大量在 7-Scenes 和 Cambridge Landmarks 数据集上的实证评估表明，我们的方法在性能上超越了现有最先进的相机位姿优化方法，在 7-Scenes 上分别实现了 53.3% 和 56.9% 的平移与旋转误差中值下降，在 Cambridge 上分别实现了 40.7% 和 53.2% 的下降。
