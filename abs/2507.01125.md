### VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting

We present VISTA (Viewpoint-based Image selection with Semantic Task Awareness), an active exploration method for robots to plan informative trajectories that improve 3D map quality in areas most relevant for task completion. Given an open-vocabulary search instruction (e.g., "find a person"), VISTA enables a robot to explore its environment to search for the object of interest, while simultaneously building a real-time semantic 3D Gaussian Splatting reconstruction of the scene. The robot navigates its environment by planning receding-horizon trajectories that prioritize semantic similarity to the query and exploration of unseen regions of the environment. To evaluate trajectories, VISTA introduces a novel, efficient viewpoint-semantic coverage metric that quantifies both the geometric view diversity and task relevance in the 3D scene. On static datasets, our coverage metric outperforms state-of-the-art baselines, FisherRF and Bayes' Rays, in computation speed and reconstruction quality. In quadrotor hardware experiments, VISTA achieves 6x higher success rates in challenging maps, compared to baseline methods, while matching baseline performance in less challenging maps. Lastly, we show that VISTA is platform-agnostic by deploying it on a quadrotor drone and a Spot quadruped robot. Open-source code will be released upon acceptance of the paper.

我们提出了 VISTA（Viewpoint-based Image selection with Semantic Task Awareness），这是一种主动探索方法，使机器人能够规划信息量丰富的轨迹，以提升与任务完成最相关区域的三维地图质量。在给定开放词汇的搜索指令（例如“寻找一个人”）的情况下，VISTA 使机器人能够在探索环境、寻找目标物体的同时，实时构建场景的语义三维高斯投影（3D Gaussian Splatting）重建。机器人通过规划递推视界轨迹来导航环境，该轨迹优先考虑与查询的语义相似性以及对环境中未探索区域的覆盖。为评估轨迹，VISTA 提出了新颖且高效的视角-语义覆盖指标，用于同时量化三维场景中的几何视角多样性和任务相关性。在静态数据集上，我们的覆盖指标在计算速度和重建质量方面均优于最先进的基线方法 FisherRF 和 Bayes' Rays。在四旋翼硬件实验中，VISTA 在复杂地图中的任务成功率比基线方法高 6 倍，同时在较简单地图中保持与基线相当的性能。最后，我们通过在四旋翼无人机和 Spot 四足机器人上的部署，证明了 VISTA 与平台无关。论文接收后将开源代码。
