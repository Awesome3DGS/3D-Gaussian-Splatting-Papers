### ParticleGS: Particle-Based Dynamics Modeling of 3D Gaussians for Prior-free Motion Extrapolation

This paper aims to model the dynamics of 3D Gaussians from visual observations to support temporal extrapolation. Existing dynamic 3D reconstruction methods often struggle to effectively learn underlying dynamics or rely heavily on manually defined physical priors, which limits their extrapolation capabilities. To address this issue, we propose a novel dynamic 3D Gaussian Splatting prior-free motion extrapolation framework based on particle dynamics systems. The core advantage of our method lies in its ability to learn differential equations that describe the dynamics of 3D Gaussians, and follow them during future frame extrapolation. Instead of simply fitting to the observed visual frame sequence, we aim to more effectively model the gaussian particle dynamics system. To this end, we introduce a dynamics latent state vector into the standard Gaussian kernel and design a dynamics latent space encoder to extract initial state. Subsequently, we introduce a Neural ODEs-based dynamics module that models the temporal evolution of Gaussian in dynamics latent space. Finally, a Gaussian kernel space decoder is used to decode latent state at the specific time step into the deformation. Experimental results demonstrate that the proposed method achieves comparable rendering quality with existing approaches in reconstruction tasks, and significantly outperforms them in future frame extrapolation.

本文旨在从视觉观测中建模三维高斯的动态行为，以支持时间外推任务。现有的动态三维重建方法通常难以有效学习潜在的运动规律，或严重依赖手动定义的物理先验，从而限制了其时间外推能力。
为解决上述问题，我们提出了一种基于粒子动力系统的、无先验的动态三维高斯投影（3D Gaussian Splatting）运动外推框架。该方法的核心优势在于能够学习描述三维高斯动态行为的微分方程，并在未来帧预测中遵循该动力系统进行外推。我们并非仅对观测到的图像序列进行拟合，而是更深入地建模高斯粒子的动态系统。
为此，我们在标准高斯核中引入了一个动态潜状态向量，并设计了一个动态潜空间编码器用于提取初始状态。随后，我们引入了基于神经常微分方程（Neural ODE）的动态模块，用于建模高斯在潜在动力空间中的时间演化过程。最后，通过高斯核空间解码器将任意时间步的潜在状态解码为对应的形变结果。
实验表明，该方法在三维重建任务中能够达到与现有方法相当的渲染质量，并在未来帧的外推任务中显著优于现有方法。
