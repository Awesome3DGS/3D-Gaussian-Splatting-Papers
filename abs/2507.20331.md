### From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos

Inserting 3D objects into videos is a longstanding challenge in computer graphics with applications in augmented reality, virtual try-on, and video composition. Achieving both temporal consistency, or realistic lighting remains difficult, particularly in dynamic scenarios with complex object motion, perspective changes, and varying illumination. While 2D diffusion models have shown promise for producing photorealistic edits, they often struggle with maintaining temporal coherence across frames. Conversely, traditional 3D rendering methods excel in spatial and temporal consistency but fall short in achieving photorealistic lighting. In this work, we propose a hybrid object insertion pipeline that combines the strengths of both paradigms. Specifically, we focus on inserting bracelets into dynamic wrist scenes, leveraging the high temporal consistency of 3D Gaussian Splatting (3DGS) for initial rendering and refining the results using a 2D diffusion-based enhancement model to ensure realistic lighting interactions. Our method introduces a shading-driven pipeline that separates intrinsic object properties (albedo, shading, reflectance) and refines both shading and sRGB images for photorealism. To maintain temporal coherence, we optimize the 3DGS model with multi-frame weighted adjustments. This is the first approach to synergize 3D rendering and 2D diffusion for video object insertion, offering a robust solution for realistic and consistent video editing.

将三维物体插入视频是计算机图形学中由来已久的挑战，在增强现实、虚拟试穿和视频合成等领域具有广泛应用。要同时实现时间一致性和逼真的光照仍然十分困难，尤其是在具有复杂物体运动、视角变化和光照多变的动态场景中。尽管二维扩散模型在生成照片级编辑方面表现出一定潜力，但它们在保持跨帧时间一致性方面常常表现欠佳。相反，传统的三维渲染方法在空间和时间一致性上表现出色，但难以实现照片级真实的光照效果。在本工作中，我们提出了一种融合两种范式优势的混合物体插入流程。具体而言，我们聚焦于在动态手腕场景中插入手镯，利用三维高斯溅射（3DGS）的高时间一致性进行初步渲染，并借助基于二维扩散的增强模型优化结果，以确保光照交互的真实感。我们的方法引入了一个以着色为驱动的流程，将物体的固有属性（反照率、着色、反射率）分离开来，并分别优化着色图和 sRGB 图像，以实现照片级真实感。为了保持时间一致性，我们对 3DGS 模型进行多帧加权优化。这是首个将三维渲染与二维扩散结合用于视频物体插入的方法，为实现逼真且一致的视频编辑提供了稳健的解决方案。
