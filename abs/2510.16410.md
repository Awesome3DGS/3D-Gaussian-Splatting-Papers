### REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting

Bridging the gap between complex human instructions and precise 3D object grounding remains a significant challenge in vision and robotics. Existing 3D segmentation methods often struggle to interpret ambiguous, reasoning-based instructions, while 2D vision-language models that excel at such reasoning lack intrinsic 3D spatial understanding. In this paper, we introduce REALM, an innovative MLLM-agent framework that enables open-world reasoning-based segmentation without requiring extensive 3D-specific post-training. We perform segmentation directly on 3D Gaussian Splatting representations, capitalizing on their ability to render photorealistic novel views that are highly suitable for MLLM comprehension. As directly feeding one or more rendered views to the MLLM can lead to high sensitivity to viewpoint selection, we propose a novel Global-to-Local Spatial Grounding strategy. Specifically, multiple global views are first fed into the MLLM agent in parallel for coarse-level localization, aggregating responses to robustly identify the target object. Then, several close-up novel views of the object are synthesized to perform fine-grained local segmentation, yielding accurate and consistent 3D masks. Extensive experiments show that REALM achieves remarkable performance in interpreting both explicit and implicit instructions across LERF, 3D-OVS, and our newly introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly supports a range of 3D interaction tasks, including object removal, replacement, and style transfer, demonstrating its practical utility and versatility.

在视觉与机器人领域，将复杂的人类指令与精准的三维物体定位相结合，仍是一项重大挑战。现有的三维分割方法往往难以理解含糊或基于推理的指令，而那些擅长语言推理的二维视觉语言模型则缺乏对三维空间的本体理解。本文提出了 REALM —— 一种创新的 MLLM-agent 框架，能够在无需大规模三维专属后训练的前提下，实现开放世界的推理驱动分割。我们直接在三维高斯散射（3D Gaussian Splatting）表示上执行分割任务，充分利用其可渲染高保真新视角的特性，使其非常适合被多模态大模型（MLLM）理解。由于直接将一幅或多幅渲染图输入 MLLM 会对视角选择高度敏感，我们提出了一种新颖的“全局到局部空间定位”策略。具体而言，首先并行地将多个全局视角输入 MLLM agent 进行粗粒度定位，通过聚合响应结果稳健地识别目标物体；随后再合成多个该物体的近距离新视角，用于精细的局部分割，从而获得准确一致的三维掩码。大量实验证明，REALM 在 LERF、3D-OVS 以及我们新提出的 REALM3D 基准上，对于显式与隐式指令的理解均表现出色。此外，该 agent 框架还可无缝支持一系列三维交互任务，如物体移除、替换与风格迁移，展现出良好的实用性与多样性。
