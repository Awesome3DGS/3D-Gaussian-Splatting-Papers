### GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians

Recently, with the development of Neural Radiance Fields and Gaussian Splatting, 3D reconstruction techniques have achieved remarkably high fidelity. However, the latent representations learnt by these methods are highly entangled and lack interpretability. In this paper, we propose a novel part-aware compositional reconstruction method, called GaussianBlock, that enables semantically coherent and disentangled representations, allowing for precise and physical editing akin to building blocks, while simultaneously maintaining high fidelity. Our GaussianBlock introduces a hybrid representation that leverages the advantages of both primitives, known for their flexible actionability and editability, and 3D Gaussians, which excel in reconstruction quality. Specifically, we achieve semantically coherent primitives through a novel attention-guided centering loss derived from 2D semantic priors, complemented by a dynamic splitting and fusion strategy. Furthermore, we utilize 3D Gaussians that hybridize with primitives to refine structural details and enhance fidelity. Additionally, a binding inheritance strategy is employed to strengthen and maintain the connection between the two. Our reconstructed scenes are evidenced to be disentangled, compositional, and compact across diverse benchmarks, enabling seamless, direct and precise editing while maintaining high quality.

随着神经辐射场（Neural Radiance Fields）和高斯散射（Gaussian Splatting）技术的发展，3D重建技术已实现了显著的高保真度。然而，这些方法学习到的潜在表示高度纠缠，缺乏可解释性。在本文中，我们提出了一种新颖的部件感知组合重建方法，称为GaussianBlock，它能够实现语义一致且解耦的表示，允许进行精确且物理的编辑，类似于构建积木，同时保持高保真度。GaussianBlock引入了一种混合表示，结合了基元（primitives）和3D高斯的优点，前者以其灵活的可操作性和可编辑性著称，而后者在重建质量上表现出色。具体而言，我们通过一种基于2D语义先验的注意力引导居中损失（attention-guided centering loss）实现了语义一致的基元，并辅以动态分裂与融合策略。此外，我们利用与基元混合的3D高斯细化结构细节，提升保真度。为加强和保持两者之间的联系，我们还采用了绑定继承策略。实验结果表明，我们重建的场景在多样基准测试中实现了解耦、组合性和紧凑性，能够在保持高质量的同时，实现无缝、直接且精确的编辑。
