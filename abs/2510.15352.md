### GaussGym: An open-source real-to-sim framework for learning locomotion from pixels

We present a novel approach for photorealistic robot simulation that integrates 3D Gaussian Splatting as a drop-in renderer within vectorized physics simulators such as IsaacGym. This enables unprecedented speed -- exceeding 100,000 steps per second on consumer GPUs -- while maintaining high visual fidelity, which we showcase across diverse tasks. We additionally demonstrate its applicability in a sim-to-real robotics setting. Beyond depth-based sensing, our results highlight how rich visual semantics improve navigation and decision-making, such as avoiding undesirable regions. We further showcase the ease of incorporating thousands of environments from iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs from generative video models like Veo, enabling rapid creation of realistic training worlds. This work bridges high-throughput simulation and high-fidelity perception, advancing scalable and generalizable robot learning. All code and data will be open-sourced for the community to build upon.

我们提出了一种用于真实感机器人仿真的新方法，将三维高斯溅射（3D Gaussian Splatting）作为即插即用的渲染器集成进如IsaacGym等向量化物理模拟器中。该方法在保持高视觉保真度的同时，实现了前所未有的模拟速度——在消费级GPU上每秒可超过100,000步，并在多项任务中展示了出色效果。我们还展示了该方法在“模拟到现实”（sim-to-real）机器人任务中的适用性。除了基于深度的感知外，我们的实验结果还表明，丰富的视觉语义信息有助于提升导航与决策能力，例如避开不安全区域。此外，我们展示了如何轻松地将数千个环境集成进系统，包括iPhone扫描数据、大规模场景数据集（如GrandTour、ARKit）以及生成式视频模型（如Veo）的输出，从而可快速构建逼真的训练世界。该工作打通了高吞吐量仿真与高保真感知之间的桥梁，推动了可扩展、可泛化的机器人学习发展。我们将开放所有代码和数据，供社区共享与扩展。
