### GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics

Autonomous drones capable of interpreting and executing high-level language instructions in unstructured environments remain a long-standing goal. Yet existing approaches are constrained by their dependence on hand-crafted skills, extensive parameter tuning, or computationally intensive models unsuitable for onboard use. We introduce GRaD-Nav++, a lightweight Vision-Language-Action (VLA) framework that runs fully onboard and follows natural-language commands in real time. Our policy is trained in a photorealistic 3D Gaussian Splatting (3DGS) simulator via Differentiable Reinforcement Learning (DiffRL), enabling efficient learning of low-level control from visual and linguistic inputs. At its core is a Mixture-of-Experts (MoE) action head, which adaptively routes computation to improve generalization while mitigating forgetting. In multi-task generalization experiments, GRaD-Nav++ achieves a success rate of 83% on trained tasks and 75% on unseen tasks in simulation. When deployed on real hardware, it attains 67% success on trained tasks and 50% on unseen ones. In multi-environment adaptation experiments, GRaD-Nav++ achieves an average success rate of 81% across diverse simulated environments and 67% across varied real-world settings. These results establish a new benchmark for fully onboard Vision-Language-Action (VLA) flight and demonstrate that compact, efficient models can enable reliable, language-guided navigation without relying on external infrastructure.

在非结构化环境中能够理解并执行高层次语言指令的自主无人机，一直是长期以来的重要目标。然而，现有方法受限于对人工设计技能的依赖、大量参数调优，或依赖计算量过大的模型，难以在机载环境中运行。我们提出了 **GRaD-Nav++**，一种轻量级视觉-语言-动作（Vision-Language-Action, VLA）框架，可在机载环境中实时运行并执行自然语言指令。我们的策略在高逼真度的三维高斯溅射（3DGS）模拟器中，通过可微分强化学习（Differentiable Reinforcement Learning, DiffRL）训练，从视觉与语言输入中高效学习低层次控制策略。其核心为**专家混合（Mixture-of-Experts, MoE）动作头**，能够自适应地分配计算以提升泛化能力并缓解遗忘问题。在多任务泛化实验中，**GRaD-Nav++** 在模拟环境中训练任务成功率达到 83%，未见任务成功率为 75%；部署到真实硬件时，训练任务成功率为 67%，未见任务成功率为 50%。在多环境适应实验中，**GRaD-Nav++** 在多样化模拟环境中平均成功率为 81%，在多种真实环境中平均成功率为 67%。这些结果为完全机载的视觉-语言-动作飞行设立了新的基准，并证明紧凑高效的模型能够在不依赖外部基础设施的情况下，实现可靠的语言引导导航。
