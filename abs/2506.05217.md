### DSG-World: Learning a 3D Gaussian World Model from Dual State Videos

Building an efficient and physically consistent world model from limited observations is a long standing challenge in vision and robotics. Many existing world modeling pipelines are based on implicit generative models, which are hard to train and often lack 3D or physical consistency. On the other hand, explicit 3D methods built from a single state often require multi-stage processing-such as segmentation, background completion, and inpainting-due to occlusions. To address this, we leverage two perturbed observations of the same scene under different object configurations. These dual states offer complementary visibility, alleviating occlusion issues during state transitions and enabling more stable and complete reconstruction. In this paper, we present DSG-World, a novel end-to-end framework that explicitly constructs a 3D Gaussian World model from Dual State observations. Our approach builds dual segmentation-aware Gaussian fields and enforces bidirectional photometric and semantic consistency. We further introduce a pseudo intermediate state for symmetric alignment and design collaborative co-pruning trategies to refine geometric completeness. DSG-World enables efficient real-to-simulation transfer purely in the explicit Gaussian representation space, supporting high-fidelity rendering and object-level scene manipulation without relying on dense observations or multi-stage pipelines. Extensive experiments demonstrate strong generalization to novel views and scene states, highlighting the effectiveness of our approach for real-world 3D reconstruction and simulation.

从有限观测中构建高效且物理一致的世界模型，一直是计算机视觉与机器人领域的核心挑战之一。许多现有的世界建模流程依赖于隐式生成模型，这类方法不仅训练困难，还常常缺乏三维或物理一致性。而基于单一状态的显式三维方法则通常需要多阶段处理流程，如分割、背景补全与遮挡区域的图像修复等，以应对遮挡问题。
为了解决这一问题，本文提出利用同一场景在不同物体配置下的两次扰动观测，即“双状态”（Dual State）输入。这两个状态提供了互补的可见性，缓解了状态转换过程中的遮挡问题，从而实现更加稳定和完整的三维重建。
我们提出了 DSG-World，一个端到端的新型框架，可从双状态观测中显式构建三维高斯世界模型（3D Gaussian World）。该方法构建了双分割感知的高斯场，并强制施加双向的光度一致性与语义一致性约束。此外，我们引入了一个伪中间状态用于实现对称对齐，并设计了协同共剪枝策略（collaborative co-pruning strategies）以进一步提升几何完整性。
DSG-World 完全在显式高斯表示空间中完成高保真渲染与对象级场景操作，能够高效支持从真实到仿真的迁移，无需依赖密集观测或多阶段建模流程。大量实验表明，该方法在新视角与新场景状态下具有良好的泛化能力，验证了其在真实世界三维重建与模拟中的有效性。
