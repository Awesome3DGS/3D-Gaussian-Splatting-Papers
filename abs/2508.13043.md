### IntelliCap: Intelligent Guidance for Consistent View Sampling

Novel view synthesis from images, for example, with 3D Gaussian splatting, has made great progress. Rendering fidelity and speed are now ready even for demanding virtual reality applications. However, the problem of assisting humans in collecting the input images for these rendering algorithms has received much less attention. High-quality view synthesis requires uniform and dense view sampling. Unfortunately, these requirements are not easily addressed by human camera operators, who are in a hurry, impatient, or lack understanding of the scene structure and the photographic process. Existing approaches to guide humans during image acquisition concentrate on single objects or neglect view-dependent material characteristics. We propose a novel situated visualization technique for scanning at multiple scales. During the scanning of a scene, our method identifies important objects that need extended image coverage to properly represent view-dependent appearance. To this end, we leverage semantic segmentation and category identification, ranked by a vision-language model. Spherical proxies are generated around highly ranked objects to guide the user during scanning. Our results show superior performance in real scenes compared to conventional view sampling strategies.

基于图像的新视角合成（例如使用三维高斯泼溅）已取得显著进展。其渲染保真度和速度甚至已能满足高要求的虚拟现实应用。然而，如何辅助人类采集用于这些渲染算法的输入图像这一问题却鲜有关注。高质量的新视角合成需要均匀且密集的视角采样。不幸的是，这些要求对匆忙、缺乏耐心或不了解场景结构和拍摄过程的人类摄影者来说难以满足。现有的人类采集引导方法多集中于单个物体，或忽略了与视角相关的材质特性。我们提出了一种新颖的多尺度扫描情境可视化技术。在场景扫描过程中，我们的方法能识别需要扩展图像覆盖的重要物体，以正确表达视角相关的外观特性。为此，我们利用语义分割和类别识别，并通过视觉-语言模型进行排序。在排序靠前的物体周围生成球形代理，以引导用户完成扫描。实验结果表明，与传统视角采样策略相比，我们的方法在真实场景中表现更为优越。
