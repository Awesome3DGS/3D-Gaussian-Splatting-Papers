### GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting

3D scene reconstruction and understanding have gained increasing popularity, yet existing methods still struggle to capture fine-grained, language-aware 3D representations from 2D images. In this paper, we present GALA, a novel framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). GALA distills a scene-specific 3D instance feature field via self-supervised contrastive learning. To extend to generalized language feature fields, we introduce the core contribution of GALA, a cross-attention module with two learnable codebooks that encode view-independent semantic embeddings. This design not only ensures intra-instance feature similarity but also supports seamless 2D and 3D open-vocabulary queries. It reduces memory consumption by avoiding per-Gaussian high-dimensional feature learning. Extensive experiments on real-world datasets demonstrate GALA's remarkable open-vocabulary performance on both 2D and 3D.

三维场景重建与理解日益受到关注，但现有方法仍难以从二维图像中捕获细粒度、具备语言感知能力的三维表征。本文提出 GALA，一种基于三维高斯喷溅（3DGS）的开放词汇三维场景理解新框架。GALA 通过自监督对比学习蒸馏出场景特定的三维实例特征场。为了扩展到通用语言特征场，我们提出了 GALA 的核心贡献——一个带有两个可学习码本的交叉注意力模块，用于编码视角无关的语义嵌入。该设计不仅保证了实例内特征的相似性，还支持无缝的二维与三维开放词汇查询。同时，通过避免针对每个高斯学习高维特征，有效降低了内存消耗。在真实数据集上的大量实验表明，GALA 在二维和三维上的开放词汇性能表现出色。
