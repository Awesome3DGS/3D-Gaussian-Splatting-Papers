### I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation

Vast and high-quality data are essential for end-to-end autonomous driving systems. However, current driving data is mainly collected by vehicles, which is expensive and inefficient. A potential solution lies in synthesizing data from real-world images. Recent advancements in 3D reconstruction demonstrate photorealistic novel view synthesis, highlighting the potential of generating driving data from images captured on the road. This paper introduces a novel method, I2V-GS, to transfer the Infrastructure view To the Vehicle view with Gaussian Splatting. Reconstruction from sparse infrastructure viewpoints and rendering under large view transformations is a challenging problem. We adopt the adaptive depth warp to generate dense training views. To further expand the range of views, we employ a cascade strategy to inpaint warped images, which also ensures inpainting content is consistent across views. To further ensure the reliability of the diffusion model, we utilize the cross-view information to perform a confidenceguided optimization. Moreover, we introduce RoadSight, a multi-modality, multi-view dataset from real scenarios in infrastructure views. To our knowledge, I2V-GS is the first framework to generate autonomous driving datasets with infrastructure-vehicle view transformation. Experimental results demonstrate that I2V-GS significantly improves synthesis quality under vehicle view, outperforming StreetGaussian in NTA-Iou, NTL-Iou, and FID by 45.7%, 34.2%, and 14.9%, respectively.

大规模且高质量的数据对端到端自动驾驶系统至关重要。然而，目前的驾驶数据主要由车辆采集，这种方式既昂贵又低效。一种潜在的解决方案是从真实世界的图像中合成数据。近年来，3D 重建在逼真新视角合成方面取得了进展，这突显了利用道路上拍摄的图像生成驾驶数据的潜力。本文提出了一种新方法——I2V-GS，通过高斯泼溅实现基础设施视角（Infrastructure view）到车辆视角（Vehicle view）的转换。从稀疏的基础设施视点进行重建并在大视角变化下进行渲染是一个具有挑战性的问题。我们采用自适应深度变形（adaptive depth warp）生成密集的训练视图。为了进一步扩展视角范围，我们引入级联策略对变形后的图像进行修补，同时确保修补内容在不同视图间保持一致。为了进一步保证扩散模型的可靠性，我们利用跨视图信息执行置信度引导优化。此外，我们还引入了 RoadSight 数据集，该数据集包含来自真实场景的多模态、多视角基础设施视图。据我们所知，I2V-GS 是首个实现基础设施到车辆视角转换以生成自动驾驶数据集的框架。实验结果表明，I2V-GS 在车辆视角下的合成质量显著提升，相比 StreetGaussian 在 NTA-Iou、NTL-Iou 和 FID 上分别提高了 45.7%、34.2% 和 14.9%。
