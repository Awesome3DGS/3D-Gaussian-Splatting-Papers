### SparseGS-W: Sparse-View 3D Gaussian Splatting in the Wild with Generative Priors

Synthesizing novel views of large-scale scenes from unconstrained in-the-wild images is an important but challenging task in computer vision. Existing methods, which optimize per-image appearance and transient occlusion through implicit neural networks from dense training views (approximately 1000 images), struggle to perform effectively under sparse input conditions, resulting in noticeable artifacts. To this end, we propose SparseGS-W, a novel framework based on 3D Gaussian Splatting that enables the reconstruction of complex outdoor scenes and handles occlusions and appearance changes with as few as five training images. We leverage geometric priors and constrained diffusion priors to compensate for the lack of multi-view information from extremely sparse input. Specifically, we propose a plug-and-play Constrained Novel-View Enhancement module to iteratively improve the quality of rendered novel views during the Gaussian optimization process. Furthermore, we propose an Occlusion Handling module, which flexibly removes occlusions utilizing the inherent high-quality inpainting capability of constrained diffusion priors. Both modules are capable of extracting appearance features from any user-provided reference image, enabling flexible modeling of illumination-consistent scenes. Extensive experiments on the PhotoTourism and Tanks and Temples datasets demonstrate that SparseGS-W achieves state-of-the-art performance not only in full-reference metrics, but also in commonly used non-reference metrics such as FID, ClipIQA, and MUSIQ.

从非约束、真实环境中的图像合成大规模场景的新视角，是计算机视觉领域一项重要但具有挑战性的任务。现有方法通常依赖于隐式神经网络，在大约 1000 张密集训练图像上，通过逐图优化外观和瞬时遮挡，但在稀疏输入条件下表现不佳，容易产生明显伪影。
为此，我们提出了 SparseGS-W，一个基于三维高斯溅射（3D Gaussian Splatting）的新型框架，能够在仅使用五张训练图像的情况下重建复杂的户外场景，并处理遮挡与外观变化问题。我们引入几何先验和受限扩散先验（constrained diffusion priors），以弥补极端稀疏输入下缺乏多视角信息的问题。
具体而言，我们提出了一个即插即用的受限新视角增强模块（Constrained Novel-View Enhancement），在高斯优化过程中迭代提升新视角渲染质量。此外，我们还设计了一个遮挡处理模块（Occlusion Handling），利用受限扩散先验中固有的高质量图像修复能力，灵活地去除遮挡。
这两个模块均可从任意用户提供的参考图像中提取外观特征，使得系统能够灵活建模具有一致光照条件的场景。
在 PhotoTourism 和 Tanks and Temples 数据集上的大量实验表明，SparseGS-W 不仅在完整参考指标上取得了当前最佳性能，还在 FID、ClipIQA 和 MUSIQ 等常用无参考指标上表现出色。
