### VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians

Visualization of large-scale time-dependent simulation data is crucial for domain scientists to analyze complex phenomena, but it demands significant I/O bandwidth, storage, and computational resources. To enable effective visualization on local, low-end machines, recent advances in view synthesis techniques, such as neural radiance fields, utilize neural networks to generate novel visualizations for volumetric scenes. However, these methods focus on reconstruction quality rather than facilitating interactive visualization exploration, such as feature extraction and tracking. We introduce VolSegGS, a novel Gaussian splatting framework that supports interactive segmentation and tracking in dynamic volumetric scenes for exploratory visualization and analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic volumetric scene, allowing for real-time novel view synthesis. For accurate segmentation, we leverage the view-independent colors of Gaussians for coarse-level segmentation and refine the results with an affinity field network for fine-level segmentation. Additionally, by embedding segmentation results within the Gaussians, we ensure that their deformation enables continuous tracking of segmented regions over time. We demonstrate the effectiveness of VolSegGS with several time-varying datasets and compare our solutions against state-of-the-art methods. With the ability to interact with a dynamic scene in real time and provide flexible segmentation and tracking capabilities, VolSegGS offers a powerful solution under low computational demands. This framework unlocks exciting new possibilities for time-varying volumetric data analysis and visualization.

大规模时变仿真数据的可视化对于领域科学家分析复杂现象至关重要，但这类任务通常需要大量的 I/O 带宽、存储和计算资源。为了在本地低端设备上实现高效可视化，近期的视图合成技术（如神经辐射场）利用神经网络为体数据场景生成新视角可视化。然而，这些方法主要关注重建质量，而非支持交互式可视化探索（如特征提取与跟踪）。为此，我们提出了 VolSegGS，这是一种新型高斯投影（Gaussian Splatting）框架，可在动态体数据场景中实现交互式分割与跟踪，用于探索性可视化与分析。我们的方法采用可变形三维高斯表示动态体数据场景，从而支持实时新视角合成。为了实现精确分割，我们利用高斯的视角无关颜色进行粗粒度分割，并通过亲和场网络（affinity field network）进行精细化分割。此外，通过将分割结果嵌入到高斯中，我们确保其在随时间变形的过程中能够持续跟踪分割区域。我们在多个时变数据集上验证了 VolSegGS 的有效性，并与当前最先进的方法进行了对比。凭借实时交互动态场景以及灵活的分割和跟踪能力，VolSegGS 在低计算需求下提供了强大的解决方案，为时变体数据的分析与可视化开启了新的可能性。
