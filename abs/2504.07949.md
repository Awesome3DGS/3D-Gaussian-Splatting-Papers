### InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars with Deformable Gaussians

With the rising interest from the community in digital avatars coupled with the importance of expressions and gestures in communication, modeling natural avatar behavior remains an important challenge across many industries such as teleconferencing, gaming, and AR/VR. Human hands are the primary tool for interacting with the environment and essential for realistic human behavior modeling, yet existing 3D hand and head avatar models often overlook the crucial aspect of hand-body interactions, such as between hand and face. We present InteracttAvatar, the first model to faithfully capture the photorealistic appearance of dynamic hand and non-rigid hand-face interactions. Our novel Dynamic Gaussian Hand model, combining template model and 3D Gaussian Splatting as well as a dynamic refinement module, captures pose-dependent change, e.g. the fine wrinkles and complex shadows that occur during articulation. Importantly, our hand-face interaction module models the subtle geometry and appearance dynamics that underlie common gestures. Through experiments of novel view synthesis, self reenactment and cross-identity reenactment, we demonstrate that InteracttAvatar can reconstruct hand and hand-face interactions from monocular or multiview videos with high-fidelity details and be animated with novel poses.

随着社区对数字化虚拟人（digital avatars）兴趣的日益增长，以及表情与手势在交流中的重要性，建模自然的虚拟人行为已成为远程会议、游戏、增强/虚拟现实（AR/VR）等多个行业亟待解决的关键挑战。其中，人手是人类与环境交互的主要工具，也是实现真实行为建模的核心，但现有的三维手部与头部虚拟人模型往往忽视了手与身体之间的关键交互，例如手与脸之间的接触行为。
我们提出了 InteracttAvatar，这是首个能够真实捕捉动态手部以及非刚性手-脸交互的照片级外观的模型。我们设计的全新动态高斯手部模型（Dynamic Gaussian Hand model）结合了模板模型、3D Gaussian Splatting与动态细化模块，能够捕捉姿态相关的变化，例如关节运动中产生的细小皱褶与复杂阴影。
尤为重要的是，我们提出的手-脸交互模块能够建模在常见手势中出现的精细几何结构与外观动态变化。
通过新视角合成、自我重演以及跨身份重演等实验，我们展示了 InteracttAvatar 能够从单目或多视角视频中高保真地重建手部及手-脸交互，并支持新姿态驱动的动画生成。

