### 3D Gaussian Inpainting with Depth-Guided Cross-View Consistency

When performing 3D inpainting using novel-view rendering methods like Neural Radiance Field (NeRF) or 3D Gaussian Splatting (3DGS), how to achieve texture and geometry consistency across camera views has been a challenge. In this paper, we propose a framework of 3D Gaussian Inpainting with Depth-Guided Cross-View Consistency (3DGIC) for cross-view consistent 3D inpainting. Guided by the rendered depth information from each training view, our 3DGIC exploits background pixels visible across different views for updating the inpainting mask, allowing us to refine the 3DGS for inpainting purposes. Through extensive experiments on benchmark datasets, we confirm that our 3DGIC outperforms current state-of-the-art 3D inpainting methods quantitatively and qualitatively.

在使用新型视图渲染方法进行3D修复（如神经辐射场（NeRF）或3D高斯点云（3DGS））时，如何在不同相机视角之间实现纹理和几何一致性一直是一个挑战。本文提出了一种具有深度引导跨视角一致性的3D高斯修复框架（3DGIC）用于跨视角一致性的3D修复。在每个训练视角渲染的深度信息的引导下，我们的3DGIC利用不同视角中可见的背景像素来更新修复掩码，从而使得3DGS能够更好地进行修复。通过在基准数据集上进行大量实验，我们验证了3DGIC在定量和定性上都超越了现有的最先进的3D修复方法。
