### SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction

Recent advances in optimizing Gaussian Splatting for scene geometry have enabled efficient reconstruction of detailed surfaces from images. However, when input views are sparse, such optimization is prone to overfitting, leading to suboptimal reconstruction quality. Existing approaches address this challenge by employing flattened Gaussian primitives to better fit surface geometry, combined with depth regularization to alleviate geometric ambiguities under limited viewpoints. Nevertheless, the increased anisotropy inherent in flattened Gaussians exacerbates overfitting in sparse-view scenarios, hindering accurate surface fitting and degrading novel view synthesis performance. In this paper, we propose \net{}, a method that reconstructs more accurate and detailed surfaces while preserving high-quality novel view rendering. Our key insight is to introduce Stereo Geometry-Texture Alignment, which bridges rendering quality and geometry estimation, thereby jointly enhancing both surface reconstruction and view synthesis. In addition, we present a Pseudo-Feature Enhanced Geometry Consistency that enforces multi-view geometric consistency by incorporating both training and unseen views, effectively mitigating overfitting caused by sparse supervision. Extensive experiments on the DTU, BlendedMVS, and Mip-NeRF360 datasets demonstrate that our method achieves the state-of-the-art performance.

近期在高斯投影（Gaussian Splatting）优化场景几何方面的研究取得了显著进展，使得从图像中高效重建精细表面成为可能。然而，当输入视角较稀疏时，此类优化易产生过拟合，导致重建质量下降。现有方法通常采用扁平化高斯图元以更好地贴合表面几何，同时引入深度正则项缓解视角受限下的几何歧义。但由于扁平高斯本身存在更高的各向异性，这种策略在稀疏视角下反而会加剧过拟合，影响表面拟合准确性并降低新视角合成质量。为解决这一问题，本文提出方法 \net{}，在保持高质量新视图渲染的同时，实现更准确、细节更丰富的表面重建。我们的核心思想是引入“立体几何-纹理对齐”（Stereo Geometry-Texture Alignment）机制，建立渲染质量与几何估计之间的桥梁，实现两者的协同优化。此外，我们还提出“伪特征增强的几何一致性”策略（Pseudo-Feature Enhanced Geometry Consistency），通过结合训练视图与未见视图，引导多视图几何一致性，有效缓解稀疏监督导致的过拟合问题。我们在 DTU、BlendedMVS 以及 Mip-NeRF360 数据集上的大量实验表明，该方法在表面重建与新视图合成任务中均达到了当前最优性能。
