### Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging

3D Gaussian Splats (3DGSs) are 3D object models derived from multi-view images. Such "digital twins" are useful for simulations, virtual reality, marketing, robot policy fine-tuning, and part inspection. 3D object scanning usually requires multi-camera arrays, precise laser scanners, or robot wrist-mounted cameras, which have restricted workspaces. We propose Omni-Scan, a pipeline for producing high-quality 3D Gaussian Splat models using a bi-manual robot that grasps an object with one gripper and rotates the object with respect to a stationary camera. The object is then re-grasped by a second gripper to expose surfaces that were occluded by the first gripper. We present the Omni-Scan robot pipeline using DepthAny-thing, Segment Anything, as well as RAFT optical flow models to identify and isolate objects held by a robot gripper while removing the gripper and the background. We then modify the 3DGS training pipeline to support concatenated datasets with gripper occlusion, producing an omni-directional (360 degree view) model of the object. We apply Omni-Scan to part defect inspection, finding that it can identify visual or geometric defects in 12 different industrial and household objects with an average accuracy of 83%.

三维高斯泼溅（3DGS）是一种由多视图图像生成的三维物体模型。这类“数字孪生”可广泛应用于仿真、虚拟现实、营销、机器人策略微调以及零件检测等领域。传统的三维物体扫描通常需要多相机阵列、精密激光扫描仪或安装在机器人手腕上的相机，但这些方法受限于工作空间。我们提出了 Omni-Scan，这是一种利用双臂机器人生成高质量 3D 高斯泼溅模型的流程。该流程中，一只机械手夹持物体并相对于固定相机旋转物体，然后由另一只机械手重新夹持物体，以暴露被第一只机械手遮挡的表面。我们在 Omni-Scan 机器人流程中结合了 DepthAnything、Segment Anything 以及 RAFT 光流模型，用于识别并分离由机器人夹持的物体，同时去除机械手和背景。随后，我们对 3DGS 训练流程进行修改，以支持包含机械手遮挡的拼接数据集，从而生成物体的全方位（360 度）模型。我们将 Omni-Scan 应用于零件缺陷检测，结果表明它能够以 83% 的平均准确率识别出 12 种不同工业和家用物体的视觉或几何缺陷。
