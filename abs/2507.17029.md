### StreamME: Simplify 3D Gaussian Avatar within Live Stream

We propose StreamME, a method focuses on fast 3D avatar reconstruction. The StreamME synchronously records and reconstructs a head avatar from live video streams without any pre-cached data, enabling seamless integration of the reconstructed appearance into downstream applications. This exceptionally fast training strategy, which we refer to as on-the-fly training, is central to our approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating the reliance on MLPs in deformable 3DGS and relying solely on geometry, which significantly improves the adaptation speed to facial expression. To further ensure high efficiency in on-the-fly training, we introduced a simplification strategy based on primary points, which distributes the point clouds more sparsely across the facial surface, optimizing points number while maintaining rendering quality. Leveraging the on-the-fly training capabilities, our method protects the facial privacy and reduces communication bandwidth in VR system or online conference. Additionally, it can be directly applied to downstream application such as animation, toonify, and relighting.

我们提出了 StreamME，这是一种专注于快速三维虚拟形象重建的方法。StreamME 可在无任何预缓存数据的情况下，从实时视频流中同步录制并重建头部虚拟形象，使重建后的外观能够无缝集成到下游应用中。这种极快的训练策略（我们称之为“即时训练”）是我们方法的核心。我们的方法基于三维高斯点渲染（3D Gaussian Splatting, 3DGS），去除了可变形 3DGS 中对 MLP 的依赖，仅依靠几何信息，大幅提升了对面部表情的适应速度。为进一步保证即时训练的高效性，我们引入了一种基于主点的简化策略，使点云在面部表面分布得更加稀疏，在优化点数的同时保持渲染质量。借助即时训练能力，我们的方法能够在 VR 系统或在线会议中保护面部隐私并减少通信带宽。此外，它还可直接应用于动画、卡通化（toonify）和重光照等下游任务。
