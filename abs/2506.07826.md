### R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation

Validating autonomous driving (AD) systems requires diverse and safety-critical testing, making photorealistic virtual environments essential. Traditional simulation platforms, while controllable, are resource-intensive to scale and often suffer from a domain gap with real-world data. In contrast, neural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a scalable solution for creating photorealistic digital twins of real-world driving scenes. However, they struggle with dynamic object manipulation and reusability as their per-scene optimization-based methodology tends to result in incomplete object models with integrated illumination effects. This paper introduces R3D2, a lightweight, one-step diffusion model designed to overcome these limitations and enable realistic insertion of complete 3D assets into existing scenes by generating plausible rendering effects-such as shadows and consistent lighting-in real time. This is achieved by training R3D2 on a novel dataset: 3DGS object assets are generated from in-the-wild AD data using an image-conditioned 3D generative model, and then synthetically placed into neural rendering-based virtual environments, allowing R3D2 to learn realistic integration. Quantitative and qualitative evaluations demonstrate that R3D2 significantly enhances the realism of inserted assets, enabling use-cases like text-to-3D asset insertion and cross-scene/dataset object transfer, allowing for true scalability in AD validation.

验证自动驾驶（Autonomous Driving，AD）系统需要覆盖多样化且安全关键的测试情境，因此逼真的虚拟环境变得尤为重要。传统仿真平台虽具可控性，但在扩展上资源消耗大，且与真实世界数据之间存在显著的领域差异。而诸如三维高斯泼洒（3D Gaussian Splatting，3DGS）等神经重建方法，则为构建真实驾驶场景的数字孪生体提供了一种可扩展的解决方案。然而，由于其基于每个场景独立优化的方式，这类方法在动态对象操作与复用方面存在困难，往往导致生成的对象模型不完整，并融合了场景固有的光照信息，难以灵活插入新对象。
为突破这一局限，本文提出 R3D2：一种轻量化的一步扩散模型，旨在实现完整三维资产在已有场景中的真实感插入，并实时生成合理的渲染效果（如阴影与一致光照）。该方法通过在一个全新构建的数据集上进行训练实现上述目标：我们首先利用图像条件的三维生成模型，从真实自动驾驶数据中生成 3DGS 对象资产；再将这些资产合成地插入基于神经渲染的虚拟环境中，从而使 R3D2 学习对象与场景的真实融合模式。
定量与定性评估均表明，R3D2 显著提升了插入资产的真实感，支持如文本生成三维资产插入（text-to-3D asset insertion）、跨场景/数据集的对象迁移等应用场景，真正实现了自动驾驶验证任务中的可扩展性。
