### Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping

3D Gaussian Splatting (3DGS) has emerged as a core technique for 3D representation. Its effectiveness largely depends on precise camera poses and accurate point cloud initialization, which are often derived from pretrained Multi-View Stereo (MVS) models. However, in unposed reconstruction task from hundreds of outdoor images, existing MVS models may struggle with memory limits and lose accuracy as the number of input images grows. To address this limitation, we propose a novel unposed 3DGS reconstruction framework that integrates pretrained MVS priors with the probabilistic Procrustes mapping strategy. The method partitions input images into subsets, maps submaps into a global space, and jointly optimizes geometry and poses with 3DGS. Technically, we formulate the mapping of tens of millions of point clouds as a probabilistic Procrustes problem and solve a closed-form alignment. By employing probabilistic coupling along with a soft dustbin mechanism to reject uncertain correspondences, our method globally aligns point clouds and poses within minutes across hundreds of images. Moreover, we propose a joint optimization framework for 3DGS and camera poses. It constructs Gaussians from confidence-aware anchor points and integrates 3DGS differentiable rendering with an analytical Jacobian to jointly refine scene and poses, enabling accurate reconstruction and pose estimation. Experiments on Waymo and KITTI datasets show that our method achieves accurate reconstruction from unposed image sequences, setting a new state of the art for unposed 3DGS reconstruction.

三维高斯点渲染（3D Gaussian Splatting, 3DGS）已成为三维表示的核心技术之一，其效果在很大程度上依赖于精确的相机位姿和准确的点云初始化，而这些通常来自预训练的多视图立体（Multi-View Stereo, MVS）模型。然而，在由数百张户外图像进行的无位姿重建任务中，现有 MVS 模型可能会受到内存限制，并且随着输入图像数量的增加而失去精度。为解决这一问题，我们提出了一种结合预训练 MVS 先验与概率 Procrustes 映射策略的新型无位姿 3DGS 重建框架。该方法将输入图像划分为子集，将子图映射到全局空间，并利用 3DGS 联合优化几何与位姿。在技术上，我们将数千万点云的映射问题形式化为概率 Procrustes 问题，并求解其闭式对齐解。通过引入概率耦合以及软垃圾桶（soft dustbin）机制以剔除不确定的对应关系，我们的方法能够在数百张图像的规模下于数分钟内实现点云与位姿的全局对齐。此外，我们提出了 3DGS 与相机位姿的联合优化框架：利用置信度感知的锚点构建高斯，并结合 3DGS 可微分渲染与解析雅可比矩阵，实现对场景与位姿的联合细化，从而获得精确的重建与位姿估计。在 Waymo 与 KITTI 数据集上的实验表明，我们的方法能够从无位姿的图像序列中实现高精度重建，并在无位姿 3DGS 重建任务上刷新了最新的性能纪录。
