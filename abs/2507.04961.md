### InterGSEdit: Interactive 3D Gaussian Splatting Editing with 3D Geometry-Consistent Attention Prior

3D Gaussian Splatting based 3D editing has demonstrated impressive performance in recent years. However, the multi-view editing often exhibits significant local inconsistency, especially in areas of non-rigid deformation, which lead to local artifacts, texture blurring, or semantic variations in edited 3D scenes. We also found that the existing editing methods, which rely entirely on text prompts make the editing process a "one-shot deal", making it difficult for users to control the editing degree flexibly. In response to these challenges, we present InterGSEdit, a novel framework for high-quality 3DGS editing via interactively selecting key views with users' preferences. We propose a CLIP-based Semantic Consistency Selection (CSCS) strategy to adaptively screen a group of semantically consistent reference views for each user-selected key view. Then, the cross-attention maps derived from the reference views are used in a weighted Gaussian Splatting unprojection to construct the 3D Geometry-Consistent Attention Prior (GAP3D). We project GAP3D to obtain 3D-constrained attention, which are fused with 2D cross-attention via Attention Fusion Network (AFN). AFN employs an adaptive attention strategy that prioritizes 3D-constrained attention for geometric consistency during early inference, and gradually prioritizes 2D cross-attention maps in diffusion for fine-grained features during the later inference. Extensive experiments demonstrate that InterGSEdit achieves state-of-the-art performance, delivering consistent, high-fidelity 3DGS editing with improved user experience.

基于三维高斯溅射（3D Gaussian Splatting, 3DGS）的三维编辑在近年来表现出了令人印象深刻的性能。然而，多视角编辑往往存在显著的局部不一致性，尤其是在非刚性变形区域，这会导致局部伪影、纹理模糊或编辑后三维场景的语义变化。我们还发现，现有完全依赖文本提示的编辑方法，使得编辑过程成为一次性操作（“one-shot deal”），用户难以灵活控制编辑程度。针对这些挑战，我们提出了 **InterGSEdit**——一种可通过交互式选择用户偏好的关键视图实现高质量 3DGS 编辑的新框架。我们提出了一种基于 CLIP 的语义一致性选择（CLIP-based Semantic Consistency Selection, CSCS）策略，用于针对每个用户选定的关键视图，自适应地筛选一组语义一致的参考视图。随后，从这些参考视图中提取的交叉注意力图将被用于加权高斯溅射反投影，以构建三维几何一致性注意力先验（3D Geometry-Consistent Attention Prior, GAP3D）。我们将 GAP3D 投影以获得三维约束注意力，并通过注意力融合网络（Attention Fusion Network, AFN）与二维交叉注意力进行融合。AFN 采用一种自适应注意力策略，在推理早期优先利用三维约束注意力以保持几何一致性，而在扩散过程的后期则逐渐优先二维交叉注意力图，以捕获更精细的特征。大量实验表明，InterGSEdit 在一致性和高保真度的 3DGS 编辑方面达到了当前最优性能，并显著提升了用户体验。
