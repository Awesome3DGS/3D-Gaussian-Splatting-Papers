### OGGSplat: Open Gaussian Growing for Generalizable Reconstruction with Expanded Field-of-View

Reconstructing semantic-aware 3D scenes from sparse views is a challenging yet essential research direction, driven by the demands of emerging applications such as virtual reality and embodied AI. Existing per-scene optimization methods require dense input views and incur high computational costs, while generalizable approaches often struggle to reconstruct regions outside the input view cone. In this paper, we propose OGGSplat, an open Gaussian growing method that expands the field-of-view in generalizable 3D reconstruction. Our key insight is that the semantic attributes of open Gaussians provide strong priors for image extrapolation, enabling both semantic consistency and visual plausibility. Specifically, once open Gaussians are initialized from sparse views, we introduce an RGB-semantic consistent inpainting module applied to selected rendered views. This module enforces bidirectional control between an image diffusion model and a semantic diffusion model. The inpainted regions are then lifted back into 3D space for efficient and progressive Gaussian parameter optimization. To evaluate our method, we establish a Gaussian Outpainting (GO) benchmark that assesses both semantic and generative quality of reconstructed open-vocabulary scenes. OGGSplat also demonstrates promising semantic-aware scene reconstruction capabilities when provided with two view images captured directly from a smartphone camera.

从稀疏视角重建具有语义感知的三维场景是一个具有挑战性却又至关重要的研究方向，其背后受到虚拟现实和具身智能等新兴应用的强烈驱动。现有的按场景优化方法通常依赖于密集输入视角，计算成本较高；而可泛化方法则往往难以重建超出输入视锥范围的区域。
本文提出了一种名为 OGGSplat 的开放式高斯增长方法（Open Gaussian Growing Splatting），用于在可泛化三维重建中扩展视野范围。我们核心的洞察在于：开放高斯的语义属性可为图像外推提供强先验，从而同时实现语义一致性与视觉合理性。
具体而言，在从稀疏视角初始化开放高斯后，我们引入了一种 RGB-语义一致的图像补全模块，该模块作用于选定的渲染视图，利用图像扩散模型与语义扩散模型之间的双向控制机制，实现视觉与语义上的协同补全。补全后的图像区域再被“升维”回三维空间，参与后续高斯参数的高效、渐进式优化。
为评估该方法，我们构建了一个新的评测基准 Gaussian Outpainting (GO)，用于衡量重建场景在语义质量与生成质量两个方面的表现。实验表明，OGGSplat 在语义感知的三维场景重建任务中表现出强大能力，即使输入仅为来自智能手机的两个视角图像。
