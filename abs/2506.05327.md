### Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting

Depth maps are widely used in feed-forward 3D Gaussian Splatting (3DGS) pipelines by unprojecting them into 3D point clouds for novel view synthesis. This approach offers advantages such as efficient training, the use of known camera poses, and accurate geometry estimation. However, depth discontinuities at object boundaries often lead to fragmented or sparse point clouds, degrading rendering quality -- a well-known limitation of depth-based representations. To tackle this issue, we introduce PM-Loss, a novel regularization loss based on a pointmap predicted by a pre-trained transformer. Although the pointmap itself may be less accurate than the depth map, it effectively enforces geometric smoothness, especially around object boundaries. With the improved depth map, our method significantly improves the feed-forward 3DGS across various architectures and scenes, delivering consistently better rendering results.

深度图在前馈式三维高斯泼洒（3D Gaussian Splatting，3DGS）流程中被广泛使用，通常通过将其反投影为三维点云以实现新视角合成。这种方法具有多个优势，例如训练效率高、可利用已知相机位姿，以及具备较高的几何精度。然而，在物体边界处的深度不连续性常常导致点云破碎或稀疏，从而降低渲染质量——这是深度图表示中广为人知的限制。
为了解决这一问题，本文提出了一种名为 PM-Loss 的新型正则化损失，其基于由预训练 Transformer 模型预测的点图（pointmap）。尽管点图在精度上可能不如深度图，但它能有效增强几何的平滑性，特别是在物体边界区域。
通过使用改进后的深度图，我们的方法显著提升了前馈式 3DGS 的渲染效果，适用于多种网络结构和场景，在保持几何准确性的同时，能够持续带来更优质的渲染结果。
