### SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D Reconstruction Priors

Recent advances in dense 3D reconstruction enable the accurate capture of local geometry; however, integrating them into SLAM is challenging due to drift and redundant point maps, which limit efficiency and downstream tasks, such as novel view synthesis. To address these issues, we propose SING3R-SLAM, a globally consistent and compact Gaussian-based dense RGB SLAM framework. The key idea is to combine locally consistent 3D reconstructions with a unified global Gaussian representation that jointly refines scene geometry and camera poses, enabling efficient and versatile 3D mapping for multiple downstream applications. SING3R-SLAM first builds locally consistent submaps through our lightweight tracking and reconstruction module, and then progressively aligns and fuses them into a global Gaussian map that enforces cross-view geometric consistency. This global map, in turn, provides feedback to correct local drift and enhance the robustness of tracking. Extensive experiments demonstrate that SING3R-SLAM achieves state-of-the-art tracking, 3D reconstruction, and novel view rendering, resulting in over 12% improvement in tracking and producing finer, more detailed geometry, all while maintaining a compact and memory-efficient global representation on real-world datasets.

近年来，稠密三维重建技术取得了显著进展，使得局部几何的高精度捕捉成为可能；然而，将其整合进SLAM系统仍面临挑战，主要包括位姿漂移和冗余点图，这些问题限制了系统的效率以及下游任务（如新视角合成）的性能表现。为了解决这些问题，我们提出了 SING3R-SLAM，这是一种具备全局一致性和紧凑表达的基于高斯分布的稠密RGB SLAM框架。其核心思想是将局部一致的三维重建结果与统一的全局高斯表示相结合，在联合优化场景几何和相机位姿的同时，实现高效且灵活的三维建图，适用于多种下游应用。SING3R-SLAM 首先通过轻量级的跟踪与重建模块构建局部一致的子图，然后逐步将其对齐并融合到一个全局高斯地图中，以强制跨视角几何一致性。反过来，该全局地图还能反馈用于修正局部漂移并增强跟踪的鲁棒性。大量实验表明，SING3R-SLAM 在跟踪精度、三维重建质量及新视角合成方面均达到了当前最优水平，跟踪性能提升超过12%，几何细节更精致丰富，同时保持了全局地图的紧凑性与内存效率，在真实世界数据集上展现了优异表现。
