### ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation

On-the-fly 3D reconstruction from monocular image sequences is a long-standing challenge in computer vision, critical for applications such as real-to-sim, AR/VR, and robotics. Existing methods face a major tradeoff: per-scene optimization yields high fidelity but is computationally expensive, whereas feed-forward foundation models enable real-time inference but struggle with accuracy and robustness. In this work, we propose ARTDECO, a unified framework that combines the efficiency of feed-forward models with the reliability of SLAM-based pipelines. ARTDECO uses 3D foundation models for pose estimation and point prediction, coupled with a Gaussian decoder that transforms multi-scale features into structured 3D Gaussians. To sustain both fidelity and efficiency at scale, we design a hierarchical Gaussian representation with a LoD-aware rendering strategy, which improves rendering fidelity while reducing redundancy. Experiments on eight diverse indoor and outdoor benchmarks show that ARTDECO delivers interactive performance comparable to SLAM, robustness similar to feed-forward systems, and reconstruction quality close to per-scene optimization, providing a practical path toward on-the-fly digitization of real-world environments with both accurate geometry and high visual fidelity.

从单目图像序列中进行实时三维重建一直是计算机视觉领域的长期挑战，对于 real-to-sim、增强/虚拟现实（AR/VR）以及机器人等应用至关重要。现有方法面临一个关键权衡：逐场景优化可实现高保真重建，但计算代价高昂；而前馈式基础模型可支持实时推理，但在精度与鲁棒性方面表现不足。为解决这一问题，我们提出了 ARTDECO——一个融合前馈模型高效性与 SLAM 系统稳定性的统一框架。ARTDECO 利用三维基础模型进行位姿估计与点预测，并结合高斯解码器将多尺度特征转换为结构化的三维高斯表示。为在大规模场景中同时维持重建保真度与效率，我们设计了分层高斯表示与面向细节层级（LoD-aware）的渲染策略，有效提升了渲染质量并减少冗余。我们在八个不同类型的室内外基准数据集上进行了实验，结果表明 ARTDECO 实现了与 SLAM 相当的交互式性能，具备前馈系统级别的鲁棒性，同时在重建质量上接近逐场景优化水平，提供了一种可行的路径，实现现实环境的高精度、高保真实时数字化。
