### GauRast: Enhancing GPU Triangle Rasterizers to Accelerate 3D Gaussian Splatting

3D intelligence leverages rich 3D features and stands as a promising frontier in AI, with 3D rendering fundamental to many downstream applications. 3D Gaussian Splatting (3DGS), an emerging high-quality 3D rendering method, requires significant computation, making real-time execution on existing GPU-equipped edge devices infeasible. Previous efforts to accelerate 3DGS rely on dedicated accelerators that require substantial integration overhead and hardware costs. This work proposes an acceleration strategy that leverages the similarities between the 3DGS pipeline and the highly optimized conventional graphics pipeline in modern GPUs. Instead of developing a dedicated accelerator, we enhance existing GPU rasterizer hardware to efficiently support 3DGS operations. Our results demonstrate a 23× increase in processing speed and a 24× reduction in energy consumption, with improvements yielding 6× faster end-to-end runtime for the original 3DGS algorithm and 4× for the latest efficiency-improved pipeline, achieving 24 FPS and 46 FPS respectively. These enhancements incur only a minimal area overhead of 0.2% relative to the entire SoC chip area, underscoring the practicality and efficiency of our approach for enabling 3DGS rendering on resource-constrained platforms.

3D 智能利用丰富的三维特征，作为人工智能的一个重要前沿方向，而3D 渲染则是众多下游应用的基础。3D 高斯散点 (3DGS) 作为一种新兴的高质量 3D 渲染方法，其计算需求极为庞大，使得在现有配备 GPU 的边缘设备上无法实现实时执行。此前的 3DGS 加速方案主要依赖专用加速器，但这些方案往往需要较高的集成成本和硬件开销。
本研究提出了一种加速策略，利用 3DGS 渲染管线与现代 GPU 高度优化的传统图形管线之间的相似性。不同于开发专用加速器，我们通过增强 GPU 光栅化硬件来高效支持 3DGS 操作。实验结果表明，该方法实现了 23× 的处理速度提升和 24× 的能耗降低，并将原始 3DGS 算法的端到端运行时间加速 6×，达到 24 FPS，最新优化的高效渲染管线加速 4×，达到 46 FPS。此外，这一改进仅带来了 0.2% 的额外芯片面积开销（相对于整个 SoC 芯片面积），充分证明了该方案在资源受限平台上支持 3DGS 渲染的可行性和高效性。
