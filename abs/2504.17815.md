### Visibility-Uncertainty-guided 3D Gaussian Inpainting via Scene Conceptional Learning

3D Gaussian Splatting (3DGS) has emerged as a powerful and efficient 3D representation for novel view synthesis. This paper extends 3DGS capabilities to inpainting, where masked objects in a scene are replaced with new contents that blend seamlessly with the surroundings. Unlike 2D image inpainting, 3D Gaussian inpainting (3DGI) is challenging in effectively leveraging complementary visual and semantic cues from multiple input views, as occluded areas in one view may be visible in others. To address this, we propose a method that measures the visibility uncertainties of 3D points across different input views and uses them to guide 3DGI in utilizing complementary visual cues. We also employ uncertainties to learn a semantic concept of scene without the masked object and use a diffusion model to fill masked objects in input images based on the learned concept. Finally, we build a novel 3DGI framework, VISTA, by integrating VISibility-uncerTainty-guided 3DGI with scene conceptuAl learning. VISTA generates high-quality 3DGS models capable of synthesizing artifact-free and naturally inpainted novel views. Furthermore, our approach extends to handling dynamic distractors arising from temporal object changes, enhancing its versatility in diverse scene reconstruction scenarios. We demonstrate the superior performance of our method over state-of-the-art techniques using two challenging datasets: the SPIn-NeRF dataset, featuring 10 diverse static 3D inpainting scenes, and an underwater 3D inpainting dataset derived from UTB180, including fast-moving fish as inpainting targets.

3D Gaussian Splatting（3DGS）作为一种高效而强大的三维表示形式，在新视角合成任务中表现突出。本文将 3DGS 的能力拓展至补全任务（inpainting），即将场景中被遮挡或移除的目标以与周围环境自然融合的内容进行替代。不同于二维图像补全，**三维高斯补全（3DGI）**面临更大挑战：如何有效利用多视图中互补的视觉和语义线索，尤其当某一视角中遮挡区域在其他视角中可见时。
为此，我们提出一种方法，通过衡量三维点在不同输入视角下的可见性不确定性，引导 3DGI 更好地利用互补视觉线索。同时，我们利用这些不确定性学习一个去除遮挡物后的场景语义概念，并基于该概念使用扩散模型对输入图像中的遮挡区域进行填补。最终，我们构建了一个新的三维补全框架 VISTA，将可见性不确定性引导的 3DGI与场景语义学习相结合，生成高质量的 3DGS 模型，能够合成无伪影、自然过渡的补全视图。
此外，我们的方法还能处理由于时间变化引起的动态干扰目标，提升其在多样化场景重建任务中的适应性。我们在两个具有挑战性的数据集上验证了方法的优越性：一是包含 10 个多样静态 3D 补全过程景的 SPIn-NeRF 数据集；二是从 UTB180 构建的水下三维补全数据集，其中以高速游动的鱼类为补全目标。实验结果表明，我们的方法在补全质量与视图一致性方面均优于现有最先进技术。
