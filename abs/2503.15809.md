### Controlling Avatar Diffusion with Learnable Gaussian Embedding

Recent advances in diffusion models have made significant progress in digital human generation. However, most existing models still struggle to maintain 3D consistency, temporal coherence, and motion accuracy. A key reason for these shortcomings is the limited representation ability of commonly used control signals(e.g., landmarks, depth maps, etc.). In addition, the lack of diversity in identity and pose variations in public datasets further hinders progress in this area. In this paper, we analyze the shortcomings of current control signals and introduce a novel control signal representation that is optimizable, dense, expressive, and 3D consistent. Our method embeds a learnable neural Gaussian onto a parametric head surface, which greatly enhances the consistency and expressiveness of diffusion-based head models. Regarding the dataset, we synthesize a large-scale dataset with multiple poses and identities. In addition, we use real/synthetic labels to effectively distinguish real and synthetic data, minimizing the impact of imperfections in synthetic data on the generated head images. Extensive experiments show that our model outperforms existing methods in terms of realism, expressiveness, and 3D consistency.

近年来，扩散模型在数字人类生成方面取得了显著进展。然而，大多数现有模型仍难以维持 3D 一致性、时间一致性 和 运动准确性。这些不足的关键原因之一是常用控制信号（如地标、深度图等）表现能力的有限性。此外，公共数据集中身份和姿势变化的多样性不足，进一步阻碍了该领域的进展。
在本文中，我们分析了当前控制信号的不足，并引入了一种新的控制信号表示方法，该方法具有可优化、密集、富有表现力和3D 一致性的特点。我们的方法将一个可学习的神经高斯嵌入到参数化的头部表面，从而大大增强了基于扩散的头部模型的一致性和表现力。
在数据集方面，我们合成了一个包含多个姿势和身份的大规模数据集。此外，我们使用真实/合成标签来有效地区分真实数据和合成数据，从而最小化合成数据中的不完美对生成头部图像的影响。
大量实验表明，我们的模型在真实性、表现力和3D 一致性方面优于现有方法。
