### LLM-Powered Code Analysis and Optimization for Gaussian Splatting Kernels

3D Gaussian splatting (3DGS) is a transformative technique with profound implications on novel view synthesis and real-time rendering. Given its importance, there have been many attempts to improve its performance. However, with the increasing complexity of GPU architectures and the vast search space of performance-tuning parameters, it is a challenging task. Although manual optimizations have achieved remarkable speedups, they require domain expertise and the optimization process can be highly time consuming and error prone. In this paper, we propose to exploit large language models (LLMs) to analyze and optimize Gaussian splatting kernels. To our knowledge, this is the first work to use LLMs to optimize highly specialized real-world GPU kernels. We reveal the intricacies of using LLMs for code optimization and analyze the code optimization techniques from the LLMs. We also propose ways to collaborate with LLMs to further leverage their capabilities. For the original 3DGS code on the MipNeRF360 datasets, LLMs achieve significant speedups, 19% with Deepseek and 24% with GPT-5, demonstrating the different capabilities of different LLMs. By feeding additional information from performance profilers, the performance improvement from LLM-optimized code is enhanced to up to 42% and 38% on average. In comparison, our best-effort manually optimized version can achieve a performance improvement up to 48% and 39% on average, showing that there are still optimizations beyond the capabilities of current LLMs. On the other hand, even upon a newly proposed 3DGS framework with algorithmic optimizations, Seele, LLMs can still further enhance its performance by 6%, showing that there are optimization opportunities missed by domain experts. This highlights the potential of collaboration between domain experts and LLMs.

三维高斯溅射（3D Gaussian Splatting, 3DGS）是一项具有变革性意义的技术，在新视图合成与实时渲染等领域具有深远影响。鉴于其重要性，学界与业界已进行了大量研究以提升其性能。然而，随着 GPU 架构的复杂性不断增加以及性能调优参数空间的急剧扩张，性能优化仍然是一项极具挑战的任务。尽管人工优化已取得显著加速效果，但这类优化依赖专家经验，且过程耗时长、易出错。本文提出利用大语言模型（Large Language Models, LLMs）对高斯溅射核心（kernels）进行分析与优化。据我们所知，这是首个利用 LLM 优化真实世界中高度专业化 GPU 核函数的研究。我们揭示了使用 LLM 进行代码优化的复杂性，并系统分析了其产生的优化策略。同时，我们提出了与 LLM 协同优化的多种方法，以进一步发挥其潜能。在 MipNeRF360 数据集上的原始 3DGS 代码测试中，LLMs 实现了显著加速效果：Deepseek 提升 19%，GPT-5 提升 24%，体现了不同 LLM 的性能差异。当引入性能分析工具（performance profilers）提供的附加信息后，LLM 优化代码的性能提升可进一步达到 **42%** 与 **38%（平均）**。相比之下，我们人工尽力优化的版本可实现 **48%** 与 **39%（平均）** 的性能提升，说明当前 LLM 仍存在未覆盖的优化潜力。另一方面，即使在一个已包含算法级优化的新型 3DGS 框架 **Seele** 上，LLMs 仍能进一步提升 **6%** 的性能，表明仍有专家未能发现的优化机会。总体而言，这项研究凸显了领域专家与大语言模型协同优化的巨大潜力。
