### VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding

3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time rendering for novel view synthesis of 3D scenes. However, existing methods focus primarily on geometric and appearance modeling, lacking deeper scene understanding while also incurring high training costs that complicate the originally streamlined differentiable rendering pipeline. To this end, we propose VoteSplat, a novel 3D scene understanding framework that integrates Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized for instance segmentation, extracting objects, and generating 2D vote maps. We then embed spatial offset vectors into Gaussian primitives. These offsets construct 3D spatial votes by associating them with 2D image votes, while depth distortion constraints refine localization along the depth axis. For open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D point clouds via voting points, reducing training costs associated with high-dimensional CLIP features while preserving semantic unambiguity. Extensive experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D instance localization, 3D point cloud understanding, click-based 3D object localization, hierarchical segmentation, and ablation studies.

三维高斯投影（3D Gaussian Splatting，3DGS）已成为高质量、实时新视角合成渲染的重要基础。然而，现有方法主要聚焦于几何与外观建模，缺乏对场景的深层理解，并且训练成本高昂，违背了其原本简洁的可微渲染管线设计初衷。为此，我们提出了 **VoteSplat** —— 一种融合 Hough 投票机制与 3DGS 的新型三维场景理解框架。具体而言，我们引入 Segment Anything Model（SAM）进行实例分割，提取物体并生成二维投票图。随后，我们将空间偏移向量嵌入至高斯基元中，并通过将这些偏移与二维图像投票关联，构建三维空间投票。同时，引入深度畸变约束以优化沿深度方向的定位精度。在开放词汇的物体定位任务中，VoteSplat 通过投票点将二维图像语义映射到三维点云，有效降低高维 CLIP 特征的训练成本，同时保留语义判别性。大量实验表明，VoteSplat 在开放词汇三维实例定位、三维点云理解、基于点击的三维物体定位、层次化分割及消融分析等任务中均展现出优异表现。
