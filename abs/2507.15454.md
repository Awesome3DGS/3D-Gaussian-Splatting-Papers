### ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting

3D Gaussian Splatting is renowned for its high-fidelity reconstructions and real-time novel view synthesis, yet its lack of semantic understanding limits object-level perception. In this work, we propose ObjectGS, an object-aware framework that unifies 3D scene reconstruction with semantic understanding. Instead of treating the scene as a unified whole, ObjectGS models individual objects as local anchors that generate neural Gaussians and share object IDs, enabling precise object-level reconstruction. During training, we dynamically grow or prune these anchors and optimize their features, while a one-hot ID encoding with a classification loss enforces clear semantic constraints. We show through extensive experiments that ObjectGS not only outperforms state-of-the-art methods on open-vocabulary and panoptic segmentation tasks, but also integrates seamlessly with applications like mesh extraction and scene editing. o

三维高斯点渲染（3D Gaussian Splatting）以其高保真重建和实时新视角合成而闻名，但缺乏语义理解能力，限制了其在物体级感知中的应用。在本研究中，我们提出了 ObjectGS，这是一种融合三维场景重建与语义理解的物体感知框架。与将整个场景视为统一整体的方式不同，ObjectGS 将单个物体建模为生成神经高斯并共享物体 ID 的局部锚点，从而实现精确的物体级重建。在训练过程中，我们动态地增加或剪除这些锚点并优化其特征，同时通过带有分类损失的独热编码（one-hot ID encoding）施加明确的语义约束。大量实验表明，ObjectGS 在开放词汇和全景分割任务上均优于当前最先进的方法，并且能够与网格提取、场景编辑等应用无缝结合。
