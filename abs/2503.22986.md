### FreeSplat++: Generalizable 3D Gaussian Splatting for Efficient Indoor Scene Reconstruction

Recently, the integration of the efficient feed-forward scheme into 3D Gaussian Splatting (3DGS) has been actively explored. However, most existing methods focus on sparse view reconstruction of small regions and cannot produce eligible whole-scene reconstruction results in terms of either quality or efficiency. In this paper, we propose FreeSplat++, which focuses on extending the generalizable 3DGS to become an alternative approach to large-scale indoor whole-scene reconstruction, which has the potential of significantly accelerating the reconstruction speed and improving the geometric accuracy. To facilitate whole-scene reconstruction, we initially propose the Low-cost Cross-View Aggregation framework to efficiently process extremely long input sequences. Subsequently, we introduce a carefully designed pixel-wise triplet fusion method to incrementally aggregate the overlapping 3D Gaussian primitives from multiple views, adaptively reducing their redundancy. Furthermore, we propose a weighted floater removal strategy that can effectively reduce floaters, which serves as an explicit depth fusion approach that is crucial in whole-scene reconstruction. After the feed-forward reconstruction of 3DGS primitives, we investigate a depth-regularized per-scene fine-tuning process. Leveraging the dense, multi-view consistent depth maps obtained during the feed-forward prediction phase for an extra constraint, we refine the entire scene's 3DGS primitive to enhance rendering quality while preserving geometric accuracy. Extensive experiments confirm that our FreeSplat++ significantly outperforms existing generalizable 3DGS methods, especially in whole-scene reconstructions. Compared to conventional per-scene optimized 3DGS approaches, our method with depth-regularized per-scene fine-tuning demonstrates substantial improvements in reconstruction accuracy and a notable reduction in training time.

近期，越来越多的研究探索将高效前馈（feed-forward）机制融入三维高斯泼洒（3D Gaussian Splatting, 3DGS）中。然而，大多数现有方法主要针对小区域的稀疏视图重建，难以在质量或效率方面生成符合要求的整场景重建结果。
本文提出了FreeSplat++，旨在扩展可泛化的3DGS，使其成为大规模室内整场景重建的可行替代方案，具备显著加速重建速度并提升几何精度的潜力。为了促进整场景重建，我们首先提出了低成本跨视角聚合框架（Low-cost Cross-View Aggregation framework），以高效处理极长的输入序列。随后，我们引入了精心设计的逐像素三元融合方法（pixel-wise triplet fusion method），用于增量式地聚合多视角中重叠的三维高斯基元，自适应地减少冗余。
此外，我们提出了加权浮点噪声移除策略（weighted floater removal strategy），作为一种显式的深度融合方法，有效降低浮点噪声，这对于整场景重建至关重要。在完成3DGS基元的前馈重建后，我们进一步设计了基于深度正则化的逐场景微调过程。通过利用前馈预测阶段获得的稠密、多视角一致的深度图作为额外约束，对整个场景的3DGS基元进行细化，在提升渲染质量的同时保持几何精度。
大量实验表明，**FreeSplat++**在整场景重建任务中显著优于现有的可泛化3DGS方法。与传统的逐场景优化3DGS方法相比，我们的方法结合深度正则化的逐场景微调，在重建精度上取得了大幅提升，并显著缩短了训练时间。
