### SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting

3D Gaussian Splatting (3DGS) has enabled the creation of highly realistic 3D scene representations from sets of multi-view images. However, inpainting missing regions, whether due to occlusion or scene editing, remains a challenging task, often leading to blurry details, artifacts, and inconsistent geometry. In this work, we introduce SplatFill, a novel depth-guided approach for 3DGS scene inpainting that achieves state-of-the-art perceptual quality and improved efficiency. Our method combines two key ideas: (1) joint depth-based and object-based supervision to ensure inpainted Gaussians are accurately placed in 3D space and aligned with surrounding geometry, and (2) we propose a consistency-aware refinement scheme that selectively identifies and corrects inconsistent regions without disrupting the rest of the scene. Evaluations on the SPIn-NeRF dataset demonstrate that SplatFill not only surpasses existing NeRF-based and 3DGS-based inpainting methods in visual fidelity but also reduces training time by 24.5%. Qualitative results show our method delivers sharper details, fewer artifacts, and greater coherence across challenging viewpoints.

三维高斯溅射（3D Gaussian Splatting, 3DGS）使得从多视角图像集构建高度逼真的三维场景表示成为可能。然而，无论是由于遮挡造成的缺失区域，还是场景编辑引起的空洞修复（inpainting），仍然是一个具有挑战性的问题，常常会导致细节模糊、伪影增多以及几何结构不一致等问题。为此，我们提出了SplatFill——一种基于深度引导的3DGS场景修复新方法，能够在感知质量和效率上均达到当前最优水平。该方法融合了两个核心设计思想：（1）结合基于深度和基于物体的联合监督机制，以确保填充后的高斯在三维空间中精确定位并与周围几何结构对齐；（2）提出一致性感知的细化策略（consistency-aware refinement scheme），能够选择性地检测并修正不一致区域，而不会破坏场景的其他部分。在SPIn-NeRF数据集上的实验结果表明，SplatFill不仅在视觉保真度上显著优于现有的基于NeRF和基于3DGS的修复方法，还将训练时间缩短了24.5%。定性结果进一步显示，我们的方法在细节清晰度、伪影抑制和跨视角一致性方面均表现出更高的水准。
