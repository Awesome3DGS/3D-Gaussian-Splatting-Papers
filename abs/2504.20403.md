### Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting

Personalized 3D avatar editing holds significant promise due to its user-friendliness and availability to applications such as AR/VR and virtual try-ons. Previous studies have explored the feasibility of 3D editing, but often struggle to generate visually pleasing results, possibly due to the unstable representation learning under mixed optimization of geometry and texture in complicated reconstructed scenarios. In this paper, we aim to provide an accessible solution for ordinary users to create their editable 3D avatars with precise region localization, geometric adaptability, and photorealistic renderings. To tackle this challenge, we introduce a meticulously designed framework that decouples the editing process into local spatial adaptation and realistic appearance learning, utilizing a hybrid Tetrahedron-constrained Gaussian Splatting (TetGS) as the underlying representation. TetGS combines the controllable explicit structure of tetrahedral grids with the high-precision rendering capabilities of 3D Gaussian Splatting and is optimized in a progressive manner comprising three stages: 3D avatar instantiation from real-world monocular videos to provide accurate priors for TetGS initialization; localized spatial adaptation with explicitly partitioned tetrahedrons to guide the redistribution of Gaussian kernels; and geometry-based appearance generation with a coarse-to-fine activation strategy. Both qualitative and quantitative experiments demonstrate the effectiveness and superiority of our approach in generating photorealistic 3D editable avatars.

个性化三维头像编辑因其易用性以及在 AR/VR 和虚拟试穿等应用中的广泛潜力而备受关注。已有研究虽验证了三维编辑的可行性，但往往难以生成视觉效果令人满意的结果，这可能源于在复杂重建场景中，几何与纹理混合优化下的不稳定表示学习。
本文旨在为普通用户提供一种可访问的解决方案，使其能够创建具有精准区域定位、几何自适应性和真实感渲染效果的可编辑三维头像。为解决这一挑战，我们提出了一个精心设计的框架，将编辑过程解耦为局部空间适配与真实外观学习两个阶段，并采用混合四面体约束高斯泼溅（Tetrahedron-constrained Gaussian Splatting, TetGS）作为底层表示。TetGS 结合了四面体网格的可控显式结构与三维高斯泼溅的高精度渲染能力，并通过三个阶段以渐进式方式进行优化：首先从真实单目视频中实例化三维头像，为 TetGS 初始化提供准确先验；接着通过显式划分的四面体实现局部空间适配，引导高斯核的重新分布；最后采用由粗到细的激活策略，完成基于几何的外观生成。
定性与定量实验均表明，我们的方法在生成真实感强、可编辑的三维头像方面具备显著的效果与优势。
