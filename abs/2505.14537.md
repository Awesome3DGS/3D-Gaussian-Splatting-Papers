### Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image

Personalizing 3D scenes from a single reference image enables intuitive user-guided editing, which requires achieving both multi-view consistency across perspectives and referential consistency with the input image. However, these goals are particularly challenging due to the viewpoint bias caused by the limited perspective provided in a single image. Lacking the mechanisms to effectively expand reference information beyond the original view, existing methods of image-conditioned 3DGS personalization often suffer from this viewpoint bias and struggle to produce consistent results. Therefore, in this paper, we present Consistent Personalization for 3D Gaussian Splatting (CP-GS), a framework that progressively propagates the single-view reference appearance to novel perspectives. In particular, CP-GS integrates pre-trained image-to-3D generation and iterative LoRA fine-tuning to extract and extend the reference appearance, and finally produces faithful multi-view guidance images and the personalized 3DGS outputs through a view-consistent generation process guided by geometric cues. Extensive experiments on real-world scenes show that our CP-GS effectively mitigates the viewpoint bias, achieving high-quality personalization that significantly outperforms existing methods.

从单张参考图像出发实现个性化的三维场景生成，使用户能够以直观方式进行引导式编辑。这一任务要求同时满足多视角一致性与与输入图像的参考一致性，但由于单张图像所提供视角的局限性，易产生视角偏置，使得上述目标尤具挑战性。现有基于图像条件的 3D Gaussian Splatting（3DGS）个性化方法缺乏有效机制来拓展原始视角以外的参考信息，因而普遍受到视角偏置的影响，难以生成一致性良好的结果。
为解决该问题，本文提出了 CP-GS（Consistent Personalization for 3D Gaussian Splatting），一个可将单视图参考外观逐步传播到新视角的个性化生成框架。具体而言，CP-GS 融合预训练的图像到三维生成模型与迭代式的 LoRA 微调方法，用于提取并扩展参考外观信息，最终在几何线索引导下，生成视角一致的引导图像与个性化的 3DGS 输出。
在多个真实场景上的实验结果表明，CP-GS 能够有效缓解视角偏置，生成高质量的个性化结果，且在一致性和外观保真度方面显著优于现有方法。
