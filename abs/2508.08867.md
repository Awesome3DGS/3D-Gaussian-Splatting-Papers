### GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments

Novel view synthesis with neural models has advanced rapidly in recent years, yet adapting these models to scene changes remains an open problem. Existing methods are either labor-intensive, requiring extensive model retraining, or fail to capture detailed types of changes over time. In this paper, we present GaussianUpdate, a novel approach that combines 3D Gaussian representation with continual learning to address these challenges. Our method effectively updates the Gaussian radiance fields with current data while preserving information from past scenes. Unlike existing methods, GaussianUpdate explicitly models different types of changes through a novel multi-stage update strategy. Additionally, we introduce a visibility-aware continual learning approach with generative replay, enabling self-aware updating without the need to store images. The experiments on the benchmark dataset demonstrate our method achieves superior and real-time rendering with the capability of visualizing changes over different times

近年来，基于神经网络的新视角合成技术发展迅速，但如何使这些模型适应场景变化仍然是一个未解决的问题。现有方法要么劳动强度大，需要大量模型重新训练，要么无法捕捉场景随时间变化的细节。本文提出了一种名为 **GaussianUpdate** 的新方法，将三维高斯表示与持续学习相结合，以应对这些挑战。我们的方法能够在利用当前数据更新高斯辐射场的同时，保留历史场景信息。与现有方法不同，GaussianUpdate 通过一种新颖的多阶段更新策略，显式建模不同类型的场景变化。此外，我们提出了一种结合生成回放的可见性感知持续学习方法，使模型能够在无需存储图像的情况下实现自适应更新。基准数据集上的实验结果表明，我们的方法在实时渲染与跨时间可视化场景变化方面均实现了优越表现。
