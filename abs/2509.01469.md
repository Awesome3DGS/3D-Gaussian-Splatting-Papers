### Im2Haircut: Single-view Strand-based Hair Reconstruction for Human Avatars

We present a novel approach for 3D hair reconstruction from single photographs based on a global hair prior combined with local optimization. Capturing strand-based hair geometry from single photographs is challenging due to the variety and geometric complexity of hairstyles and the lack of ground truth training data. Classical reconstruction methods like multi-view stereo only reconstruct the visible hair strands, missing the inner structure of hairstyles and hampering realistic hair simulation. To address this, existing methods leverage hairstyle priors trained on synthetic data. Such data, however, is limited in both quantity and quality since it requires manual work from skilled artists to model the 3D hairstyles and create near-photorealistic renderings. To address this, we propose a novel approach that uses both, real and synthetic data to learn an effective hairstyle prior. Specifically, we train a transformer-based prior model on synthetic data to obtain knowledge of the internal hairstyle geometry and introduce real data in the learning process to model the outer structure. This training scheme is able to model the visible hair strands depicted in an input image, while preserving the general 3D structure of hairstyles. We exploit this prior to create a Gaussian-splatting-based reconstruction method that creates hairstyles from one or more images. Qualitative and quantitative comparisons with existing reconstruction pipelines demonstrate the effectiveness and superior performance of our method for capturing detailed hair orientation, overall silhouette, and backside consistency.

我们提出了一种基于全局发型先验与局部优化相结合的从单张照片进行三维头发重建的新方法。从单张照片中捕捉基于发丝的头发几何结构极具挑战性，这源于发型的多样性与几何复杂性，以及缺乏真实的训练数据。传统的重建方法（如多视角立体重建）只能重建可见的发丝，忽略了发型的内部结构，从而阻碍了真实感头发模拟。为了解决这一问题，现有方法通常利用在合成数据上训练的发型先验。然而，这类数据在数量和质量上都存在局限性，因为其需要专业艺术家手工建模三维发型并制作近乎照片级的渲染。针对这一问题，我们提出了一种新方法，结合真实数据和合成数据共同学习有效的发型先验。具体而言，我们在合成数据上训练一个基于Transformer的先验模型，以获取发型内部几何结构知识，并在训练过程中引入真实数据来建模外部结构。该训练方案能够对输入图像中可见的发丝进行建模，同时保持发型整体的三维结构。我们进一步利用这一先验，提出了一种基于高斯溅射的重建方法，可从一张或多张图像生成发型。与现有重建流程的定性与定量比较表明，我们的方法在捕捉头发细节方向、整体轮廓以及背面一致性方面具有有效性和优越性能。
