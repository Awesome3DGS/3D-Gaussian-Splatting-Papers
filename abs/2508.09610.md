### DualPhys-GS: Dual Physically-Guided 3D Gaussian Splatting for Underwater Scene Reconstruction

In 3D reconstruction of underwater scenes, traditional methods based on atmospheric optical models cannot effectively deal with the selective attenuation of light wavelengths and the effect of suspended particle scattering, which are unique to the water medium, and lead to color distortion, geometric artifacts, and collapsing phenomena at long distances. We propose the DualPhys-GS framework to achieve high-quality underwater reconstruction through a dual-path optimization mechanism. Our approach further develops a dual feature-guided attenuation-scattering modeling mechanism, the RGB-guided attenuation optimization model combines RGB features and depth information and can handle edge and structural details. In contrast, the multi-scale depth-aware scattering model captures scattering effects at different scales using a feature pyramid network and an attention mechanism. Meanwhile, we design several special loss functions. The attenuation scattering consistency loss ensures physical consistency. The water body type adaptive loss dynamically adjusts the weighting coefficients. The edge-aware scattering loss is used to maintain the sharpness of structural edges. The multi-scale feature loss helps to capture global and local structural information. In addition, we design a scene adaptive mechanism that can automatically identify the water-body-type characteristics (e.g., clear coral reef waters or turbid coastal waters) and dynamically adjust the scattering and attenuation parameters and optimization strategies. Experimental results show that our method outperforms existing methods in several metrics, especially in suspended matter-dense regions and long-distance scenes, and the reconstruction quality is significantly improved.

在水下场景的三维重建中，基于大气光学模型的传统方法无法有效处理水体介质特有的光波长选择性衰减和悬浮颗粒散射效应，导致远距离场景中出现颜色失真、几何伪影和塌陷现象。为解决这一问题，我们提出了 **DualPhys-GS** 框架，通过双路径优化机制实现高质量的水下重建。我们进一步设计了一种双特征引导的衰减-散射建模机制，其中 **RGB 引导的衰减优化模型** 结合了 RGB 特征和深度信息，能够更好地处理边缘和结构细节；而 **多尺度深度感知散射模型** 则利用特征金字塔网络与注意力机制捕捉不同尺度下的散射效应。同时，我们设计了多种特殊损失函数：**衰减-散射一致性损失** 用于保证物理一致性；**水体类型自适应损失** 可动态调整权重系数；**边缘感知散射损失** 用于保持结构边缘的清晰度；**多尺度特征损失** 有助于捕捉全局与局部结构信息。此外，我们提出了一种 **场景自适应机制**，能够自动识别水体类型特征（如清澈的珊瑚礁海域或浑浊的近海水域），并动态调整散射与衰减参数及优化策略。实验结果表明，该方法在多个评价指标上均优于现有方法，尤其在悬浮物密集区域与远距离场景中，重建质量显著提升。
