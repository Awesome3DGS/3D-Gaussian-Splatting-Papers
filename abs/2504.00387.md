### Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration

The reconstruction of immersive and realistic 3D scenes holds significant practical importance in various fields of computer vision and computer graphics. Typically, immersive and realistic scenes should be free from obstructions by dynamic objects, maintain global texture consistency, and allow for unrestricted exploration. The current mainstream methods for image-driven scene construction involves iteratively refining the initial image using a moving virtual camera to generate the scene. However, previous methods struggle with visual discontinuities due to global texture inconsistencies under varying camera poses, and they frequently exhibit scene voids caused by foreground-background occlusions. To this end, we propose a novel layered 3D scene reconstruction framework from panoramic image, named Scene4U. Specifically, Scene4U integrates an open-vocabulary segmentation model with a large language model to decompose a real panorama into multiple layers. Then, we employs a layered repair module based on diffusion model to restore occluded regions using visual cues and depth information, generating a hierarchical representation of the scene. The multi-layer panorama is then initialized as a 3D Gaussian Splatting representation, followed by layered optimization, which ultimately produces an immersive 3D scene with semantic and structural consistency that supports free exploration. Scene4U outperforms state-of-the-art method, improving by 24.24% in LPIPS and 24.40% in BRISQUE, while also achieving the fastest training speed. Additionally, to demonstrate the robustness of Scene4U and allow users to experience immersive scenes from various landmarks, we build WorldVista3D dataset for 3D scene reconstruction, which contains panoramic images of globally renowned sites.

沉浸式、真实感三维场景的重建在计算机视觉与计算机图形学的多个应用中具有重要的实际意义。通常，具备沉浸感与真实感的场景应满足以下条件：不被动态物体遮挡、具有全局纹理一致性，并支持自由探索。目前主流的图像驱动场景重建方法，通常采用移动虚拟相机对初始图像进行迭代优化以生成场景。然而，现有方法在不同相机姿态下常出现全局纹理不一致，导致视觉不连续性问题，同时也容易因前景-背景遮挡而产生场景空洞。
为此，我们提出了一种基于全景图像的新型分层三维场景重建框架，命名为 Scene4U。具体而言，Scene4U 首先结合开放词汇的分割模型与大型语言模型，将真实全景图像分解为多个语义层。随后，利用基于扩散模型的分层修复模块，结合视觉线索与深度信息，恢复被遮挡区域，从而构建场景的分层表达。接着，将多层全景图初始化为三维高斯喷洒（3D Gaussian Splatting）表示，并通过分层优化过程，最终生成具有语义一致性与结构一致性的沉浸式三维场景，支持用户自由探索。
Scene4U 在性能上显著优于现有最先进方法，在 LPIPS 指标上提升 24.24%，在 BRISQUE 指标上提升 24.40%，同时具备最快的训练速度。
此外，为验证 Scene4U 的鲁棒性，并让用户能够体验来自不同地标的沉浸式场景，我们构建了用于三维场景重建的 WorldVista3D 数据集，该数据集包含全球著名景点的全景图像。
