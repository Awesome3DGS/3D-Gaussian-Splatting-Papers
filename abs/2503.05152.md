### GSplatVNM: Point-of-View Synthesis for Visual Navigation Models Using Gaussian Splatting

This paper presents a novel approach to image-goal navigation by integrating 3D Gaussian Splatting (3DGS) with Visual Navigation Models (VNMs), a method we refer to as GSplatVNM. VNMs offer a promising paradigm for image-goal navigation by guiding a robot through a sequence of point-of-view images without requiring metrical localization or environment-specific training. However, constructing a dense and traversable sequence of target viewpoints from start to goal remains a central challenge, particularly when the available image database is sparse. To address these challenges, we propose a 3DGS-based viewpoint synthesis framework for VNMs that synthesizes intermediate viewpoints to seamlessly bridge gaps in sparse data while significantly reducing storage overhead. Experimental results in a photorealistic simulator demonstrate that our approach not only enhances navigation efficiency but also exhibits robustness under varying levels of image database sparsity.

本文提出了一种新颖的图像目标导航 (image-goal navigation) 方法，将 3D 高斯散点 (3D Gaussian Splatting, 3DGS) 与视觉导航模型 (Visual Navigation Models, VNMs) 相结合，称为 GSplatVNM。
VNMs 通过一系列视角图像引导机器人导航，无需度量级定位 (metrical localization) 或特定环境的训练，为图像目标导航提供了一个有前景的范式。然而，在起点到目标点的导航过程中，如何构建稠密且可遍历的目标视点序列仍然是核心挑战，特别是在可用图像数据库稀疏的情况下。
为此，我们提出了一种基于 3DGS 的 VNMs 视点合成框架，用于合成中间视点，从而无缝填补数据稀疏带来的空缺，同时大幅减少存储开销。在高真实感模拟环境中的实验表明，我们的方法不仅提升了导航效率，还能在不同程度的图像数据库稀疏性下保持稳健性。
