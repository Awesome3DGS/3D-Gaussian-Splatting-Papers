### S3Gaussian: Self-Supervised Street Gaussians for Autonomous Driving

Photorealistic 3D reconstruction of street scenes is a critical technique for developing real-world simulators for autonomous driving. Despite the efficacy of Neural Radiance Fields (NeRF) for driving scenes, 3D Gaussian Splatting (3DGS) emerges as a promising direction due to its faster speed and more explicit representation. However, most existing street 3DGS methods require tracked 3D vehicle bounding boxes to decompose the static and dynamic elements for effective reconstruction, limiting their applications for in-the-wild scenarios. To facilitate efficient 3D scene reconstruction without costly annotations, we propose a self-supervised street Gaussian (S3Gaussian) method to decompose dynamic and static elements from 4D consistency. We represent each scene with 3D Gaussians to preserve the explicitness and further accompany them with a spatial-temporal field network to compactly model the 4D dynamics. We conduct extensive experiments on the challenging Waymo-Open dataset to evaluate the effectiveness of our method. Our S3Gaussian demonstrates the ability to decompose static and dynamic scenes and achieves the best performance without using 3D annotations.

三维高保真重建街景对于开发自动驾驶实时模拟器是一项关键技术。尽管神经辐射场（NeRF）在驾驶场景中效果显著，但三维高斯溅射（3DGS）由于其更快的速度和更明确的表示而成为一个有前景的方向。然而，大多数现有的街道3DGS方法需要跟踪的三维车辆边界框来分解静态和动态元素以有效重建，这限制了它们在野外场景中的应用。为了在不需要昂贵标注的情况下促进高效的三维场景重建，我们提出了一种自监督街道高斯（S3Gaussian）方法，从四维一致性中分解动态和静态元素。我们用三维高斯表示每个场景以保持明确性，并进一步将其与一个空间-时间场网络结合使用，以紧凑地模拟四维动态。我们在具有挑战性的Waymo-Open数据集上进行了广泛的实验以评估我们方法的有效性。我们的S3Gaussian展示了分解静态和动态场景的能力，并在不使用三维注释的情况下达到了最佳性能。
