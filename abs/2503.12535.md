### SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor Open-World Free-view Synthesis from Sparse Inputs

3D Gaussian Splatting-based indoor open-world free-view synthesis approaches have shown significant performance with dense input images. However, they exhibit poor performance when confronted with sparse inputs, primarily due to the sparse distribution of Gaussian points and insufficient view supervision. To relieve these challenges, we propose SPC-GS, leveraging Scene-layout-based Gaussian Initialization (SGI) and Semantic-Prompt Consistency (SPC) Regularization for open-world free view synthesis with sparse inputs. Specifically, SGI provides a dense, scene-layout-based Gaussian distribution by utilizing view-changed images generated from the video generation model and view-constraint Gaussian points densification. Additionally, SPC mitigates limited view supervision by employing semantic-prompt-based consistency constraints developed by SAM2. This approach leverages available semantics from training views, serving as instructive prompts, to optimize visually overlapping regions in novel views with 2D and 3D consistency constraints. Extensive experiments demonstrate the superior performance of SPC-GS across Replica and ScanNet benchmarks. Notably, our SPC-GS achieves a 3.06 dB gain in PSNR for reconstruction quality and a 7.3% improvement in mIoU for open-world semantic segmentation.

基于三维高斯点云渲染（3D Gaussian Splatting）的室内开放世界自由视角合成方法在密集输入图像下表现出显著的性能。然而，当面对稀疏输入时，它们的表现较差，主要是由于高斯点的稀疏分布和视角监督不足。为了解决这些挑战，我们提出了SPC-GS，利用基于场景布局的高斯初始化（SGI）和语义提示一致性（SPC）正则化来进行稀疏输入的开放世界自由视角合成。具体而言，SGI通过利用视频生成模型生成的视角变化图像和视角约束的高斯点密集化，提供了一个密集的基于场景布局的高斯分布。此外，SPC通过采用由SAM2开发的语义提示一致性约束，缓解了有限视角监督的问题。该方法利用训练视角中可用的语义信息作为指导提示，优化新视角中视觉重叠区域，结合2D和3D一致性约束。广泛的实验表明，SPC-GS在Replica和ScanNet基准测试中的表现优越。值得注意的是，我们的SPC-GS在重建质量上取得了3.06 dB的PSNR提升，并且在开放世界语义分割中实现了7.3%的mIoU改善。
