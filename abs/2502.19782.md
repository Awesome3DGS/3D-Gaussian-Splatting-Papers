### Open-Vocabulary Semantic Part Segmentation of 3D Human

3D part segmentation is still an open problem in the field of 3D vision and AR/VR. Due to limited 3D labeled data, traditional supervised segmentation methods fall short in generalizing to unseen shapes and categories. Recently, the advancement in vision-language models' zero-shot abilities has brought a surge in open-world 3D segmentation methods. While these methods show promising results for 3D scenes or objects, they do not generalize well to 3D humans. In this paper, we present the first open-vocabulary segmentation method capable of handling 3D human. Our framework can segment the human category into desired fine-grained parts based on the textual prompt. We design a simple segmentation pipeline, leveraging SAM to generate multi-view proposals in 2D and proposing a novel HumanCLIP model to create unified embeddings for visual and textual inputs. Compared with existing pre-trained CLIP models, the HumanCLIP model yields more accurate embeddings for human-centric contents. We also design a simple-yet-effective MaskFusion module, which classifies and fuses multi-view features into 3D semantic masks without complex voting and grouping mechanisms. The design of decoupling mask proposals and text input also significantly boosts the efficiency of per-prompt inference. Experimental results on various 3D human datasets show that our method outperforms current state-of-the-art open-vocabulary 3D segmentation methods by a large margin. In addition, we show that our method can be directly applied to various 3D representations including meshes, point clouds, and 3D Gaussian Splatting.

3D 部件分割仍然是3D 视觉和 AR/VR 领域中的一个开放性问题。由于3D 标注数据有限，传统的监督分割方法难以泛化到未见过的形状和类别。近年来，视觉-语言模型 在零样本能力上的突破推动了开放世界 3D 分割方法的发展。然而，尽管这些方法在3D 场景或物体上取得了良好效果，但它们在3D 人体上的泛化能力仍然较差。
在本文中，我们提出了首个能够处理 3D 人体的开放词汇分割方法。我们的框架能够根据文本提示，将人体类别划分为细粒度的部件。我们设计了一条简洁的分割流水线，利用 SAM 在2D 视图上生成多视角分割候选区域，并提出 HumanCLIP 模型，以创建统一的视觉和文本嵌入。相比现有的预训练 CLIP 模型，HumanCLIP 在人体相关内容上生成的嵌入更加准确。我们还提出 MaskFusion 模块，以分类和融合多视角特征，从而生成3D 语义掩码，无需复杂的投票和分组机制。此外，掩码候选区域与文本输入的解耦设计显著提升了按需推理（per-prompt inference）的效率。
在多个3D 人体数据集上的实验表明，我们的方法相比现有最先进（SOTA）的开放词汇 3D 分割方法取得了大幅度提升。此外，我们的方法可直接适用于多种 3D 表示，包括网格（meshes）、点云（point clouds）和 3D Gaussian Splatting（3DGS），展现出卓越的通用性。
