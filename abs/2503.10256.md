### ROODI: Reconstructing Occluded Objects with Denoising Inpainters

While the quality of novel-view images has improved dramatically with 3D Gaussian Splatting, extracting specific objects from scenes remains challenging. Isolating individual 3D Gaussian primitives for each object and handling occlusions in scenes remain far from being solved. We propose a novel object extraction method based on two key principles: (1) being object-centric by pruning irrelevant primitives; and (2) leveraging generative inpainting to compensate for missing observations caused by occlusions. For pruning, we analyze the local structure of primitives using K-nearest neighbors, and retain only relevant ones. For inpainting, we employ an off-the-shelf diffusion-based inpainter combined with occlusion reasoning, utilizing the 3D representation of the entire scene. Our findings highlight the crucial synergy between pruning and inpainting, both of which significantly enhance extraction performance. We evaluate our method on a standard real-world dataset and introduce a synthetic dataset for quantitative analysis. Our approach outperforms the state-of-the-art, demonstrating its effectiveness in object extraction from complex scenes.

尽管使用 3D 高斯溅射（3DGS）新视角图像的质量有了显著提高，但从场景中提取特定对象仍然具有挑战性。为每个对象孤立出单独的 3D 高斯原语并处理场景中的遮挡问题，仍远未解决。我们提出了一种基于两个关键原则的新型对象提取方法：(1) 以对象为中心，通过修剪不相关的原语；(2) 利用生成性修复来弥补由于遮挡导致的缺失观察。对于修剪，我们通过使用 K 最近邻分析原语的局部结构，并仅保留相关的原语。对于修复，我们采用一个现成的基于扩散的修复模型，并结合遮挡推理，利用整个场景的 3D 表征。我们的研究结果强调了修剪与修复之间的关键协同作用，这两者显著提高了提取性能。我们在一个标准的现实世界数据集上评估了我们的方法，并引入了一个合成数据集进行定量分析。实验结果表明，我们的方法优于最先进的技术，展示了它在复杂场景中进行对象提取的有效性。
