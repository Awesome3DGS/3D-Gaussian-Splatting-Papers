### Enhancing 3D Gaussian Splatting Compression via Spatial Condition-based Prediction

Recently, 3D Gaussian Spatting (3DGS) has gained widespread attention in Novel View Synthesis (NVS) due to the remarkable real-time rendering performance. However, the substantial cost of storage and transmission of vanilla 3DGS hinders its further application (hundreds of megabytes or even gigabytes for a single scene). Motivated by the achievements of prediction in video compression, we introduce the prediction technique into the anchor-based Gaussian representation to effectively reduce the bit rate. Specifically, we propose a spatial condition-based prediction module to utilize the grid-captured scene information for prediction, with a residual compensation strategy designed to learn the missing fine-grained information. Besides, to further compress the residual, we propose an instance-aware hyper prior, developing a structure-aware and instance-aware entropy model. Extensive experiments demonstrate the effectiveness of our prediction-based compression framework and each technical component. Even compared with SOTA compression method, our framework still achieves a bit rate savings of 24.42 percent.

近年来，三维高斯泼洒（3D Gaussian Splatting, 3DGS）因其出色的实时渲染性能，在新视角合成（Novel View Synthesis, NVS）领域受到了广泛关注。然而，原始3DGS在存储与传输方面的高开销（单个场景通常需要数百兆字节甚至数千兆字节）严重阻碍了其进一步应用。
受视频压缩中预测技术成功应用的启发，本文将预测技术引入基于锚点（anchor-based）的高斯表示，以有效降低比特率。具体而言，我们提出了一种基于空间条件的预测模块（spatial condition-based prediction module），利用网格采样的场景信息进行预测，并设计了残差补偿策略（residual compensation strategy）以学习缺失的细粒度信息。此外，为了进一步压缩残差信息，我们提出了面向实例的超先验（instance-aware hyper prior），发展了一种结构感知与实例感知的熵模型。
大量实验验证了我们基于预测的压缩框架及各技术组件的有效性。即使与当前最佳（SOTA）压缩方法相比，我们的框架仍实现了24.42%的比特率节省。
