### MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video

We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner. Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality. While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects. To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for effective latent camera trajectory estimation, improving global camera motion deblurring. In addition, we propose a physically-inspired Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both global camera and local object motion. Our MoBGS framework ensures the temporal consistency of unseen latent timestamps and robust motion decomposition of static and dynamic regions. Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent advanced methods (DyBluRF and Deblur4DGS), achieving state-of-the-art performance for dynamic NVS under motion blur.

我们提出了 MoBGS，一个新颖的去模糊动态 3D Gaussian Splatting（3DGS）框架，能够端到端地从模糊的单目视频中重建清晰且高质量的时空新视角图像。现有的动态新视角合成（Novel View Synthesis, NVS）方法对日常拍摄视频中的运动模糊极为敏感，导致渲染质量显著下降。尽管近期的一些方法开始关注带有运动模糊输入的 NVS 问题，但这些方法大多聚焦于静态场景重建，缺乏对动态物体运动的专门建模。
为克服上述限制，MoBGS 引入了一种新颖的 模糊自适应潜摄像机估计方法（Blur-adaptive Latent Camera Estimation, BLCE），用于有效估计潜摄像机轨迹，从而改善全局摄像机运动引起的模糊。此外，我们还提出了一种受物理启发的 潜摄像机诱导曝光估计方法（Latent Camera-induced Exposure Estimation, LCEE），以实现全局摄像机与局部物体运动的统一去模糊。
MoBGS 框架能够确保未见潜时间戳（latent timestamps）的时间一致性，并实现对静态与动态区域的鲁棒运动解耦。我们在 Stereo Blur 数据集及多个真实模糊视频上进行了广泛实验，结果显示 MoBGS 显著优于最新的先进方法 DyBluRF 和 Deblur4DGS，在存在运动模糊的动态 NVS 任务中达到了当前最优性能。
