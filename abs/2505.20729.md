### Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting

Sparse-view scene reconstruction often faces significant challenges due to the constraints imposed by limited observational data. These limitations result in incomplete information, leading to suboptimal reconstructions using existing methodologies. To address this, we present Intern-GS, a novel approach that effectively leverages rich prior knowledge from vision foundation models to enhance the process of sparse-view Gaussian Splatting, thereby enabling high-quality scene reconstruction. Specifically, Intern-GS utilizes vision foundation models to guide both the initialization and the optimization process of 3D Gaussian splatting, effectively addressing the limitations of sparse inputs. In the initialization process, our method employs DUSt3R to generate a dense and non-redundant gaussian point cloud. This approach significantly alleviates the limitations encountered by traditional structure-from-motion (SfM) methods, which often struggle under sparse-view constraints. During the optimization process, vision foundation models predict depth and appearance for unobserved views, refining the 3D Gaussians to compensate for missing information in unseen regions. Extensive experiments demonstrate that Intern-GS achieves state-of-the-art rendering quality across diverse datasets, including both forward-facing and large-scale scenes, such as LLFF, DTU, and Tanks and Temples.

稀疏视角下的场景重建由于观测数据受限，常常面临显著挑战。这些限制导致信息不完整，使得现有方法难以实现高质量的重建效果。为解决这一问题，我们提出 Intern-GS，一种新颖的方法，通过有效利用视觉基础模型中的丰富先验知识，提升稀疏视角条件下的高斯投影（Gaussian Splatting）重建质量，从而实现高质量的三维场景重建。
具体而言，Intern-GS 利用视觉基础模型在 初始化阶段与优化阶段对 3D Gaussian Splatting 过程进行引导，从根本上缓解稀疏输入带来的不足。在初始化过程中，方法使用 DUSt3R 生成稠密且无冗余的高斯点云，显著缓解了传统结构光束法（Structure-from-Motion, SfM）在稀疏视角下难以构建有效点云的问题。
在优化阶段，Intern-GS 借助视觉基础模型预测未观测视角下的深度与外观信息，从而补全不可见区域中的缺失信息，进一步细化三维高斯表示。
大量实验证明，Intern-GS 在多个数据集上实现了当前最优的渲染质量，包括前视场景（如 LLFF）与大规模场景（如 DTU、Tanks and Temples）。该方法在稀疏视角条件下表现出强大的重建能力与泛化性能。
