### DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D Gaussian Splatting

3D Gaussian Splatting (3DGS) represents a significant advancement in the field of efficient and high-fidelity novel view synthesis. Despite recent progress, achieving accurate geometric reconstruction under sparse-view conditions remains a fundamental challenge. Existing methods often rely on non-local depth regularization, which fails to capture fine-grained structures and is highly sensitive to depth estimation noise. Furthermore, traditional smoothing methods neglect semantic boundaries and indiscriminately degrade essential edges and textures, consequently limiting the overall quality of reconstruction. In this work, we propose DET-GS, a unified depth and edge-aware regularization framework for 3D Gaussian Splatting. DET-GS introduces a hierarchical geometric depth supervision framework that adaptively enforces multi-level geometric consistency, significantly enhancing structural fidelity and robustness against depth estimation noise. To preserve scene boundaries, we design an edge-aware depth regularization guided by semantic masks derived from Canny edge detection. Furthermore, we introduce an RGB-guided edge-preserving Total Variation loss that selectively smooths homogeneous regions while rigorously retaining high-frequency details and textures. Extensive experiments demonstrate that DET-GS achieves substantial improvements in both geometric accuracy and visual fidelity, outperforming state-of-the-art (SOTA) methods on sparse-view novel view synthesis benchmarks.

三维高斯溅射（3D Gaussian Splatting，3DGS）在高效、高保真的新视角合成领域取得了重要进展。尽管近年来取得了进步，但在稀疏视角条件下实现精确的几何重建仍是一个核心挑战。现有方法通常依赖非局部深度正则化，这类方法难以捕捉精细结构，并且对深度估计噪声高度敏感。此外，传统的平滑方法忽视了语义边界，不加区分地削弱了关键边缘和纹理，从而限制了重建的整体质量。为此，我们提出了 DET-GS，这是一种面向三维高斯溅射的统一深度与边缘感知正则化框架。DET-GS 引入了分层几何深度监督机制，自适应地在多层级上施加几何一致性约束，从而显著提升结构保真度，并增强对深度估计噪声的鲁棒性。为了保留场景边界，我们设计了基于 Canny 边缘检测生成的语义掩码引导的边缘感知深度正则化。此外，我们提出了一种基于 RGB 引导的边缘保持全变差（Total Variation）损失，该方法在选择性平滑均质区域的同时，严格保留高频细节与纹理。大量实验结果表明，DET-GS 在几何精度和视觉保真度方面均取得了显著提升，并在稀疏视角新视角合成基准上优于当前最先进（SOTA）的方法。
