### FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training

The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately. While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance. To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images. We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models. This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses. In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene. Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods.

从图像生成新视图的领域随着神经辐射场（NeRF）以及最近的3D Gaussian Splatting技术的引入得到了快速发展。由于高效且能够准确渲染新视图，高斯散点已被广泛采用。然而，当训练图像数量不足时，高斯散点的非结构化显式表示容易在稀疏输入图像场景中过拟合，导致渲染效果不佳。为此，我们提出了一种基于3D高斯的少样本新视图合成方法，使用稀疏输入图像即可准确渲染训练图像未覆盖视角下的场景。我们提出了一种多阶段训练方案，在新视图上施加基于匹配的一致性约束，而无需依赖预训练的深度估计或扩散模型。通过利用现有训练图像的匹配信息，对在训练帧之间采样的颜色、几何和语义损失进行监督生成。此外，我们引入了一种局部性保持正则化，用于3D高斯，保留场景的局部颜色结构，从而消除渲染伪影。合成和真实数据集上的评估结果表明，我们的方法在少样本新视图合成方面相比现有最先进方法具有竞争力甚至优越的性能。

