### GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation with Unity Integration

Photorealistic avatars have become essential for immersive applications in virtual reality (VR) and augmented reality (AR), enabling lifelike interactions in areas such as training simulations, telemedicine, and virtual collaboration. These avatars bridge the gap between the physical and digital worlds, improving the user experience through realistic human representation. However, existing avatar creation techniques face significant challenges, including high costs, long creation times, and limited utility in virtual applications. Manual methods, such as MetaHuman, require extensive time and expertise, while automatic approaches, such as NeRF-based pipelines often lack efficiency, detailed facial expression fidelity, and are unable to be rendered at a speed sufficent for real-time applications. By involving several cutting-edge modern techniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar creation pipeline that leverages monocular video input to create a scalable and efficient photorealistic avatar directly compatible with the Unity game engine. Our pipeline incorporates a novel Gaussian splatting technique with customized preprocessing that enables the user of "in the wild" monocular video capture, detailed facial expression reconstruction and embedding within a fully rigged avatar model. Additionally, we present a Unity-integrated Gaussian Splatting Avatar Editor, offering a user-friendly environment for VR/AR application development. Experimental results validate the effectiveness of our preprocessing pipeline in standardizing custom data for 3DGS training and demonstrate the versatility of Gaussian avatars in Unity, highlighting the scalability and practicality of our approach.

逼真写实的虚拟化身（Photorealistic avatars）已成为虚拟现实（VR）与增强现实（AR）等沉浸式应用中的关键组成部分，广泛应用于训练模拟、远程医疗、虚拟协作等场景，赋予数字空间中更具真实感的人际互动体验。通过对人类形象的逼真重建，这类虚拟化身有效连接了物理世界与数字世界，显著提升了用户沉浸感与交互质量。
然而，现有的虚拟化身生成技术仍面临诸多挑战，如成本高昂、制作周期长、以及在虚拟应用中的适用性有限。手工构建方案（如 MetaHuman）依赖专业人员、制作复杂，而自动化方案（如基于 NeRF 的方法）则常常存在效率低下、面部表情精细度不足，以及无法满足实时渲染需求等问题。
为此，我们提出了一个端到端的 3D Gaussian Splatting（3DGS）化身生成流程，支持从单目视频输入中快速构建可扩展、高保真的写实化身，并可直接部署于 Unity 游戏引擎。该流程融合了多项前沿技术：引入了自定义预处理策略的新型高斯投影方法，支持“野外”条件下的视频采集输入，并可精细还原面部表情，同时将其嵌入到完整骨骼绑定的虚拟角色中。
此外，我们开发了 Unity 集成版 Gaussian Splatting Avatar Editor，为 VR/AR 应用开发者提供了一个直观友好的编辑环境。实验结果表明，我们的预处理流程能够有效标准化用户自定义数据以适配 3DGS 训练，同时展示了高斯化身在 Unity 中的灵活适应性与广泛实用性，充分体现了本方法的可扩展性与实用价值。
