### Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling

Arbitrary-scale super-resolution (ASSR) aims to reconstruct high-resolution (HR) images from low-resolution (LR) inputs with arbitrary upsampling factors using a single model, addressing the limitations of traditional SR methods constrained to fixed-scale factors (\textit{e.g.}, × 2). Recent advances leveraging implicit neural representation (INR) have achieved great progress by modeling coordinate-to-pixel mappings. However, the efficiency of these methods may suffer from repeated upsampling and decoding, while their reconstruction fidelity and quality are constrained by the intrinsic representational limitations of coordinate-based functions. To address these challenges, we propose a novel ContinuousSR framework with a Pixel-to-Gaussian paradigm, which explicitly reconstructs 2D continuous HR signals from LR images using Gaussian Splatting. This approach eliminates the need for time-consuming upsampling and decoding, enabling extremely fast arbitrary-scale super-resolution. Once the Gaussian field is built in a single pass, ContinuousSR can perform arbitrary-scale rendering in just 1ms per scale. Our method introduces several key innovations. Through statistical analysis, we uncover the Deep Gaussian Prior (DGP) and propose DGP-Driven Covariance Weighting, which dynamically optimizes covariance via adaptive weighting. Additionally, we present Adaptive Position Drifting, which refines the positional distribution of the Gaussian space based on image content, further enhancing reconstruction quality. Extensive experiments on seven benchmarks demonstrate that our ContinuousSR delivers significant improvements in SR quality across all scales, with an impressive 19.5× speedup when continuously upsampling an image across forty scales.

任意尺度超分辨率 (Arbitrary-scale Super-Resolution, ASSR) 旨在通过单一模型从低分辨率 (LR) 输入重建高分辨率 (HR) 图像，并支持任意放大倍数，从而突破传统超分辨率 (SR) 方法受固定缩放因子（\textit{e.g.}, ×2）限制的问题。近年来，利用隐式神经表示 (Implicit Neural Representation, INR) 的方法通过建模坐标到像素的映射取得了显著进展。然而，这类方法的效率可能受到重复放大和解码过程的影响，同时，其重建保真度和质量也受限于基于坐标函数的固有表示能力。
为解决这些挑战，我们提出了一种新的 ContinuousSR 框架，基于像素到高斯 (Pixel-to-Gaussian) 方案，通过高斯散点 (Gaussian Splatting) 从 LR 图像显式重建二维连续 HR 信号。这种方法无需耗时的放大和解码过程，实现了极高速的任意尺度超分辨率。一旦建立高斯场（Gaussian field），ContinuousSR 仅需 1ms 即可完成任意尺度渲染。
我们的方法引入了多个关键创新点。首先，通过统计分析，我们揭示了深度高斯先验 (Deep Gaussian Prior, DGP)，并提出 DGP 驱动的协方差加权 (DGP-Driven Covariance Weighting)，利用自适应加权动态优化协方差。此外，我们提出 自适应位置漂移 (Adaptive Position Drifting)，根据图像内容优化高斯空间中的位置分布，进一步提升重建质量。 在七个基准数据集上的广泛实验表明，ContinuousSR 在所有尺度下均显著提升 SR 质量，并在跨四十个尺度连续放大时实现了 19.5× 的加速。
