### P-4DGS: Predictive 4D Gaussian Splatting with 90× Compression

3D Gaussian Splatting (3DGS) has garnered significant attention due to its superior scene representation fidelity and real-time rendering performance, especially for dynamic 3D scene reconstruction (i.e., 4D reconstruction). However, despite achieving promising results, most existing algorithms overlook the substantial temporal and spatial redundancies inherent in dynamic scenes, leading to prohibitive memory consumption. To address this, we propose P-4DGS, a novel dynamic 3DGS representation for compact 4D scene modeling. Inspired by intra- and inter-frame prediction techniques commonly used in video compression, we first design a 3D anchor point-based spatial-temporal prediction module to fully exploit the spatial-temporal correlations across different 3D Gaussian primitives. Subsequently, we employ an adaptive quantization strategy combined with context-based entropy coding to further reduce the size of the 3D anchor points, thereby achieving enhanced compression efficiency. To evaluate the rate-distortion performance of our proposed P-4DGS in comparison with other dynamic 3DGS representations, we conduct extensive experiments on both synthetic and real-world datasets. Experimental results demonstrate that our approach achieves state-of-the-art reconstruction quality and the fastest rendering speed, with a remarkably low storage footprint (around 1MB on average), achieving up to 40× and 90× compression on synthetic and real-world scenes, respectively.

三维高斯泼溅（3D Gaussian Splatting, 3DGS）因其卓越的场景表达保真度与实时渲染性能，特别是在动态三维场景重建（即4D重建）中的表现，近年来受到广泛关注。然而，尽管现有方法取得了令人鼓舞的成果，但大多数算法忽视了动态场景中大量存在的时间与空间冗余，导致内存消耗极为高昂。为此，我们提出P-4DGS，一种用于紧凑型4D场景建模的动态3DGS新表示方法。该方法受到视频压缩中帧内与帧间预测技术的启发，首先设计了一种基于三维锚点的时空预测模块，充分挖掘不同高斯基元之间的时空相关性。随后，我们结合上下文熵编码，采用自适应量化策略进一步压缩三维锚点的存储开销，从而实现更高效的压缩率。为评估P-4DGS在码率-失真性能方面相较其他动态3DGS表示的优劣，我们在合成数据与真实场景数据上进行了大量实验。实验结果表明，我们的方法在重建质量和渲染速度上均达到当前最优水平，同时具有极低的存储占用（平均约为1MB），在合成场景和真实场景上分别实现了高达40×与90×的压缩率。
