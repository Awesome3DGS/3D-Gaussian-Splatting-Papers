### UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering

In this paper, we propose UniGS, a unified map representation and differentiable framework for high-fidelity multimodal 3D reconstruction based on 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated rasterization pipeline capable of rendering photo-realistic RGB images, geometrically accurate depth maps, consistent surface normals, and semantic logits simultaneously. We redesign the rasterization to render depth via differentiable ray-ellipsoid intersection rather than using Gaussian centers, enabling effective optimization of rotation and scale attribute through analytic depth gradients. Furthermore, we derive the analytic gradient formulation for surface normal rendering, ensuring geometric consistency among reconstructed 3D scenes. To improve computational and storage efficiency, we introduce a learnable attribute that enables differentiable pruning of Gaussians with minimal contribution during training. Quantitative and qualitative experiments demonstrate state-of-the-art reconstruction accuracy across all modalities, validating the efficacy of our geometry-aware paradigm.

本文提出了UniGS，一种基于三维高斯溅射（3D Gaussian Splatting）的统一地图表示与可微框架，用于高保真多模态三维重建。该框架集成了一条CUDA加速的光栅化管线，能够同时渲染照片级真实感的RGB图像、几何精确的深度图、一致的表面法线以及语义logits。我们重新设计了光栅化过程，通过可微的射线-椭球体交点计算方式来渲染深度，而非采用高斯中心，从而可通过解析深度梯度高效优化旋转和尺度属性。此外，我们推导了表面法线渲染的解析梯度公式，确保所重建三维场景之间的几何一致性。为提高计算与存储效率，我们引入了一种可学习属性，允许在训练过程中对贡献较小的高斯进行可微裁剪。定量与定性实验结果显示，我们的方法在各模态上均达到了当前最优的重建精度，有力验证了我们几何感知范式的有效性。
