### VizFlyt: Perception-centric Pedagogical Framework For Autonomous Aerial Robots

Autonomous aerial robots are becoming commonplace in our lives. Hands-on aerial robotics courses are pivotal in training the next-generation workforce to meet the growing market demands. Such an efficient and compelling course depends on a reliable testbed. In this paper, we present VizFlyt, an open-source perception-centric Hardware-In-The-Loop (HITL) photorealistic testing framework for aerial robotics courses. We utilize pose from an external localization system to hallucinate real-time and photorealistic visual sensors using 3D Gaussian Splatting. This enables stress-free testing of autonomy algorithms on aerial robots without the risk of crashing into obstacles. We achieve over 100Hz of system update rate. Lastly, we build upon our past experiences of offering hands-on aerial robotics courses and propose a new open-source and open-hardware curriculum based on VizFlyt for the future. We test our framework on various course projects in real-world HITL experiments and present the results showing the efficacy of such a system and its large potential use cases.

自主飞行机器人正在逐渐融入我们的生活。动手实践的飞行机器人课程对于培养下一代技术人才、满足日益增长的市场需求至关重要。而高效、吸引人的课程依赖于可靠的测试平台。
本文提出了VizFlyt，一个开源、以感知为中心的硬件在环（Hardware-In-The-Loop, HITL）真实感测试框架，专为飞行机器人课程设计。我们利用外部定位系统提供的位姿信息，通过三维高斯泼洒（3D Gaussian Splatting）实时生成高度真实感的视觉传感器数据，从而实现无风险地测试飞行机器人的自主算法，避免撞击障碍物的风险。系统更新频率超过100Hz。
基于我们以往开设飞行机器人实践课程的经验，本文进一步提出了一个基于VizFlyt的新型开源、开硬件课程体系，面向未来教学需求。我们在多个真实HITL实验项目中测试了该框架，并展示了其实验结果，验证了系统的有效性及其广泛的应用潜力。
