### LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering

3D Gaussian Splatting SLAM has emerged as a widely used technique for high-fidelity mapping in spatial intelligence. However, existing methods often rely on a single representation scheme, which limits their performance in large-scale dynamic outdoor scenes and leads to cumulative pose errors and scale ambiguity. To address these challenges, we propose \textbf{LVD-GS}, a novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human chain-of-thought process for information seeking, we introduce a hierarchical collaborative representation module that facilitates mutual reinforcement for mapping optimization, effectively mitigating scale drift and enhancing reconstruction robustness. Furthermore, to effectively eliminate the influence of dynamic objects, we propose a joint dynamic modeling module that generates fine-grained dynamic masks by fusing open-world segmentation with implicit residual constraints, guided by uncertainty estimates from DINO-Depth features. Extensive evaluations on KITTI, nuScenes, and self-collected datasets demonstrate that our approach achieves state-of-the-art performance compared to existing methods.

3D 高斯泼洒 SLAM 已成为空间智能中广泛应用的高保真建图技术。然而，现有方法通常依赖单一的表示方案，这在大规模动态户外场景中会限制其性能，导致位姿误差累积与尺度歧义。为了解决这些问题，我们提出了 **LVD-GS**，一种新颖的激光-视觉融合的 3D 高斯泼洒 SLAM 系统。受人类在信息搜索过程中“思维链”机制的启发，我们引入了层次化协同表示模块，实现了建图优化中的互补强化，有效缓解了尺度漂移问题并提升了重建的鲁棒性。此外，为了有效消除动态物体的干扰，我们提出了联合动态建模模块，通过融合开放世界分割与隐式残差约束，并结合 DINO-Depth 特征的不确定性估计，引导生成细粒度的动态掩码。在 KITTI、nuScenes 以及自采数据集上的大量实验表明，我们的方法在性能上全面超越现有方法，达到了最先进的水平。
