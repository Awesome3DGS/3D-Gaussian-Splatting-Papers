### Efficient representation of 3D spatial data for defense-related applications

Geospatial sensor data is essential for modern defense and security, offering indispensable 3D information for situational awareness. This data, gathered from sources like lidar sensors and optical cameras, allows for the creation of detailed models of operational environments. In this paper, we provide a comparative analysis of traditional representation methods, such as point clouds, voxel grids, and triangle meshes, alongside modern neural and implicit techniques like Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS). Our evaluation reveals a fundamental trade-off: traditional models offer robust geometric accuracy ideal for functional tasks like line-of-sight analysis and physics simulations, while modern methods excel at producing high-fidelity, photorealistic visuals but often lack geometric reliability. Based on these findings, we conclude that a hybrid approach is the most promising path forward. We propose a system architecture that combines a traditional mesh scaffold for geometric integrity with a neural representation like 3DGS for visual detail, managed within a hierarchical scene structure to ensure scalability and performance.

地理空间传感数据对于现代国防与安全至关重要，能够为态势感知提供不可或缺的三维信息。这类数据通常来自激光雷达传感器和光学相机等来源，可用于构建作战环境的高精度模型。本文对传统表示方法（如点云、体素网格和三角网格）与现代神经和隐式技术（如Neural Radiance Fields, NeRFs 和三维高斯投影 3D Gaussian Splatting, 3DGS）进行了对比分析。我们的评估揭示出一个基本的权衡关系：传统模型在几何精度方面更具优势，适用于视线分析、物理仿真等功能性任务，而现代方法则擅长生成高保真、照片级真实感的视觉效果，但通常缺乏几何可靠性。基于上述发现，我们认为混合式方法是未来最具前景的发展方向。我们提出了一种系统架构，将具有几何准确性的传统网格支架与用于视觉细节表达的神经表示（如3DGS）相结合，并通过分层场景结构进行管理，以保障系统的可扩展性与运行效率。
