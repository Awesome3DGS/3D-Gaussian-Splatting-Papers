### Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos

High-quality, animatable 3D human avatar reconstruction from monocular videos offers significant potential for reducing reliance on complex hardware, making it highly practical for applications in game development, augmented reality, and social media. However, existing methods still face substantial challenges in capturing fine geometric details and maintaining animation stability, particularly under dynamic or complex poses. To address these issues, we propose a novel real-time framework for animatable human avatar reconstruction based on 2D Gaussian Splatting (2DGS). By leveraging 2DGS and global SMPL pose parameters, our framework not only aligns positional and rotational discrepancies but also enables robust and natural pose-driven animation of the reconstructed avatars. Furthermore, we introduce a Rotation Compensation Network (RCN) that learns rotation residuals by integrating local geometric features with global pose parameters. This network significantly improves the handling of non-rigid deformations and ensures smooth, artifact-free pose transitions during animation. Experimental results demonstrate that our method successfully reconstructs realistic and highly animatable human avatars from monocular videos, effectively preserving fine-grained details while ensuring stable and natural pose variation. Our approach surpasses current state-of-the-art methods in both reconstruction quality and animation robustness on public benchmarks.

从单目视频中重建高质量、可动画的三维人体头像，具有显著潜力，有望减少对复杂硬件的依赖，在游戏开发、增强现实和社交媒体等应用中具备极高的实用性。然而，现有方法在捕捉精细几何细节以及在动态或复杂姿态下保持动画稳定性方面仍面临诸多挑战。
为应对这些问题，我们提出了一种基于二维高斯泼溅（2D Gaussian Splatting, 2DGS）的实时可动画人体头像重建新框架。该框架利用 2DGS 结合全局 SMPL 姿态参数，不仅实现了对位置与旋转误差的有效对齐，还支持对重建头像的鲁棒且自然的姿态驱动动画。
此外，我们引入了一个旋转补偿网络（Rotation Compensation Network, RCN），通过融合局部几何特征与全局姿态参数，学习旋转残差，从而显著提升对非刚性变形的处理能力，并确保动画过程中的姿态过渡平滑、无伪影。
实验结果表明，我们的方法能够从单目视频中成功重建出逼真且高度可动画的人体头像，兼顾精细细节的保留与姿态变化的稳定性。在多个公开基准测试中，我们的方法在重建质量与动画鲁棒性方面均优于当前最先进的方法。
