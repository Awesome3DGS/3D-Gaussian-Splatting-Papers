### MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction

We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian avatars from a single-view image. The main challenge lies in inferring unseen appearance and geometric details while ensuring 3D consistency and realism. Most previous methods rely on 2D diffusion models to synthesize unseen views; however, these generated views are sparse and inconsistent, resulting in unrealistic 3D artifacts and blurred appearance. To address these limitations, we leverage a generative avatar model, that can generate diverse 3D avatars by sampling deformed Gaussians from a learned prior distribution. Due to limited 3D training data, such a 3D model alone cannot capture all image details of unseen identities. Consequently, we integrate it as a prior, ensuring 3D consistency by projecting input images into its latent space and enforcing additional 3D appearance and geometric constraints. Our novel approach formulates Gaussian avatar creation as model inversion by fitting the generative avatar to synthetic views from 2D diffusion models. The generative avatar provides an initialization for model fitting, enforces 3D regularization, and helps in refining pose. Experiments show that our method surpasses state-of-the-art techniques and generalizes well to real-world scenarios. Our Gaussian avatars are also inherently animatable.

我们提出了 MoGA，这是一种从单视图图像重建高保真三维高斯头像的新方法。其主要挑战在于在保证三维一致性与真实感的同时，推断未见的外观和几何细节。以往大多数方法依赖二维扩散模型来合成未见视角，但这些生成的视角往往稀疏且不一致，导致三维伪影和外观模糊等不真实现象。为克服这些局限，我们利用生成头像模型，通过从学习到的先验分布中采样变形高斯来生成多样化的三维头像。由于三维训练数据有限，这类三维模型单独使用时无法捕捉所有未见身份的图像细节。因此，我们将其作为先验引入，通过将输入图像投影到其潜空间并施加额外的三维外观与几何约束来保证三维一致性。我们的新方法将高斯头像的生成形式化为模型反演过程，即将生成头像拟合到由二维扩散模型生成的合成视图上。生成头像不仅为模型拟合提供初始化，还能施加三维正则化并辅助姿态优化。实验表明，我们的方法优于现有最先进技术，并在真实场景中具有良好的泛化能力。此外，我们的高斯头像天然具有可动画性。
