### Holistic Large-Scale Scene Reconstruction via Mixed Gaussian Splatting

Recent advances in 3D Gaussian Splatting have shown remarkable potential for novel view synthesis. However, most existing large-scale scene reconstruction methods rely on the divide-and-conquer paradigm, which often leads to the loss of global scene information and requires complex parameter tuning due to scene partitioning and local optimization. To address these limitations, we propose MixGS, a novel holistic optimization framework for large-scale 3D scene reconstruction. MixGS models the entire scene holistically by integrating camera pose and Gaussian attributes into a view-aware representation, which is decoded into fine-detailed Gaussians. Furthermore, a novel mixing operation combines decoded and original Gaussians to jointly preserve global coherence and local fidelity. Extensive experiments on large-scale scenes demonstrate that MixGS achieves state-of-the-art rendering quality and competitive speed, while significantly reducing computational requirements, enabling large-scale scene reconstruction training on a single 24GB VRAM GPU.

近年来，3D Gaussian Splatting 在新视角合成方面展现出显著潜力。然而，大多数现有的大规模场景重建方法仍依赖于“分而治之”的范式，这种方式通常导致全局场景信息的丢失，并因场景划分与局部优化而需要复杂的参数调优。为了解决这些限制，我们提出了一种新颖的大规模三维场景重建整体优化框架——MixGS。MixGS 通过将相机位姿与高斯属性整合为一种面向视图的表示，实现对整个场景的整体建模，该表示随后被解码为具有精细细节的高斯点。此外，我们设计了一种新颖的混合操作，将解码后的高斯与原始高斯结合，有效地同时保持全局一致性与局部细节保真。我们在多个大规模场景上的广泛实验表明，MixGS 在保持先进渲染质量与具有竞争力的速度的同时，显著降低了计算资源需求，使得在单块 24GB 显存的 GPU 上训练大规模场景重建成为可能。
