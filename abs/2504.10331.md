### LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis

Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed data--such as RAW sensor inputs or multi-exposure sequences--which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality.

低光照场景中的新视角合成（Novel View Synthesis, NVS）由于输入图像存在严重噪声、低动态范围（LDR）以及初始化不可靠等问题，仍是一项极具挑战性的任务。尽管近年来基于 NeRF 的方法取得了一定进展，但大多数方法计算开销巨大，且部分依赖精心采集或预处理的数据（例如 RAW 传感器输入或多曝光序列），这在实际应用中极大限制了其实用性。
相比之下，3D Gaussian Splatting（3DGS）具备实时渲染能力，且可实现具有竞争力的视觉保真度。然而，现有基于 3DGS 的方法在面对低光照 sRGB 输入时表现不佳，常导致高斯初始化不稳定、噪声抑制无效等问题。
为应对上述挑战，我们提出了 LL-Gaussian，一种用于从低光照 sRGB 图像中进行三维重建与增强的新型框架，能够实现类正常光照条件下的新视角合成。该方法引入三项核心创新：通过端到端的低光照高斯初始化模块（LLGIM）借助学习驱动的多视角立体方法中的密集先验生成高质量初始点云；采用双分支的高斯分解模型，将场景的固有属性（如反射率与光照）与瞬时干扰进行解耦，优化过程稳定且具可解释性；利用结合物理约束与扩散模型先验的无监督优化策略，协同引导分解与增强过程。
此外，我们还构建了一个极端低光环境下采集的高挑战性数据集，并验证了 LL-Gaussian 的有效性。与现有最先进的 NeRF 方法相比，LL-Gaussian 在保持优越重建与渲染质量的同时，实现了高达 2000 倍的推理速度提升，训练时间缩短至仅 2%。
