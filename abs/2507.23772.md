### SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting

3D affordance reasoning, the task of associating human instructions with the functional regions of 3D objects, is a critical capability for embodied agents. Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited to single-object, single-step interactions, a paradigm that falls short of addressing the long-horizon, multi-object tasks required for complex real-world applications. To bridge this gap, we introduce the novel task of Sequential 3D Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale benchmark featuring 1800+ scenes to support research on long-horizon affordance understanding in complex 3DGS environments. We then propose SeqSplatNet, an end-to-end framework that directly maps an instruction to a sequence of 3D affordance masks. SeqSplatNet employs a large language model that autoregressively generates text interleaved with special segmentation tokens, guiding a conditional decoder to produce the corresponding 3D mask. To handle complex scene geometry, we introduce a pre-training strategy, Conditional Geometric Reconstruction, where the model learns to reconstruct complete affordance region masks from known geometric observations, thereby building a robust geometric prior. Furthermore, to resolve semantic ambiguities, we design a feature injection mechanism that lifts rich semantic features from 2D Vision Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales. Extensive experiments demonstrate that our method sets a new state-of-the-art on our challenging benchmark, effectively advancing affordance reasoning from single-step interactions to complex, sequential tasks at the scene level.

三维可供性推理（3D affordance reasoning）旨在将人类指令与三维物体的功能区域关联起来，是具身智能体的一项关键能力。当前基于 3D 高斯泼溅（3DGS）的方法，基本上局限于单物体、单步骤交互，这种范式难以满足复杂真实场景中长时序、多物体任务的需求。为弥补这一差距，我们提出了一项新的任务——顺序三维高斯可供性推理（Sequential 3D Gaussian Affordance Reasoning），并构建了 SeqAffordSplat，一个包含 1800+ 场景的大规模基准，用于支持在复杂 3DGS 环境中开展长时序可供性理解的研究。随后，我们提出了 SeqSplatNet，这是一个端到端框架，可将指令直接映射为一系列三维可供性掩码。SeqSplatNet 利用大语言模型自回归生成包含特殊分割标记的文本，引导条件解码器生成对应的三维掩码。为应对复杂场景几何，我们引入了条件几何重建（Conditional Geometric Reconstruction）预训练策略，使模型能够根据已知几何观测重建完整的可供性区域掩码，从而建立稳健的几何先验。此外，为解决语义歧义，我们设计了特征注入机制，将来自二维视觉基础模型（VFM）的丰富语义特征提升到三维解码器中，并在多尺度上进行融合。大量实验表明，我们的方法在具有挑战性的基准上刷新了最新性能记录，有效推动了可供性推理从单步交互发展到场景级的复杂顺序任务。
