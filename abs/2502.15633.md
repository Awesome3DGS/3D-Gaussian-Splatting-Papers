### RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes

3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Compared to commonly used depth maps, pointmaps include spatial relationships and scene geometry across multiple views, enabling robust camera pose estimation. Then, we propose integrating the estimated camera poses with 3DGS rendering as an end-to-end differentiable pipeline. Our method achieves simultaneous optimization of camera poses and 3DGS scene parameters, significantly enhancing system tracking accuracy. Specifically, we also design an adaptive scale mapper for the pointmap regression network, which provides more accurate pointmap mapping to the 3DGS map representation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8\% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis.

3D 高斯溅射（3DGS） 由于能够生成高保真的新视角，已成为 SLAM 领域的热门解决方案。然而，现有基于 3DGS 的方法主要针对室内场景，依赖 RGB-D 传感器 或 预训练的深度估计模型，因此在室外场景中的表现较差。
为了解决这一问题，我们提出 OpenGS-SLAM，一种针对无界室外场景的纯 RGB 高斯溅射 SLAM 方法。
在技术上，我们首先引入 点图（pointmap）回归网络，用于在不同帧之间生成一致的点图，以进行位姿估计。与常用的深度图相比，点图能够编码跨多个视角的空间关系和场景几何信息，从而实现更稳健的相机位姿估计。接着，我们提出将估计的相机位姿与 3DGS 渲染相结合，构建端到端可微分管线，实现相机位姿与 3DGS 场景参数的联合优化，显著提升系统的跟踪精度。此外，我们特别设计了一种自适应尺度映射器，用于点图回归网络，以提供更精确的点图到 3DGS 地图的映射。
在 Waymo 数据集上的实验表明，OpenGS-SLAM 将跟踪误差降低到现有 3DGS 方法的 9.8%，并在新视角合成任务上达到了最先进的性能。

