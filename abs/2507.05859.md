### D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos

Free-viewpoint video (FVV) enables immersive 3D experiences, but efficient compression of dynamic 3D representations remains a major challenge. Recent advances in 3D Gaussian Splatting (3DGS) and its dynamic extensions have enabled high-fidelity scene modeling. However, existing methods often couple scene reconstruction with optimization-dependent coding, which limits generalizability. This paper presents Feedforward Compression of Dynamic Gaussian Splatting (D-FCGS), a novel feedforward framework for compressing temporally correlated Gaussian point cloud sequences. Our approach introduces a Group-of-Frames (GoF) structure with I-P frame coding, where inter-frame motions are extracted via sparse control points. The resulting motion tensors are compressed in a feedforward manner using a dual prior-aware entropy model that combines hyperprior and spatial-temporal priors for accurate rate estimation. For reconstruction, we perform control-point-guided motion compensation and employ a refinement network to enhance view-consistent fidelity. Trained on multi-view video-derived Gaussian frames, D-FCGS generalizes across scenes without per-scene optimization. Experiments show that it matches the rate-distortion performance of optimization-based methods, achieving over 40 times compression in under 2 seconds while preserving visual quality across viewpoints. This work advances feedforward compression for dynamic 3DGS, paving the way for scalable FVV transmission and storage in immersive applications.

自由视角视频（Free-viewpoint Video, FVV）能够带来沉浸式的三维体验，但高效压缩动态三维表示仍然是一大挑战。近年来，三维高斯溅射（3D Gaussian Splatting, 3DGS）及其动态扩展在高保真场景建模方面取得了显著进展。然而，现有方法通常将场景重建与依赖优化的编码过程耦合，限制了通用性。本文提出了 **D-FCGS**（Feedforward Compression of Dynamic Gaussian Splatting），一种用于压缩时间相关的高斯点云序列的新型前馈框架。我们引入了基于帧组（Group-of-Frames, GoF）的 I-P 帧编码结构，其中帧间运动通过稀疏控制点提取。所得的运动张量通过结合超先验（hyperprior）和时空先验（spatial-temporal priors）的双先验感知熵模型，以前馈方式进行压缩，从而实现精确的码率估计。在重建阶段，我们采用基于控制点的运动补偿，并引入细化网络以提升视图一致的保真度。D-FCGS 在多视图视频生成的高斯帧数据上进行训练，无需针对每个场景单独优化即可实现跨场景泛化。实验结果表明，该方法在码率失真性能上可与基于优化的方法相媲美，在不到 2 秒的时间内实现超过 40 倍的压缩率，同时保持跨视角的视觉质量。该研究推动了动态 3DGS 的前馈压缩发展，为沉浸式应用中 FVV 的可扩展传输与存储奠定了基础。
