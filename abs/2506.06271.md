### BecomingLit: Relightable Gaussian Avatars with Hybrid Neural Shading

We introduce BecomingLit, a novel method for reconstructing relightable, high-resolution head avatars that can be rendered from novel viewpoints at interactive rates. Therefore, we propose a new low-cost light stage capture setup, tailored specifically towards capturing faces. Using this setup, we collect a novel dataset consisting of diverse multi-view sequences of numerous subjects under varying illumination conditions and facial expressions. By leveraging our new dataset, we introduce a new relightable avatar representation based on 3D Gaussian primitives that we animate with a parametric head model and an expression-dependent dynamics module. We propose a new hybrid neural shading approach, combining a neural diffuse BRDF with an analytical specular term. Our method reconstructs disentangled materials from our dynamic light stage recordings and enables all-frequency relighting of our avatars with both point lights and environment maps. In addition, our avatars can easily be animated and controlled from monocular videos. We validate our approach in extensive experiments on our dataset, where we consistently outperform existing state-of-the-art methods in relighting and reenactment by a significant margin.

我们提出了 BecomingLit，一种用于重建可重光照的高分辨率头像角色的新方法，该方法支持从新视角进行交互式渲染。为此，我们设计了一种面向人脸捕捉的低成本光照舞台采集系统，并基于该系统采集了一个全新数据集，包含多个主体在不同光照条件和面部表情下的多视角序列。
基于该数据集，我们提出了一种基于三维高斯图元（3D Gaussian primitives）的可重光照头像表示方法，并通过参数化头部模型和表情相关的动态模块进行驱动。我们还提出了一种混合神经着色方法，将神经漫反射 BRDF 与解析高光项相结合，实现更真实的外观建模。
该方法能够从动态光照舞台采集数据中重建解耦的材质表示，并支持在点光源与环境光图下进行全频率重光照。此外，我们的头像模型也能通过单目视频轻松驱动和控制。
我们在自建数据集上进行了大量实验，结果表明，在重光照与驱动再现任务中，BecomingLit 在各项指标上均显著优于现有最先进方法。
