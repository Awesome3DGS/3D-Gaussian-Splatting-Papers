### PartRM: Modeling Part-Level Dynamics with Large Cross-State Reconstruction Model

As interest grows in world models that predict future states from current observations and actions, accurately modeling part-level dynamics has become increasingly relevant for various applications. Existing approaches, such as Puppet-Master, rely on fine-tuning large-scale pre-trained video diffusion models, which are impractical for real-world use due to the limitations of 2D video representation and slow processing times. To overcome these challenges, we present PartRM, a novel 4D reconstruction framework that simultaneously models appearance, geometry, and part-level motion from multi-view images of a static object. PartRM builds upon large 3D Gaussian reconstruction models, leveraging their extensive knowledge of appearance and geometry in static objects. To address data scarcity in 4D, we introduce the PartDrag-4D dataset, providing multi-view observations of part-level dynamics across over 20,000 states. We enhance the model's understanding of interaction conditions with a multi-scale drag embedding module that captures dynamics at varying granularities. To prevent catastrophic forgetting during fine-tuning, we implement a two-stage training process that focuses sequentially on motion and appearance learning. Experimental results show that PartRM establishes a new state-of-the-art in part-level motion learning and can be applied in manipulation tasks in robotics.

随着对能够根据当前观测与动作预测未来状态的世界模型的关注不断增长，准确建模部件级别的动态在多个应用中变得愈发重要。现有方法（如 Puppet-Master）依赖对大规模预训练视频扩散模型的微调，但由于二维视频表示的局限性和处理速度缓慢，在现实世界中难以实际应用。
为克服这些挑战，我们提出了 PartRM，这是一种新颖的四维重建框架，能够同时建模静态物体的外观、几何结构以及部件级别的运动。PartRM 构建于大型三维高斯重建模型之上，利用其在静态物体外观与几何方面的丰富知识。为缓解 4D 数据稀缺的问题，我们引入了 PartDrag-4D 数据集，提供涵盖两万多个状态的部件级动态多视角观测数据。
我们还通过多尺度拖拽嵌入模块增强模型对交互条件的理解，该模块可捕捉不同粒度下的动态变化。为防止在微调过程中发生灾难性遗忘，我们设计了一个两阶段训练过程，依次聚焦于运动学习与外观学习。
实验结果表明，PartRM 在部件级运动学习方面达到了新的最先进水平，并可应用于机器人操作任务中。
