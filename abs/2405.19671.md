### GaussianRoom: Improving 3D Gaussian Splatting with SDF Guidance and Monocular Cues for Indoor Scene Reconstruction

Recently, 3D Gaussian Splatting(3DGS) has revolutionized neural rendering with its high-quality rendering and real-time speed. However, when it comes to indoor scenes with a significant number of textureless areas, 3DGS yields incomplete and noisy reconstruction results due to the poor initialization of the point cloud and under-constrained optimization. Inspired by the continuity of signed distance field (SDF), which naturally has advantages in modeling surfaces, we present a unified optimizing framework integrating neural SDF with 3DGS. This framework incorporates a learnable neural SDF field to guide the densification and pruning of Gaussians, enabling Gaussians to accurately model scenes even with poor initialized point clouds. At the same time, the geometry represented by Gaussians improves the efficiency of the SDF field by piloting its point sampling. Additionally, we regularize the optimization with normal and edge priors to eliminate geometry ambiguity in textureless areas and improve the details. Extensive experiments in ScanNet and ScanNet++ show that our method achieves state-of-the-art performance in both surface reconstruction and novel view synthesis.

近期，三维高斯溅射（3DGS）以其高质量的渲染和实时速度革新了神经渲染技术。然而，当涉及到内部场景中有大量无纹理区域的情况时，由于点云的初始化不良和优化受限，3DGS会产生不完整和嘈杂的重建结果。受到符号距离场（SDF）连续性的启发，该场自然在建模表面方面具有优势，我们提出了一个将神经SDF与3DGS整合的统一优化框架。该框架整合了一个可学习的神经SDF场，以指导高斯体的密集化和修剪，使高斯体能够准确地建模即使是初始化较差的点云的场景。同时，由高斯体表示的几何形状通过引导其点采样来提高SDF场的效率。此外，我们还用法线和边缘先验规范优化，以消除无纹理区域中的几何模糊并改善细节。在ScanNet和ScanNet++数据集上进行的广泛实验表明，我们的方法在表面重建和新视角合成方面均达到了最先进的性能。
