### StructGS: Adaptive Spherical Harmonics and Rendering Enhancements for Superior 3D Gaussian Splatting

Recent advancements in 3D reconstruction coupled with neural rendering techniques have greatly improved the creation of photo-realistic 3D scenes, influencing both academic research and industry applications. The technique of 3D Gaussian Splatting and its variants incorporate the strengths of both primitive-based and volumetric representations, achieving superior rendering quality. While 3D Geometric Scattering (3DGS) and its variants have advanced the field of 3D representation, they fall short in capturing the stochastic properties of non-local structural information during the training process. Additionally, the initialisation of spherical functions in 3DGS-based methods often fails to engage higher-order terms in early training rounds, leading to unnecessary computational overhead as training progresses. Furthermore, current 3DGS-based approaches require training on higher resolution images to render higher resolution outputs, significantly increasing memory demands and prolonging training durations. We introduce StructGS, a framework that enhances 3D Gaussian Splatting (3DGS) for improved novel-view synthesis in 3D reconstruction. StructGS innovatively incorporates a patch-based SSIM loss, dynamic spherical harmonics initialisation and a Multi-scale Residual Network (MSRN) to address the above-mentioned limitations, respectively. Our framework significantly reduces computational redundancy, enhances detail capture and supports high-resolution rendering from low-resolution inputs. Experimentally, StructGS demonstrates superior performance over state-of-the-art (SOTA) models, achieving higher quality and more detailed renderings with fewer artifacts.

近年来，三维重建技术结合神经渲染方法，极大地提升了照片级真实感三维场景的构建能力，对学术研究和工业应用均产生了深远影响。**三维高斯散点（3D Gaussian Splatting, 3DGS）**及其变体结合了基元（primitive-based）表示和体素（volumetric）表示的优势，实现了卓越的渲染质量。
尽管 3DGS 及其变体 在 三维表示 领域取得了重要进展，但在训练过程中，它们未能充分捕捉非局部结构信息的随机特性。此外，3DGS 方法中球函数（spherical functions）的初始化通常在训练初期无法有效激活高阶项，导致训练过程中不必要的计算开销。此外，当前基于 3DGS 的方法需要在高分辨率图像上训练才能生成高分辨率的输出，这显著增加了内存需求并延长了训练时间。
为了解决这些问题，我们提出 StructGS，一个针对 三维重建中新视角合成（novel-view synthesis） 进行增强的 3DGS 框架。StructGS 通过块级 SSIM 损失（patch-based SSIM loss）、动态球谐函数初始化（dynamic spherical harmonics initialization）和多尺度残差网络（Multi-scale Residual Network, MSRN），分别解决了上述限制。我们的框架有效降低计算冗余，增强细节捕捉，并支持从低分辨率输入渲染高分辨率输出。
实验结果表明，StructGS 在多个基准测试中超越**当前最先进（SOTA）**方法，在渲染质量和细节保留方面均表现出色，同时减少了伪影。
