### Avat3r: Large Animatable Gaussian Reconstruction Model for High-fidelity 3D Head Avatars

Traditionally, creating photo-realistic 3D head avatars requires a studio-level multi-view capture setup and expensive optimization during test-time, limiting the use of digital human doubles to the VFX industry or offline renderings.
To address this shortcoming, we present Avat3r, which regresses a high-quality and animatable 3D head avatar from just a few input images, vastly reducing compute requirements during inference. More specifically, we make Large Reconstruction Models animatable and learn a powerful prior over 3D human heads from a large multi-view video dataset. For better 3D head reconstructions, we employ position maps from DUSt3R and generalized feature maps from the human foundation model Sapiens. To animate the 3D head, our key discovery is that simple cross-attention to an expression code is already sufficient. Finally, we increase robustness by feeding input images with different expressions to our model during training, enabling the reconstruction of 3D head avatars from inconsistent inputs, e.g., an imperfect phone capture with accidental movement, or frames from a monocular video.
We compare Avat3r with current state-of-the-art methods for few-input and single-input scenarios, and find that our method has a competitive advantage in both tasks. Finally, we demonstrate the wide applicability of our proposed model, creating 3D head avatars from images of different sources, smartphone captures, single images, and even out-of-domain inputs like antique busts.

传统上，创建逼真的 3D 头像模型需要使用专业级的多视角捕捉设备，并在测试阶段进行昂贵的优化，这限制了数字人双胞胎技术的应用范围，仅能用于视觉特效（VFX）行业或离线渲染。
为了解决这一局限性，我们提出了 Avat3r，该方法能够仅凭少量输入图像回归出高质量且可动画化的 3D 头像模型，大幅降低推理时的计算成本。具体而言，我们使大规模重建模型（Large Reconstruction Models）具备动画能力，并从大规模多视角视频数据集中学习了强大的 3D 人头先验。为了实现更高质量的 3D 头部重建，我们结合了 DUSt3R 提供的位置映射（position maps）以及人类基础模型 Sapiens 的通用特征映射（generalized feature maps）。
在 3D 头部动画化方面，我们的关键发现是：简单的跨注意力（cross-attention）机制应用于表情编码（expression code）即可实现高效的动画驱动。此外，为了增强鲁棒性，我们在训练过程中输入了具有不同表情的图像，使模型能够从不一致的输入数据中重建 3D 头像，例如因意外运动导致的手机拍摄误差，或是单目视频中的不同帧图像。
我们将 Avat3r 与当前最先进的少量输入和单输入 3D 头像重建方法进行了比较，结果表明，我们的方法在这两种任务上均具有竞争优势。最后，我们展示了 Avat3r 的广泛适用性，它能够从不同来源的图像（如智能手机拍摄、单张图片，甚至是古代雕像）生成高质量的 3D 头像模型。
