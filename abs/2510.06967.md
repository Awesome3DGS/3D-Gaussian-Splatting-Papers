### Generating Surface for Text-to-3D using 2D Gaussian Splatting

Recent advancements in Text-to-3D modeling have shown significant potential for the creation of 3D content. However, due to the complex geometric shapes of objects in the natural world, generating 3D content remains a challenging task. Current methods either leverage 2D diffusion priors to recover 3D geometry, or train the model directly based on specific 3D representations. In this paper, we propose a novel method named DirectGaussian, which focuses on generating the surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize conditional text generation models and the surface of a 3D object is rendered by 2D Gaussian splatting with multi-view normal and texture priors. For multi-view geometric consistency problems, DirectGaussian incorporates curvature constraints on the generated surface during optimization process. Through extensive experiments, we demonstrate that our framework is capable of achieving diverse and high-fidelity 3D content creation.

近年来，Text-to-3D（文本生成三维）建模取得了显著进展，在三维内容创作方面展现出巨大潜力。然而，由于自然界中物体几何形状的复杂性，生成高质量三维内容依然是一项挑战。目前的方法主要采用两种策略：一是借助二维扩散先验来恢复三维几何，二是直接基于特定的三维表示形式对模型进行训练。本文提出了一种新方法，名为 DirectGaussian，专注于以面元（surfels）为表示形式生成三维物体表面。在 DirectGaussian 中，我们利用条件文本生成模型，并通过结合多视角法线与纹理先验，以二维高斯泼溅方式对三维物体表面进行渲染。针对多视角几何一致性问题，DirectGaussian 在优化过程中引入了曲率约束，以提升生成表面的结构连贯性。通过大量实验，我们验证了该框架在多样化与高保真三维内容生成方面的强大能力。
