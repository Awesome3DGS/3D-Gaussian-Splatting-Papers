### DGE: Direct Gaussian 3D Editing by Consistent Multi-view Editing

We consider the problem of editing 3D objects and scenes based on open-ended language instructions. The established paradigm to solve this problem is to use a 2D image generator or editor to guide the 3D editing process. However, this is often slow as it requires do update a computationally expensive 3D representations such as a neural radiance field, and to do so by using contradictory guidance from a 2D model which is inherently not multi-view consistent. We thus introduce the Direct Gaussian Editor (DGE), a method that addresses these issues in two ways. First, we modify a given high-quality image editor like InstructPix2Pix to be multi-view consistent. We do so by utilizing a training-free approach which integrates cues from the underlying 3D geometry of the scene. Second, given a multi-view consistent edited sequence of images of the object, we directly and efficiently optimize the 3D object representation, which is based on 3D Gaussian Splatting. Because it does not require to apply edits incrementally and iteratively, DGE is significantly more efficient than existing approaches, and comes with other perks such as allowing selective editing of parts of the scene.

我们考虑了基于开放式语言指令编辑3D对象和场景的问题。解决这个问题的传统范式是使用2D图像生成器或编辑器来指导3D编辑过程。然而，这通常较慢，因为它需要更新如神经辐射场这样的计算成本高昂的3D表示，并且还需使用本质上不具备多视图一致性的2D模型提供的矛盾指导。因此，我们引入了直接高斯编辑器（DGE），这是一种以两种方式解决这些问题的方法。首先，我们修改了像InstructPix2Pix这样的高质量图像编辑器，使其具有多视图一致性。我们通过使用一种无需训练的方法实现，该方法整合了场景底层3D几何的线索。其次，给定一个多视图一致的编辑过的对象图像序列，我们直接且高效地优化基于3D高斯喷溅的3D对象表示。由于DGE不需要逐步和迭代地应用编辑，它比现有方法更加高效，并且还具有其他优点，如允许选择性编辑场景的部分。
