### Complete Gaussian Splats from a Single Image with Denoising Diffusion Models

Gaussian splatting typically requires dense observations of the scene and can fail to reconstruct occluded and unobserved areas. We propose a latent diffusion model to reconstruct a complete 3D scene with Gaussian splats, including the occluded parts, from only a single image during inference. Completing the unobserved surfaces of a scene is challenging due to the ambiguity of the plausible surfaces. Conventional methods use a regression-based formulation to predict a single "mode" for occluded and out-of-frustum surfaces, leading to blurriness, implausibility, and failure to capture multiple possible explanations. Thus, they often address this problem partially, focusing either on objects isolated from the background, reconstructing only visible surfaces, or failing to extrapolate far from the input views. In contrast, we propose a generative formulation to learn a distribution of 3D representations of Gaussian splats conditioned on a single input image. To address the lack of ground-truth training data, we propose a Variational AutoReconstructor to learn a latent space only from 2D images in a self-supervised manner, over which a diffusion model is trained. Our method generates faithful reconstructions and diverse samples with the ability to complete the occluded surfaces for high-quality 360-degree renderings.

高斯点绘通常需要对场景进行密集观测，但在重建被遮挡或未观测区域时往往失败。我们提出了一种潜在扩散模型，在推理阶段仅需一张图像即可利用高斯点绘重建完整的三维场景，包括被遮挡的部分。补全场景中未观测表面是一个挑战，因为合理表面存在多重歧义。传统方法采用基于回归的建模方式，对被遮挡或视锥外表面预测单一“模式”，这通常导致模糊、不合理，且无法捕捉多种可能性。因此，这类方法往往只能部分解决问题，例如仅针对从背景中分离的物体、只重建可见表面，或无法从输入视角进行远距离外推。相比之下，我们提出了一种生成式建模方法，学习在单张输入图像条件下高斯点绘的三维表示分布。为应对缺乏真实训练数据的问题，我们提出了一种变分自编码重建器（Variational AutoReconstructor），仅利用二维图像以自监督方式学习潜在空间，并在其上训练扩散模型。我们的方法能够生成真实可信的重建结果和多样化样本，并具备补全遮挡表面的能力，从而实现高质量的全景（360 度）渲染。
