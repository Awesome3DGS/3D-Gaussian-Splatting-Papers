### SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians

Accurate, real-time 3D reconstruction of human heads from monocular images and videos underlies numerous visual applications. As 3D ground truth data is hard to come by at scale, previous methods have sought to learn from abundant 2D videos in a self-supervised manner. Typically, this involves the use of differentiable mesh rendering, which is effective but faces limitations. To improve on this, we propose SHeaP (Self-supervised Head Geometry Predictor Learned via 2D Gaussians). Given a source image, we predict a 3DMM mesh and a set of Gaussians that are rigged to this mesh. We then reanimate this rigged head avatar to match a target frame, and backpropagate photometric losses to both the 3DMM and Gaussian prediction networks. We find that using Gaussians for rendering substantially improves the effectiveness of this self-supervised approach. Training solely on 2D data, our method surpasses existing self-supervised approaches in geometric evaluations on the NoW benchmark for neutral faces and a new benchmark for non-neutral expressions. Our method also produces highly expressive meshes, outperforming state-of-the-art in emotion classification.

从单目图像和视频中实现精准、实时的三维人头重建是众多视觉应用的基础。然而，由于大规模三维标注数据难以获取，现有方法通常依赖自监督学习，从大量二维视频中学习三维结构，常用技术包括可微分的网格渲染。尽管这一方案在一定程度上取得了成功，但仍面临表达能力受限等问题。
为此，我们提出 SHeaP，一种基于二维高斯渲染的自监督人头几何学习方法。在输入一张源图像后，模型会预测一个三维形变模型（3D Morphable Model, 3DMM）网格及其绑定的一组二维高斯表示。随后，我们将该绑定人头化身重新驱动，使其与目标帧中的人脸姿态一致，并通过光度损失对 3DMM 和高斯预测网络进行联合反向传播。
我们发现，相较于传统网格渲染，使用二维高斯进行渲染可显著提升自监督训练的效果。在仅使用二维数据进行训练的设定下，SHeaP 在中性面孔的 NoW 基准测试和一个涵盖非中性表情的新测试集上，均在几何评估指标上优于现有自监督方法。同时，我们方法生成的人头网格具有更强的表情表现力，在情绪识别任务中也超越当前最先进技术，展现出对细腻面部变化的高保真建模能力。
