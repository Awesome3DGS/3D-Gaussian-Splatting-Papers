### Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation

Recent advances in text-to-image diffusion models have been driven by the increasing availability of paired 2D data. However, the development of 3D diffusion models has been hindered by the scarcity of high-quality 3D data, resulting in less competitive performance compared to their 2D counterparts. To address this challenge, we propose repurposing pre-trained 2D diffusion models for 3D object generation. We introduce Gaussian Atlas, a novel representation that utilizes dense 2D grids, enabling the fine-tuning of 2D diffusion models to generate 3D Gaussians. Our approach demonstrates successful transfer learning from a pre-trained 2D diffusion model to a 2D manifold flattened from 3D structures. To support model training, we compile GaussianVerse, a large-scale dataset comprising 205K high-quality 3D Gaussian fittings of various 3D objects. Our experimental results show that text-to-image diffusion models can be effectively adapted for 3D content generation, bridging the gap between 2D and 3D modeling.

近年来，文本到图像的扩散模型（text-to-image diffusion models）取得了显著进展，主要得益于配对 2D 数据 的不断增加。然而，3D 扩散模型的发展受限于高质量 3D 数据 的匮乏，导致其与 2D 模型相比性能较为逊色。为了解决这一挑战，我们提出了将预训练的 2D 扩散模型重新用于 3D 物体生成的方法。
我们引入了 Gaussian Atlas，一种新的表示方式，利用密集的 2D 网格，使得 2D 扩散模型能够微调以生成 3D 高斯点。我们的方法展示了从预训练的 2D 扩散模型到从 3D 结构展开的 2D 流形的成功迁移学习。为了支持模型训练，我们编制了 GaussianVerse，一个大规模数据集，包含了 205K 个高质量的 3D 高斯拟合数据，涵盖各种 3D 物体。
实验结果表明，文本到图像的扩散模型可以有效地适应 3D 内容生成，从而弥合了 2D 和 3D 建模之间的差距。
