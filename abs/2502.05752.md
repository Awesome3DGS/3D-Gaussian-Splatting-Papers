### PINGS: Gaussian Splatting Meets Distance Fields within a Point-Based Implicit Neural Map

Robots require high-fidelity reconstructions of their environment for effective operation. Such scene representations should be both, geometrically accurate and photorealistic to support downstream tasks. While this can be achieved by building distance fields from range sensors and radiance fields from cameras, the scalable incremental mapping of both fields consistently and at the same time with high quality remains challenging. In this paper, we propose a novel map representation that unifies a continuous signed distance field and a Gaussian splatting radiance field within an elastic and compact point-based implicit neural map. By enforcing geometric consistency between these fields, we achieve mutual improvements by exploiting both modalities. We devise a LiDAR-visual SLAM system called PINGS using the proposed map representation and evaluate it on several challenging large-scale datasets. Experimental results demonstrate that PINGS can incrementally build globally consistent distance and radiance fields encoded with a compact set of neural points. Compared to the state-of-the-art methods, PINGS achieves superior photometric and geometric rendering at novel views by leveraging the constraints from the distance field. Furthermore, by utilizing dense photometric cues and multi-view consistency from the radiance field, PINGS produces more accurate distance fields, leading to improved odometry estimation and mesh reconstruction.

机器人需要对其环境进行高保真重建，以实现有效的操作。这样的场景表示应该在几何上准确，并且在视觉上逼真，以支持后续任务。虽然通过从激光雷达传感器构建距离场和通过摄像头构建辐射场可以实现这一目标，但同时高质量且可扩展的增量化映射这两种场景表示仍然是一个挑战。本文提出了一种新型的地图表示方法，它将连续的符号距离场和高斯点云辐射场统一到一个弹性且紧凑的基于点的隐式神经地图中。通过强制这两种场景表示之间的几何一致性，我们通过利用这两种模式相互促进，取得了共同的改进。我们设计了一种名为PINGS的激光雷达-视觉SLAM系统，使用提出的地图表示，并在多个具有挑战性的、大规模数据集上进行了评估。实验结果表明，PINGS能够增量地构建全局一致的距离场和辐射场，并用一组紧凑的神经点进行编码。与最先进的方法相比，PINGS通过利用距离场的约束，在新视角下实现了更优的光度和几何渲染。此外，通过利用来自辐射场的密集光度线索和多视角一致性，PINGS能够生成更准确的距离场，从而改善了里程计估计和网格重建。
