### Pushing Rendering Boundaries: Hard Gaussian Splatting

3D Gaussian Splatting (3DGS) has demonstrated impressive Novel View Synthesis (NVS) results in a real-time rendering manner. During training, it relies heavily on the average magnitude of view-space positional gradients to grow Gaussians to reduce rendering loss. However, this average operation smooths the positional gradients from different viewpoints and rendering errors from different pixels, hindering the growth and optimization of many defective Gaussians. This leads to strong spurious artifacts in some areas. To address this problem, we propose Hard Gaussian Splatting, dubbed HGS, which considers multi-view significant positional gradients and rendering errors to grow hard Gaussians that fill the gaps of classical Gaussian Splatting on 3D scenes, thus achieving superior NVS results. In detail, we present positional gradient driven HGS, which leverages multi-view significant positional gradients to uncover hard Gaussians. Moreover, we propose rendering error guided HGS, which identifies noticeable pixel rendering errors and potentially over-large Gaussians to jointly mine hard Gaussians. By growing and optimizing these hard Gaussians, our method helps to resolve blurring and needle-like artifacts. Experiments on various datasets demonstrate that our method achieves state-of-the-art rendering quality while maintaining real-time efficiency.

3D高斯点云（3D Gaussian Splatting, 3DGS）在实时渲染环境下展示了令人印象深刻的新视角合成（Novel View Synthesis, NVS）效果。在训练过程中，它严重依赖视角空间位置梯度平均幅值来扩展高斯点云以减少渲染损失。然而，这种平均操作会平滑来自不同视点的位置梯度和不同像素的渲染误差，从而阻碍许多有缺陷高斯点云的生长和优化。这导致某些区域出现明显的伪影。为了解决这个问题，我们提出了一种称为硬高斯点云（Hard Gaussian Splatting, HGS）的方法，该方法通过考虑多视角显著位置梯度和渲染误差，生成硬高斯点云，填补经典高斯点云在3D场景中的空白，从而实现更优的新视角合成效果。
具体来说，我们提出了基于位置梯度驱动的HGS方法，该方法利用多视角显著位置梯度来发现硬高斯点云。此外，我们还提出了基于渲染误差引导的HGS方法，通过识别显著像素渲染误差以及潜在的过大的高斯点云，联合挖掘硬高斯点云。通过扩展和优化这些硬高斯点云，我们的方法有效解决了模糊和针状伪影问题。多种数据集上的实验表明，该方法在保持实时效率的同时，实现了最新的渲染质量。
