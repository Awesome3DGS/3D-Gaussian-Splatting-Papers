### Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting

Self-supervised learning (SSL) for point cloud pre-training has become a cornerstone for many 3D vision tasks, enabling effective learning from large-scale unannotated data. At the scene level, existing SSL methods often incorporate volume rendering into the pre-training framework, using RGB-D images as reconstruction signals to facilitate cross-modal learning. This strategy promotes alignment between 2D and 3D modalities and enables the model to benefit from rich visual cues in the RGB-D inputs. However, these approaches are limited by their reliance on implicit scene representations and high memory demands. Furthermore, since their reconstruction objectives are applied only in 2D space, they often fail to capture underlying 3D geometric structures. To address these challenges, we propose Gaussian2Scene, a novel scene-level SSL framework that leverages the efficiency and explicit nature of 3D Gaussian Splatting (3DGS) for pre-training. The use of 3DGS not only alleviates the computational burden associated with volume rendering but also supports direct 3D scene reconstruction, thereby enhancing the geometric understanding of the backbone network. Our approach follows a progressive two-stage training strategy. In the first stage, a dual-branch masked autoencoder learns both 2D and 3D scene representations. In the second stage, we initialize training with reconstructed point clouds and further supervise learning using the geometric locations of Gaussian primitives and rendered RGB images. This process reinforces both geometric and cross-modal learning. We demonstrate the effectiveness of Gaussian2Scene across several downstream 3D object detection tasks, showing consistent improvements over existing pre-training methods.

点云自监督学习（Self-supervised learning, SSL）在预训练中的应用已成为众多 3D 视觉任务的基石，使得模型能够高效地从大规模无标注数据中学习。在场景级别，现有的 SSL 方法通常将体渲染（volume rendering）引入预训练框架中，并利用 RGB-D 图像作为重建信号，以促进跨模态学习。这一策略有助于实现 2D 与 3D 模态的对齐，并使模型能够从 RGB-D 输入中丰富的视觉线索中获益。然而，这类方法受限于对隐式场景表示的依赖以及较高的内存需求。此外，由于其重建目标仅在二维空间中施加，往往难以有效捕捉潜在的三维几何结构。
为解决上述问题，我们提出 Gaussian2Scene，一种新颖的场景级 SSL 框架，在预训练中利用 3D 高斯点渲染（3D Gaussian Splatting, 3DGS） 的高效性与显式特性。3DGS 的引入不仅缓解了体渲染所带来的计算负担，还支持直接的三维场景重建，从而增强主干网络对几何信息的理解。
我们的方法采用渐进式的两阶段训练策略：
第一阶段，使用双分支的掩码自编码器（masked autoencoder）同时学习二维与三维场景表示；
第二阶段，以重建的点云初始化训练，并进一步利用高斯基元（Gaussian primitives）的几何位置以及渲染得到的 RGB 图像进行监督，从而同时强化几何学习与跨模态学习。
在多个下游的三维目标检测任务中，我们验证了 Gaussian2Scene 的有效性，并在性能上持续优于现有的预训练方法。
