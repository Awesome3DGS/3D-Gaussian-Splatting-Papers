### Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework

This paper proposes an efficient 3D avatar coding framework that leverages compact human priors and canonical-to-target transformation to enable high-quality 3D human avatar video compression at ultra-low bit rates. The framework begins by training a canonical Gaussian avatar using articulated splatting in a network-free manner, which serves as the foundation for avatar appearance modeling. Simultaneously, a human-prior template is employed to capture temporal body movements through compact parametric representations. This decomposition of appearance and temporal evolution minimizes redundancy, enabling efficient compression: the canonical avatar is shared across the sequence, requiring compression only once, while the temporal parameters, consisting of just 94 parameters per frame, are transmitted with minimal bit-rate. For each frame, the target human avatar is generated by deforming canonical avatar via Linear Blend Skinning transformation, facilitating temporal coherent video reconstruction and novel view synthesis. Experimental results demonstrate that the proposed method significantly outperforms conventional 2D/3D codecs and existing learnable dynamic 3D Gaussian splatting compression method in terms of rate-distortion performance on mainstream multi-view human video datasets, paving the way for seamless immersive multimedia experiences in meta-verse applications.

本文提出了一种高效的三维虚拟人编码框架，利用紧凑的人体先验与标准到目标的变换机制，实现了在超低比特率下的高质量三维虚拟人视频压缩。该框架首先通过无网络的关节高斯泼溅方式训练出标准高斯虚拟人，用于建模人物外观。与此同时，引入人体先验模板，通过紧凑的参数化表示捕捉时间维度上的身体运动。该种对外观与时间演化的分离建模有效减少了冗余，从而实现高效压缩：标准虚拟人在整个序列中共享，仅需压缩一次；而每帧仅需传输94个时间参数，极大降低了码率。每帧的目标虚拟人通过线性混合蒙皮（Linear Blend Skinning）对标准虚拟人进行形变生成，从而实现时间连贯的视频重建与新视角合成。实验结果表明，该方法在主流多视角人体视频数据集上，相较传统2D/3D编解码器和现有可学习的动态三维高斯泼溅压缩方法，在码率-失真表现方面具有显著优势，为元宇宙应用中的沉浸式多媒体体验铺平了道路。
