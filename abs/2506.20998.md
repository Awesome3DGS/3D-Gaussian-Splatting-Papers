### DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting

Novel view synthesis is a task of generating scenes from unseen perspectives; however, synthesizing dynamic scenes from blurry monocular videos remains an unresolved challenge that has yet to be effectively addressed. Existing novel view synthesis methods are often constrained by their reliance on high-resolution images or strong assumptions about static geometry and rigid scene priors. Consequently, their approaches lack robustness in real-world environments with dynamic object and camera motion, leading to instability and degraded visual fidelity. To address this, we propose Motion-aware Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting (DBMovi-GS), a method designed for dynamic view synthesis from blurry monocular videos. Our model generates dense 3D Gaussians, restoring sharpness from blurry videos and reconstructing detailed 3D geometry of the scene affected by dynamic motion variations. Our model achieves robust performance in novel view synthesis under dynamic blurry scenes and sets a new benchmark in realistic novel view synthesis for blurry monocular video inputs.

新视角合成（Novel View Synthesis）旨在从未见过的视角生成场景。然而，从模糊的单目视频中合成动态场景仍是一个尚未被有效解决的难题。现有的新视角合成方法通常依赖高分辨率图像或对静态几何和刚性场景的强假设，这使得它们在存在动态物体与摄像机运动的真实环境中表现出较差的鲁棒性，进而导致渲染不稳定和视觉保真度下降。为了解决这一问题，我们提出了一种基于稀疏控制高斯投影的模糊单目视频动态视图合成方法，称为 DBMovi-GS。该方法专为从模糊单目视频中进行动态新视角合成而设计，能够生成稠密的三维高斯表示，从而在恢复视频清晰度的同时，重建受动态运动变化影响的场景的精细三维几何结构。实验证明，该方法在动态模糊场景下的新视角合成任务中表现出强大的鲁棒性，并为模糊单目视频输入下的真实感视图合成设立了新基准。
