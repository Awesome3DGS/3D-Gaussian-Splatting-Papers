### SplatPose: Geometry-Aware 6-DoF Pose Estimation from Single RGB Image via 3D Gaussian Splatting

6-DoF pose estimation is a fundamental task in computer vision with wide-ranging applications in augmented reality and robotics. Existing single RGB-based methods often compromise accuracy due to their reliance on initial pose estimates and susceptibility to rotational ambiguity, while approaches requiring depth sensors or multi-view setups incur significant deployment costs. To address these limitations, we introduce SplatPose, a novel framework that synergizes 3D Gaussian Splatting (3DGS) with a dual-branch neural architecture to achieve high-precision pose estimation using only a single RGB image. Central to our approach is the Dual-Attention Ray Scoring Network (DARS-Net), which innovatively decouples positional and angular alignment through geometry-domain attention mechanisms, explicitly modeling directional dependencies to mitigate rotational ambiguity. Additionally, a coarse-to-fine optimization pipeline progressively refines pose estimates by aligning dense 2D features between query images and 3DGS-synthesized views, effectively correcting feature misalignment and depth errors from sparse ray sampling. Experiments on three benchmark datasets demonstrate that SplatPose achieves state-of-the-art 6-DoF pose estimation accuracy in single RGB settings, rivaling approaches that depend on depth or multi-view images.

6-DoF 位姿估计是计算机视觉中的一项基础任务，在增强现实和机器人等领域具有广泛应用。然而，现有基于单张 RGB 图像的方法往往因依赖初始位姿估计且易受旋转歧义影响而牺牲精度，而依赖深度传感器或多视角设置的方法则会带来较高的部署成本。
为了解决这些局限性，我们提出 SplatPose，一个结合 3D 高斯散点 (3D Gaussian Splatting, 3DGS) 与双分支神经网络架构的全新框架，仅利用单张 RGB 图像即可实现高精度的位姿估计。
我们方法的核心是 双注意力射线评分网络 (Dual-Attention Ray Scoring Network, DARS-Net)，其创新之处在于通过几何域注意力机制解耦位置和角度对齐，显式建模方向依赖关系，以缓解旋转歧义问题。此外，我们设计了一种由粗到细的优化管线 (coarse-to-fine optimization pipeline)，通过在查询图像与 3DGS 合成视图之间对齐稠密的 2D 特征，逐步优化位姿估计，从而有效纠正因稀疏射线采样导致的特征错位和深度误差。
在三个基准数据集上的实验表明，SplatPose 在单 RGB 设置下实现了当前最先进的 6-DoF 位姿估计精度，其效果可与依赖深度或多视角图像的方法相媲美。
