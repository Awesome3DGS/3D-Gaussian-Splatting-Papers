### Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors

Many 3D scene editing tasks focus on modifying local regions rather than the entire scene, except for some global applications like style transfer, and in the context of 3D Gaussian Splatting (3DGS), where scenes are represented by a series of Gaussians, this structure allows for precise regional edits, offering enhanced control over specific areas of the scene; however, the challenge lies in the fact that 3D semantic parsing often underperforms compared to its 2D counterpart, making targeted manipulations within 3D spaces more difficult and limiting the fidelity of edits, which we address by leveraging 2D diffusion editing to accurately identify modification regions in each view, followed by inverse rendering for 3D localization, then refining the frontal view and initializing a coarse 3DGS with consistent views and approximate shapes derived from depth maps predicted by a 2D foundation model, thereby supporting an iterative, view-consistent editing process that gradually enhances structural details and textures to ensure coherence across perspectives. Experiments demonstrate that our method achieves state-of-the-art performance while delivering up to a 4× speedup, providing a more efficient and effective approach to 3D scene local editing.

许多三维场景编辑任务更侧重于局部区域的修改，而非整个场景，除了一些如风格迁移等全局应用。在三维高斯溅射（3D Gaussian Splatting, 3DGS）中，场景由一系列高斯表示，这种结构使精确的局部编辑成为可能，从而能够更好地控制场景中的特定区域。然而，挑战在于三维语义解析的表现往往不如二维，这使得在三维空间中进行针对性的操作更加困难，并限制了编辑的保真度。为解决这一问题，我们利用二维扩散编辑在每个视图中精确识别修改区域，随后通过反向渲染实现三维定位，然后对正视图进行细化，并利用二维基础模型预测的深度图生成一致视图和近似形状，以初始化粗略的 3DGS，从而支持一种迭代的、视图一致的编辑过程，在该过程中逐步增强结构细节与纹理，以确保多视角间的一致性。实验表明，我们的方法在性能上达到了当前最优，并实现了最高 4 倍的加速，为三维场景局部编辑提供了一种更高效且更有效的方案。
