### Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis

Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization.

说话人头像合成（Talking Head Synthesis）已成为计算机图形学与多媒体领域的关键研究方向，然而，大多数现有方法在生成质量与计算效率之间难以兼顾。
本文提出了一种新颖的方法，基于**音频因子分解平面（Audio Factorization Plane, Audio-Plane）**的高斯泼洒（Gaussian Splatting），实现高质量且实时的说话人头像生成。为了建模动态说话人头像，需要使用四维体积表示（4D volume representation）。然而，直接存储密集的四维网格不仅代价高昂，而且在处理长时间序列时缺乏可扩展性。
为克服这一挑战，我们提出了Audio-Plane，将四维体积表示分解为音频无关的空间平面和音频相关的平面。这种分解提供了一种紧凑且可解释的特征表示方式，便于实现更精确的音频感知空间编码与更细致的音频驱动唇部动态建模。
为了进一步提升语音动态表现，我们还开发了一种动态泼洒方法（dynamic splatting method），引导网络更有效地关注于口部区域的动态建模。
大量实验表明，通过将上述创新与强大的高斯泼洒方法结合，我们的方法能够实时合成高度真实的说话人视频，并实现精准的音频与唇动同步。
