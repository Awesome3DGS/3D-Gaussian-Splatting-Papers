### SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting

Reconstructing articulated objects prevalent in daily environments is crucial for applications in augmented/virtual reality and robotics. However, existing methods face scalability limitations (requiring 3D supervision or costly annotations), robustness issues (being susceptible to local optima), and rendering shortcomings (lacking speed or photorealism). We introduce SplArt, a self-supervised, category-agnostic framework that leverages 3D Gaussian Splatting (3DGS) to reconstruct articulated objects and infer kinematics from two sets of posed RGB images captured at different articulation states, enabling real-time photorealistic rendering for novel viewpoints and articulations. SplArt augments 3DGS with a differentiable mobility parameter per Gaussian, achieving refined part segmentation. A multi-stage optimization strategy is employed to progressively handle reconstruction, part segmentation, and articulation estimation, significantly enhancing robustness and accuracy. SplArt exploits geometric self-supervision, effectively addressing challenging scenarios without requiring 3D annotations or category-specific priors. Evaluations on established and newly proposed benchmarks, along with applications to real-world scenarios using a handheld RGB camera, demonstrate SplArt's state-of-the-art performance and real-world practicality.

在增强/虚拟现实与机器人等应用中，重建日常环境中常见的可动结构物体具有重要意义。然而，现有方法在可扩展性（需要3D监督或高成本标注）、鲁棒性（易陷入局部最优解）和渲染性能（缺乏速度或真实感）方面仍面临诸多限制。为此，我们提出了 SplArt —— 一种自监督、无类别依赖的框架，利用 三维高斯喷洒（3D Gaussian Splatting, 3DGS） 实现可动结构物体的重建与运动学推理，仅需在不同姿态状态下拍摄的两组有姿态标注的 RGB 图像，即可实现新视角和新动作的实时写实渲染。
SplArt 在 3DGS 的基础上引入每个高斯粒子的可微运动参数，从而实现精细的部件分割。同时，框架采用多阶段优化策略，逐步处理重建、部件分割与姿态估计任务，显著提升鲁棒性与准确性。该方法利用几何自监督信号，有效应对具有挑战性的场景，无需任何 3D 标注或类别特定先验。
在多个已有及新提出的基准测试上的评估结果，以及基于手持 RGB 相机采集的真实场景应用，均表明 SplArt 在性能与实用性方面均达到当前最优水平。
