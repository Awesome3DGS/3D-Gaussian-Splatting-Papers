### Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline

Incrementally recovering real-sized 3D geometry from a pose-free RGB stream is a challenging task in 3D reconstruction, requiring minimal assumptions on input data. Existing methods can be broadly categorized into end-to-end and visual SLAM-based approaches, both of which either struggle with long sequences or depend on slow test-time optimization and depth sensors. To address this, we first integrate a depth estimator into an RGB-D SLAM system, but this approach is hindered by inaccurate geometric details in predicted depth. Through further investigation, we find that 3D Gaussian mapping can effectively solve this problem. Building on this, we propose an online 3D reconstruction method using 3D Gaussian-based SLAM, combined with a feed-forward recurrent prediction module to directly infer camera pose from optical flow. This approach replaces slow test-time optimization with fast network inference, significantly improving tracking speed. Additionally, we introduce a local graph rendering technique to enhance robustness in feed-forward pose prediction. Experimental results on the Replica and TUM-RGBD datasets, along with a real-world deployment demonstration, show that our method achieves performance on par with the state-of-the-art SplaTAM, while reducing tracking time by more than 90%.

在无需位姿的 RGB 流中逐步恢复真实尺寸的三维几何是一项具有挑战性的三维重建任务，对输入数据的假设要求极低。现有方法大致可分为端到端方法和基于视觉 SLAM 的方法，这两类方法要么难以处理长序列，要么依赖于缓慢的测试时优化和深度传感器。为了解决这一问题，我们首先将深度估计器集成到 RGB-D SLAM 系统中，但该方法受限于预测深度的几何细节不准确。进一步研究发现，三维高斯映射能够有效解决这一问题。在此基础上，我们提出了一种结合基于三维高斯的 SLAM 与前向递归预测模块的在线三维重建方法，该模块可直接根据光流推断相机位姿。该方法用快速的网络推理替代了缓慢的测试时优化，从而显著提升了跟踪速度。此外，我们引入了一种局部图渲染技术，以增强前向位姿预测的鲁棒性。在 Replica 和 TUM-RGBD 数据集上的实验结果，以及真实环境部署的展示表明，我们的方法在性能上可与当前最先进的 SplaTAM 相媲美，同时将跟踪时间减少了 90% 以上。
