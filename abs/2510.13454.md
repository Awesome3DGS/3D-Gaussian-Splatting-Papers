### VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator

The rapid progress of large, pretrained models for both visual content generation and 3D reconstruction opens up new possibilities for text-to-3D generation. Intuitively, one could obtain a formidable 3D scene generator if one were able to combine the power of a modern latent text-to-video model as "generator" with the geometric abilities of a recent (feedforward) 3D reconstruction system as "decoder". We introduce VIST3A, a general framework that does just that, addressing two main challenges. First, the two components must be joined in a way that preserves the rich knowledge encoded in their weights. We revisit model stitching, i.e., we identify the layer in the 3D decoder that best matches the latent representation produced by the text-to-video generator and stitch the two parts together. That operation requires only a small dataset and no labels. Second, the text-to-video generator must be aligned with the stitched 3D decoder, to ensure that the generated latents are decodable into consistent, perceptually convincing 3D scene geometry. To that end, we adapt direct reward finetuning, a popular technique for human preference alignment. We evaluate the proposed VIST3A approach with different video generators and 3D reconstruction models. All tested pairings markedly improve over prior text-to-3D models that output Gaussian splats. Moreover, by choosing a suitable 3D base model, VIST3A also enables high-quality text-to-pointmap generation.

近年来，大规模预训练模型在视觉内容生成与三维重建领域的迅猛发展为文本到三维（text-to-3D）生成带来了全新机遇。直观来看，若能将现代潜变量文本到视频生成模型作为“生成器”与最新的（前馈式）三维重建系统作为“解码器”相结合，则有望构建出强大的三维场景生成器。我们提出了VIST3A，一个实现上述目标的通用框架，并针对其中的两大关键挑战提出解决方案。首先，这两个组件必须以一种能够保留其权重中丰富知识的方式进行衔接。我们重新审视了模型拼接的策略，即在三维解码器中识别最匹配文本到视频生成器所生成潜变量表示的层，并将两者拼接起来。该过程仅需少量数据且无需标签。其次，为确保生成的潜变量能够被解码为一致且感知上可信的三维场景几何结构，需对文本到视频生成器进行与拼接后的三维解码器的对齐。为此，我们采用了一种流行的人类偏好对齐技术——直接奖励微调（Direct Reward Finetuning）。我们在多种视频生成器与三维重建模型组合下对VIST3A进行了评估，所有组合在效果上均显著优于以往输出高斯点云的text-to-3D模型。此外，得益于灵活的三维基础模型选择，VIST3A还支持高质量的文本到点云图（text-to-pointmap）生成。
