### CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis

Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high quality synthesis of human heads. However, existing methods stabilize training and enhance rendering quality from steep viewpoints by conditioning the random latent vector on the current camera position. This compromises 3D consistency, as we observe significant identity changes when re-synthesizing the 3D head with each camera shift. Conversely, fixing the camera to a single viewpoint yields high-quality renderings for that perspective but results in poor performance for novel views. Removing view-conditioning typically destabilizes GAN training, often causing the training to collapse. In response to these challenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework that enables stable training and high-quality 3D-consistent synthesis of human heads without relying on view-conditioning. To ensure training stability, we introduce a multi-view regularization technique that enhances generator convergence with minimal computational overhead. Additionally, we adapt the conditional loss used in existing 3D Gaussian splatting GANs and propose a generator architecture designed to not only stabilize training but also facilitate efficient rendering and straightforward scaling, enabling output resolutions up to 20482. To evaluate the capabilities of CGS-GAN, we curate a new dataset derived from FFHQ. This dataset enables very high resolutions, focuses on larger portions of the human head, reduces view-dependent artifacts for improved 3D consistency, and excludes images where subjects are obscured by hands or other objects. As a result, our approach achieves very high rendering quality, supported by competitive FID scores, while ensuring consistent 3D scene generation.

近年来，基于三维高斯散点（3D Gaussian Splatting, 3DGS）的三维生成对抗网络（3D GANs）被提出用于高质量的人头合成。然而，现有方法通常通过将随机潜变量与当前相机位置进行条件耦合，以稳定训练过程并提升从极端视角渲染的质量。但这种方式牺牲了三维一致性：我们观察到，当相机视角发生变化并重新合成三维人头时，身份特征会发生显著改变。
相反，若固定相机位置，仅从单一视角进行训练，虽然可获得该视角下的高质量图像，但在新视角下表现较差。完全去除视角条件通常会导致 GAN 训练不稳定，甚至直接崩溃。
针对上述挑战，我们提出了 CGS-GAN，一种新颖的三维高斯散点 GAN 框架，在无需视角条件的情况下实现稳定训练与高质量的三维一致性人头合成。
为保障训练稳定性，我们引入了一种多视角正则化技术，以极低的计算开销提升生成器的收敛效果。同时，我们对现有三维高斯 GAN 中的条件损失函数进行了适配，并设计了一种新的生成器架构，该架构不仅增强训练稳定性，还具备高效渲染与易于扩展的特性，可支持最高达 2048² 分辨率的输出。
为了评估 CGS-GAN 的性能，我们基于 FFHQ 数据构建了一个新数据集。该数据集支持超高分辨率训练，覆盖更大范围的人头区域，减少视角相关伪影，增强三维一致性，并剔除因手部或其他物体遮挡面部的图像。
最终，我们的方法在实现卓越渲染质量的同时，也保持了良好的三维场景一致性，FID 等指标表现具有竞争力。
