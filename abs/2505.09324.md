### Neural Video Compression using 2D Gaussian Splatting

The computer vision and image processing research community has been involved in standardizing video data communications for the past many decades, leading to standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent groundbreaking works have focused on employing deep learning-based techniques to replace the traditional video codec pipeline to a greater affect. Neural video codecs (NVC) create an end-to-end ML-based solution that does not rely on any handcrafted features (motion or edge-based) and have the ability to learn content-aware compression strategies, offering better adaptability and higher compression efficiency than traditional methods. This holds a great potential not only for hardware design, but also for various video streaming platforms and applications, especially video conferencing applications such as MS-Teams or Zoom that have found extensive usage in classrooms and workplaces. However, their high computational demands currently limit their use in real-time applications like video conferencing. To address this, we propose a region-of-interest (ROI) based neural video compression model that leverages 2D Gaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable of real-time decoding and can be optimized using fewer data points, requiring only thousands of Gaussians for decent quality outputs as opposed to millions in 3D scenes. In this work, we designed a video pipeline that speeds up the encoding time of the previous Gaussian splatting-based image codec by 88% by using a content-aware initialization strategy paired with a novel Gaussian inter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be used for a video-codec solution, the first of its kind solution in this neural video codec space.

计算机视觉与图像处理研究社区在过去几十年中持续推动视频数据通信标准的发展，先后制定了 AVC、HEVC、VVC、AV1、AV2 等标准。然而，近年来的突破性研究逐渐将重心转向利用深度学习技术替代传统视频编解码流程。神经视频编解码器（Neural Video Codecs, NVC） 提供了一种端到端的机器学习解决方案，完全摆脱了对传统手工设计特征（如运动或边缘信息）的依赖，具备学习内容自适应压缩策略的能力，在适应性和压缩效率方面均优于传统方法。
这一发展不仅对硬件设计具有重大意义，也对视频流媒体平台和应用（特别是 MS-Teams、Zoom 等广泛应用于教室和办公场景的视频会议平台）带来巨大潜力。然而，目前神经视频编解码器的高计算开销仍限制了其在实时应用（如视频会议）中的广泛部署。
为应对这一挑战，我们提出了一种基于**兴趣区域（Region-of-Interest, ROI）**的神经视频压缩模型，利用 二维高斯投影（2D Gaussian Splatting） 实现高效编码。不同于传统编解码器，2D 高斯投影具备实时解码能力，并且仅需数千个高斯点即可生成质量较高的输出，而无需像三维场景那样使用上百万个高斯。
在本工作中，我们设计了一条完整的视频处理流水线，结合内容感知初始化策略与新颖的高斯帧间冗余消除机制，在此前基于高斯投影的图像编解码器基础上，将编码速度提升了 88%，首次实现在神经视频编解码领域中应用高斯投影的可行视频编码方案。
