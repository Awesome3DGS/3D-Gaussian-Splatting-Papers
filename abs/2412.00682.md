### FlashSLAM: Accelerated RGB-D SLAM for Real-Time 3D Scene Reconstruction with Gaussian Splatting

We present FlashSLAM, a novel SLAM approach that leverages 3D Gaussian Splatting for efficient and robust 3D scene reconstruction. Existing 3DGS-based SLAM methods often fall short in sparse view settings and during large camera movements due to their reliance on gradient descent-based optimization, which is both slow and inaccurate. FlashSLAM addresses these limitations by combining 3DGS with a fast vision-based camera tracking technique, utilizing a pretrained feature matching model and point cloud registration for precise pose estimation in under 80 ms - a 90% reduction in tracking time compared to SplaTAM - without costly iterative rendering. In sparse settings, our method achieves up to a 92% improvement in average tracking accuracy over previous methods. Additionally, it accounts for noise in depth sensors, enhancing robustness when using unspecialized devices such as smartphones. Extensive experiments show that FlashSLAM performs reliably across both sparse and dense settings, in synthetic and real-world environments. Evaluations on benchmark datasets highlight its superior accuracy and efficiency, establishing FlashSLAM as a versatile and high-performance solution for SLAM, advancing the state-of-the-art in 3D reconstruction across diverse applications.

我们提出了一种新颖的SLAM方法——FlashSLAM，该方法利用3D高斯散点（3D Gaussian Splatting，3DGS）实现高效且鲁棒的三维场景重建。现有基于3DGS的SLAM方法在稀疏视角设置和大范围相机运动情况下表现较差，主要原因是其依赖于梯度下降的优化过程，速度缓慢且精度不足。FlashSLAM通过将3DGS与一种快速的基于视觉的相机跟踪技术相结合，克服了这些局限。该方法采用预训练的特征匹配模型和点云配准技术，在不依赖代价高昂的迭代渲染的情况下，实现了精准的位姿估计，耗时不足80毫秒——与SplaTAM相比，跟踪时间减少了90%。在稀疏场景中，我们的方法在平均跟踪精度上相较于现有方法提升了高达92%。此外，它能够有效处理深度传感器中的噪声，从而增强了使用智能手机等非专业设备时的鲁棒性。
大量实验表明，FlashSLAM在稀疏和密集环境中均表现可靠，适用于合成和真实场景。基准数据集上的评估结果进一步突出了其卓越的精度和效率，使FlashSLAM成为一个多功能、高性能的SLAM解决方案，在3D重建领域的多个应用中推动了技术的发展。
