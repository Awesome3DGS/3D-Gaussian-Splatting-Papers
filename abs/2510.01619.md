### MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics

While there has been significant progress in the field of 3D avatar creation from visual observations, modeling physically plausible dynamics of humans with loose garments remains a challenging problem. Although a few existing works address this problem by leveraging physical simulation, they suffer from limited accuracy or robustness to novel animation inputs. In this work, we present MPMAvatar, a framework for creating 3D human avatars from multi-view videos that supports highly realistic, robust animation, as well as photorealistic rendering from free viewpoints. For accurate and robust dynamics modeling, our key idea is to use a Material Point Method-based simulator, which we carefully tailor to model garments with complex deformations and contact with the underlying body by incorporating an anisotropic constitutive model and a novel collision handling algorithm. We combine this dynamics modeling scheme with our canonical avatar that can be rendered using 3D Gaussian Splatting with quasi-shadowing, enabling high-fidelity rendering for physically realistic animations. In our experiments, we demonstrate that MPMAvatar significantly outperforms the existing state-of-the-art physics-based avatar in terms of (1) dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and efficiency. Additionally, we present a novel application in which our avatar generalizes to unseen interactions in a zero-shot manner-which was not achievable with previous learning-based methods due to their limited simulation generalizability.

尽管从视觉观测中构建三维虚拟人技术已取得显著进展，但对于穿着宽松服饰的人体进行物理合理的动态建模，仍然是一个极具挑战性的问题。已有少数工作尝试借助物理仿真解决该问题，但在面对新颖动画输入时，其准确性和鲁棒性仍然有限。在本研究中，我们提出了 MPMAvatar——一个从多视角视频中创建三维人体虚拟人的框架，支持高度真实且鲁棒的动画，同时实现任意视角下的逼真渲染。为了实现准确且稳健的动态建模，我们的核心思想是使用基于材料点法（Material Point Method, MPM）的仿真器，并通过引入各向异性的本构模型和全新的碰撞处理算法，对其进行精细定制，使其能够建模服饰的复杂形变以及与身体的接触行为。我们将这一动态建模机制与可使用带有准阴影效果的三维高斯泼溅进行渲染的标准虚拟人结合，从而实现具备物理真实性的高保真动画渲染。在实验中，我们展示了 MPMAvatar 在以下几个方面显著优于当前最先进的基于物理的虚拟人方法：（1）动态建模的准确性，（2）渲染的精度，以及（3）鲁棒性和效率。此外，我们还展示了一个新颖的应用场景，即该虚拟人可以在零样本条件下泛化至未见过的交互情境，而这在以往的基于学习的方法中是无法实现的，因为其仿真泛化能力受限。
