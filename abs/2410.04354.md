### StreetSurfGS: Scalable Urban Street Surface Reconstruction with Planar-based Gaussian Splatting

Reconstructing urban street scenes is crucial due to its vital role in applications such as autonomous driving and urban planning. These scenes are characterized by long and narrow camera trajectories, occlusion, complex object relationships, and data sparsity across multiple scales. Despite recent advancements, existing surface reconstruction methods, which are primarily designed for object-centric scenarios, struggle to adapt effectively to the unique characteristics of street scenes. To address this challenge, we introduce StreetSurfGS, the first method to employ Gaussian Splatting specifically tailored for scalable urban street scene surface reconstruction. StreetSurfGS utilizes a planar-based octree representation and segmented training to reduce memory costs, accommodate unique camera characteristics, and ensure scalability. Additionally, to mitigate depth inaccuracies caused by object overlap, we propose a guided smoothing strategy within regularization to eliminate inaccurate boundary points and outliers. Furthermore, to address sparse views and multi-scale challenges, we use a dual-step matching strategy that leverages adjacent and long-term information. Extensive experiments validate the efficacy of StreetSurfGS in both novel view synthesis and surface reconstruction.

重建城市街景对于自动驾驶和城市规划等应用至关重要。这类场景通常具有长且狭窄的摄像机轨迹、遮挡、复杂的物体关系以及跨多尺度的数据稀疏性。尽管近年来取得了一些进展，现有的主要为物体中心场景设计的表面重建方法，难以有效适应街景的独特特征。为了解决这一挑战，我们提出了StreetSurfGS，这是第一个专门为可扩展的城市街景表面重建设计的高斯散射方法。StreetSurfGS采用了基于平面的八叉树表示和分段训练，旨在降低内存成本，适应独特的摄像机特性，并确保可扩展性。此外，为了减轻物体重叠引起的深度误差，我们在正则化中提出了一种引导平滑策略，用于消除不准确的边界点和离群值。针对稀疏视图和多尺度问题，我们使用了双步骤匹配策略，结合了相邻信息和长期信息。大量实验验证了StreetSurfGS在新视图合成和表面重建中的有效性。
