### Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting

While text-to-3D and image-to-3D generation tasks have received considerable attention, one important but under-explored field between them is controllable text-to-3D generation, which we mainly focus on in this work. To address this task, 1) we introduce Multi-view ControlNet (MVControl), a novel neural network architecture designed to enhance existing pre-trained multi-view diffusion models by integrating additional input conditions, such as edge, depth, normal, and scribble maps. Our innovation lies in the introduction of a conditioning module that controls the base diffusion model using both local and global embeddings, which are computed from the input condition images and camera poses. Once trained, MVControl is able to offer 3D diffusion guidance for optimization-based 3D generation. And, 2) we propose an efficient multi-stage 3D generation pipeline that leverages the benefits of recent large reconstruction models and score distillation algorithm. Building upon our MVControl architecture, we employ a unique hybrid diffusion guidance method to direct the optimization process. In pursuit of efficiency, we adopt 3D Gaussians as our representation instead of the commonly used implicit representations. We also pioneer the use of SuGaR, a hybrid representation that binds Gaussians to mesh triangle faces. This approach alleviates the issue of poor geometry in 3D Gaussians and enables the direct sculpting of fine-grained geometry on the mesh. Extensive experiments demonstrate that our method achieves robust generalization and enables the controllable generation of high-quality 3D content.

虽然文本到3D和图像到3D的生成任务已经得到了相当多的关注，但在它们之间的一个重要但未被充分探索的领域是可控文本到3D生成，这正是我们在这项工作中主要关注的。为了解决这个任务，1) 我们引入了多视图控制网（MVControl），这是一个新颖的神经网络架构，旨在通过整合额外的输入条件，如边缘、深度、法线和涂鸦图，来增强现有的预训练多视图扩散模型。我们的创新在于引入了一个条件模块，该模块使用从输入条件图像和相机姿态计算得到的局部和全局嵌入来控制基础扩散模型。一旦训练完成，MVControl能够为基于优化的3D生成提供3D扩散引导。并且，2) 我们提出了一个高效的多阶段3D生成流程，该流程利用了最近大型重建模型和分数蒸馏算法的优势。基于我们的MVControl架构，我们采用了一种独特的混合扩散引导方法来指导优化过程。为了追求效率，我们采用3D高斯作为我们的表示，而不是常用的隐式表示。我们还率先使用了SuGaR，一种将高斯绑定到网格三角形面的混合表示。这种方法缓解了3D高斯中几何质量差的问题，并使得直接在网格上雕刻细粒度几何成为可能。广泛的实验表明，我们的方法实现了强大的泛化能力，并使得可控生成高质量3D内容成为可能。
