### OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS

Recent advances in 3D Gaussian Splatting (3DGS) have achieved state-of-the-art results for novel view synthesis. However, efficiently capturing high-fidelity reconstructions of specific objects within complex scenes remains a significant challenge. A key limitation of existing active reconstruction methods is their reliance on scene-level uncertainty metrics, which are often biased by irrelevant background clutter and lead to inefficient view selection for object-centric tasks. We present OUGS, a novel framework that addresses this challenge with a more principled, physically-grounded uncertainty formulation for 3DGS. Our core innovation is to derive uncertainty directly from the explicit physical parameters of the 3D Gaussian primitives (e.g., position, scale, rotation). By propagating the covariance of these parameters through the rendering Jacobian, we establish a highly interpretable uncertainty model. This foundation allows us to then seamlessly integrate semantic segmentation masks to produce a targeted, object-aware uncertainty score that effectively disentangles the object from its environment. This allows for a more effective active view selection strategy that prioritizes views critical to improving object fidelity. Experimental evaluations on public datasets demonstrate that our approach significantly improves the efficiency of the 3DGS reconstruction process and achieves higher quality for targeted objects compared to existing state-of-the-art methods, while also serving as a robust uncertainty estimator for the global scene.

近年来，**三维高斯溅射（3D Gaussian Splatting，3DGS）**在新视角合成任务上取得了最先进的性能。然而，在复杂场景中高效地捕获**特定目标的高保真重建**仍然是一个重大挑战。现有主动重建方法的一个关键局限在于其依赖于**场景级不确定性度量**，而这些度量往往受到无关背景杂波的干扰，从而在以目标为中心的任务中导致低效的视角选择。
为此，我们提出了 **OUGS**，这是一种针对 3DGS 的新型框架，通过更加原则化、**物理可解释的不确定性建模**来解决上述问题。我们的核心创新在于，直接从三维高斯基元的**显式物理参数**（如位置、尺度和旋转）中推导不确定性。通过将这些参数的协方差经由**渲染雅可比矩阵**进行传播，我们构建了一个高度可解释的不确定性模型。
在此基础上，我们进一步无缝融合**语义分割掩码**，生成一种具有针对性的、**目标感知的不确定性评分**，从而有效地将目标与其环境解耦。这使得我们能够制定更加有效的**主动视角选择策略**，优先选择对提升目标重建质量至关重要的视角。
在公开数据集上的实验评估表明，与现有最先进方法相比，我们的方法显著提升了 **3DGS 重建过程的效率**，并在目标对象上取得了更高的重建质量，同时也可作为一种**稳健的全局场景不确定性估计器**。
