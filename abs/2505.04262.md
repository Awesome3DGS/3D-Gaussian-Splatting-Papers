### Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting

Score Distillation Sampling (SDS) leverages pretrained 2D diffusion models to advance text-to-3D generation but neglects multi-view correlations, being prone to geometric inconsistencies and multi-face artifacts in the generated 3D content. In this work, we propose Coupled Score Distillation (CSD), a framework that couples multi-view joint distribution priors to ensure geometrically consistent 3D generation while enabling the stable and direct optimization of 3D Gaussian Splatting. Specifically, by reformulating the optimization as a multi-view joint optimization problem, we derive an effective optimization rule that effectively couples multi-view priors to guide optimization across different viewpoints while preserving the diversity of generated 3D assets. Additionally, we propose a framework that directly optimizes 3D Gaussian Splatting (3D-GS) with random initialization to generate geometrically consistent 3D content. We further employ a deformable tetrahedral grid, initialized from 3D-GS and refined through CSD, to produce high-quality, refined meshes. Quantitative and qualitative experimental results demonstrate the efficiency and competitive quality of our approach.

Score Distillation Sampling（SDS）利用预训练的二维扩散模型推动文本生成三维（text-to-3D）技术的发展，但忽视了多视角之间的相关性，容易在生成的三维内容中产生几何不一致和多面伪影等问题。
为解决这一问题，本文提出 Coupled Score Distillation（CSD） 框架，通过耦合多视角联合分布先验，实现几何一致的三维生成，并支持稳定且直接地优化三维高斯泼溅（3D Gaussian Splatting, 3D-GS）。具体而言，我们将优化过程重构为一个多视角联合优化问题，并由此推导出一条有效的优化规则，该规则在保持生成三维资产多样性的同时，有效耦合多视角先验，引导不同视角间的一致优化。
此外，我们提出了一个从随机初始化出发、直接优化 3D-GS 的生成框架，用于生成几何一致的三维内容。我们进一步引入一种可变形四面体网格结构，以 3D-GS 初始化，并通过 CSD 进行精细优化，从而生成高质量、细致的三维网格。
定量与定性实验结果表明，我们的方法在效率和生成质量上均表现出竞争力。
