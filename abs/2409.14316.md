### MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views

Recently, the Neural Radiance Field (NeRF) advancement has facilitated few-shot Novel View Synthesis (NVS), which is a significant challenge in 3D vision applications. Despite numerous attempts to reduce the dense input requirement in NeRF, it still suffers from time-consumed training and rendering processes. More recently, 3D Gaussian Splatting (3DGS) achieves real-time high-quality rendering with an explicit point-based representation. However, similar to NeRF, it tends to overfit the train views for lack of constraints. In this paper, we propose MVPGS, a few-shot NVS method that excavates the multi-view priors based on 3D Gaussian Splatting. We leverage the recent learning-based Multi-view Stereo (MVS) to enhance the quality of geometric initialization for 3DGS. To mitigate overfitting, we propose a forward-warping method for additional appearance constraints conforming to scenes based on the computed geometry. Furthermore, we introduce a view-consistent geometry constraint for Gaussian parameters to facilitate proper optimization convergence and utilize a monocular depth regularization as compensation. Experiments show that the proposed method achieves state-of-the-art performance with real-time rendering speed.

最近，神经辐射场（NeRF）的进步推动了少样本新视角合成（NVS）的发展，这是3D视觉应用中的一个重要挑战。尽管有许多尝试减少NeRF对密集输入的需求，它仍然面临耗时的训练和渲染过程。近期，3D Gaussian Splatting（3DGS）通过显式的点基表示实现了实时高质量渲染。然而，和NeRF类似，它也容易由于缺乏约束而过拟合训练视图。在本文中，我们提出了MVPGS，一种基于3D Gaussian Splatting的少样本NVS方法，挖掘多视角先验。我们利用最近的基于学习的多视角立体（MVS）方法，提升3DGS几何初始化的质量。为减轻过拟合，我们提出了一种前向变形方法，基于计算出的几何为场景提供额外的外观约束。此外，我们引入了一个视角一致的几何约束，以促进高斯参数的优化收敛，并使用单目深度正则化作为补充。实验表明，所提出的方法在实时渲染速度下实现了最先进的性能。
