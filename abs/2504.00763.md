### UnIRe: Unsupervised Instance Decomposition for Dynamic Urban Scene Reconstruction

Reconstructing and decomposing dynamic urban scenes is crucial for autonomous driving, urban planning, and scene editing. However, existing methods fail to perform instance-aware decomposition without manual annotations, which is crucial for instance-level scene editing. We propose UnIRe, a 3D Gaussian Splatting (3DGS) based approach that decomposes a scene into a static background and individual dynamic instances using only RGB images and LiDAR point clouds. At its core, we introduce 4D superpoints, a novel representation that clusters multi-frame LiDAR points in 4D space, enabling unsupervised instance separation based on spatiotemporal correlations. These 4D superpoints serve as the foundation for our decomposed 4D initialization, i.e., providing spatial and temporal initialization to train a dynamic 3DGS for arbitrary dynamic classes without requiring bounding boxes or object templates. Furthermore, we introduce a smoothness regularization strategy in both 2D and 3D space, further improving the temporal stability. Experiments on benchmark datasets show that our method outperforms existing methods in decomposed dynamic scene reconstruction while enabling accurate and flexible instance-level editing, making it a practical solution for real-world applications.

重建与分解动态城市场景对于自动驾驶、城市规划以及场景编辑等任务至关重要。然而，现有方法在无人工标注的情况下难以实现实例感知的场景分解，这对于实例级场景编辑来说至关重要。
我们提出了 UnIRe，一种基于三维高斯喷洒（3D Gaussian Splatting, 3DGS）的方法，仅使用 RGB 图像和激光雷达点云，将场景分解为静态背景与各个动态实例。其核心在于引入了 4D 超点（4D superpoints），这是一种新颖的表示方式，通过在 4D 空间中对多帧激光雷达点进行聚类，基于时空相关性实现无监督的实例分离。
这些 4D 超点构成了我们的 4D 分解初始化的基础，即为动态 3DGS 提供空间和时间上的初始化，使其能够针对任意动态类别进行训练，无需边界框或对象模板。
此外，我们在二维与三维空间中引入了平滑正则化策略，进一步提升了时间稳定性。
在多个基准数据集上的实验表明，UnIRe 在动态场景分解重建方面优于现有方法，同时支持精确且灵活的实例级编辑，为真实场景中的应用提供了实用解决方案。
