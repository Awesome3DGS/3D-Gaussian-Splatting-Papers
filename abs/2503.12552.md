### MTGS: Multi-Traversal Gaussian Splatting

Multi-traversal data, commonly collected through daily commutes or by self-driving fleets, provides multiple viewpoints for scene reconstruction within a road block. This data offers significant potential for high-quality novel view synthesis, which is crucial for applications such as autonomous vehicle simulators. However, inherent challenges in multi-traversal data often result in suboptimal reconstruction quality, including variations in appearance and the presence of dynamic objects. To address these issues, we propose Multi-Traversal Gaussian Splatting (MTGS), a novel approach that reconstructs high-quality driving scenes from arbitrarily collected multi-traversal data by modeling a shared static geometry while separately handling dynamic elements and appearance variations. Our method employs a multi-traversal dynamic scene graph with a shared static node and traversal-specific dynamic nodes, complemented by color correction nodes with learnable spherical harmonics coefficient residuals. This approach enables high-fidelity novel view synthesis and provides flexibility to navigate any viewpoint. We conduct extensive experiments on a large-scale driving dataset, nuPlan, with multi-traversal data. Our results demonstrate that MTGS improves LPIPS by 23.5% and geometry accuracy by 46.3% compared to single-traversal baselines.

多次穿越数据通常通过日常通勤或自动驾驶车队收集，提供了用于路段内场景重建的多个视角。这些数据为高质量的新颖视角合成提供了显著潜力，这对于自动驾驶汽车模拟器等应用至关重要。然而，多次穿越数据中固有的挑战常常导致重建质量不理想，包括外观变化和动态物体的存在。为了解决这些问题，我们提出了多次穿越高斯点云渲染（MTGS），这是一种通过建模共享静态几何结构，同时单独处理动态元素和外观变化，从任意收集的多次穿越数据中重建高质量驾驶场景的新方法。我们的方法采用了一个多次穿越动态场景图，包含一个共享的静态节点和特定于每次穿越的动态节点，并辅以带有可学习球谐系数残差的颜色校正节点。该方法能够实现高保真的新颖视角合成，并提供在任意视角下进行导航的灵活性。我们在一个大规模驾驶数据集nuPlan上进行了大量实验，使用了多次穿越数据。实验结果表明，与单次穿越基线相比，MTGS在LPIPS上提高了23.5%，在几何准确性上提高了46.3%。
