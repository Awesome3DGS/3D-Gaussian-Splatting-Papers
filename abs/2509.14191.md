### MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping

Recent progress in dense SLAM has primarily targeted monocular setups, often at the expense of robustness and geometric coverage. We present MCGS-SLAM, the first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting (3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM fuses dense RGB inputs from multiple viewpoints into a unified, continuously optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines poses and depths via dense photometric and geometric residuals, while a scale consistency module enforces metric alignment across views using low-rank priors. The system supports RGB input and maintains real-time performance at large scale. Experiments on synthetic and real-world datasets show that MCGS-SLAM consistently yields accurate trajectories and photorealistic reconstructions, usually outperforming monocular baselines. Notably, the wide field of view from multi-camera input enables reconstruction of side-view regions that monocular setups miss, critical for safe autonomous operation. These results highlight the promise of multi-camera Gaussian Splatting SLAM for high-fidelity mapping in robotics and autonomous driving.

近年来，稠密 SLAM 的研究主要集中于单目系统，这往往以牺牲鲁棒性和几何覆盖率为代价。本文提出 **MCGS-SLAM**，这是首个基于三维高斯溅射（3D Gaussian Splatting, 3DGS）的纯 RGB 多相机 SLAM 系统。与以往依赖稀疏地图或惯性数据的方法不同，MCGS-SLAM 将来自多个视角的稠密 RGB 输入融合为一个统一、持续优化的高斯地图。系统中的多相机联合优化（Multi-Camera Bundle Adjustment, MCBA）通过稠密的光度与几何残差共同优化相机位姿与深度；同时，尺度一致性模块利用低秩先验实现多视角间的度量对齐。该系统支持 RGB 输入，并在大规模场景下保持实时性能。在公开的合成与真实数据集上的实验表明，MCGS-SLAM 能稳定地获得高精度轨迹与逼真的重建结果，整体性能优于单目基线方法。值得注意的是，多相机输入带来的宽视场显著提升了侧向区域的重建能力，而这些区域在单目系统中往往被忽略，这对于安全的自主操作尤为关键。实验结果表明，多相机高斯溅射 SLAM 在机器人与自动驾驶等领域的高保真建图任务中具有广阔的应用前景。
