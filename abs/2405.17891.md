### A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction

In recent years, Neural Radiance Fields (NeRF) has revolutionized three-dimensional (3D) reconstruction with its implicit representation. Building upon NeRF, 3D Gaussian Splatting (3D-GS) has departed from the implicit representation of neural networks and instead directly represents scenes as point clouds with Gaussian-shaped distributions. While this shift has notably elevated the rendering quality and speed of radiance fields but inevitably led to a significant increase in memory usage. Additionally, effectively rendering dynamic scenes in 3D-GS has emerged as a pressing challenge. To address these concerns, this paper purposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction. Firstly, we use a deformable multi-layer perceptron (MLP) network to capture the dynamic offset of Gaussian points and express the color features of points through hash encoding and a tiny MLP to reduce storage requirements. Subsequently, we introduce a learnable denoising mask coupled with denoising loss to eliminate noise points from the scene, thereby further compressing 3D Gaussian model. Finally, motion noise of points is mitigated through static constraints and motion consistency constraints. Experimental results demonstrate that our method surpasses existing approaches in rendering quality and speed, while significantly reducing the memory usage associated with 3D-GS, making it highly suitable for various tasks such as novel view synthesis, and dynamic mapping.

近年来，神经辐射场（NeRF）凭借其隐式表达方式革新了三维（3D）重建技术。在 NeRF 的基础上，三维高斯喷溅（3D-GS）脱离了神经网络的隐式表达，转而直接将场景以高斯形状分布的点云形式表示。虽然这种转变显著提升了辐射场的渲染质量和速度，但不可避免地导致了内存使用的显著增加。此外，有效渲染 3D-GS 中的动态场景已成为一个紧迫的挑战。为解决这些问题，本文提出了一种精细的三维高斯表达方式，用于高质量动态场景重建。首先，我们使用一个可变形的多层感知器（MLP）网络来捕捉高斯点的动态偏移，并通过哈希编码及一个小型 MLP 来表达点的颜色特征，以减少存储需求。接着，我们引入了一个可学习的去噪掩模与去噪损失相结合，以从场景中消除噪点，进一步压缩三维高斯模型。最后，通过静态约束和运动一致性约束来缓解点的运动噪声。实验结果表明，我们的方法在渲染质量和速度上超越了现有方法，同时显著降低了与 3D-GS 相关的内存使用，使其非常适合用于新视角合成、动态映射等多种任务。
