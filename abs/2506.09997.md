### DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos

We introduce the Deformable Gaussian Splats Large Reconstruction Model (DGS-LRM), the first feed-forward method predicting deformable 3D Gaussian splats from a monocular posed video of any dynamic scene. Feed-forward scene reconstruction has gained significant attention for its ability to rapidly create digital replicas of real-world environments. However, most existing models are limited to static scenes and fail to reconstruct the motion of moving objects. Developing a feed-forward model for dynamic scene reconstruction poses significant challenges, including the scarcity of training data and the need for appropriate 3D representations and training paradigms. To address these challenges, we introduce several key technical contributions: an enhanced large-scale synthetic dataset with ground-truth multi-view videos and dense 3D scene flow supervision; a per-pixel deformable 3D Gaussian representation that is easy to learn, supports high-quality dynamic view synthesis, and enables long-range 3D tracking; and a large transformer network that achieves real-time, generalizable dynamic scene reconstruction. Extensive qualitative and quantitative experiments demonstrate that DGS-LRM achieves dynamic scene reconstruction quality comparable to optimization-based methods, while significantly outperforming the state-of-the-art predictive dynamic reconstruction method on real-world examples. Its predicted physically grounded 3D deformation is accurate and can readily adapt for long-range 3D tracking tasks, achieving performance on par with state-of-the-art monocular video 3D tracking methods.

我们提出了**可变形高斯溅射大规模重建模型（DGS-LRM）**，这是首个能够从任意动态场景的单目已知位姿视频中预测可变形三维高斯溅射的前馈式方法。前馈式场景重建因其能够快速生成真实环境的数字副本而备受关注。然而，大多数现有模型仅适用于静态场景，无法重建运动物体的动态信息。开发用于动态场景重建的前馈模型面临多重挑战，包括训练数据稀缺以及对合适的三维表示与训练范式的需求。为此，我们提出了若干关键技术创新：(1) 构建了增强型大规模合成数据集，包含真实标注的多视角视频与密集三维场景流监督；(2) 提出了易于学习的逐像素可变形三维高斯表示，既支持高质量的动态视图合成，又可实现长距离三维跟踪；(3) 设计了大规模 Transformer 网络，实现了实时、具有泛化能力的动态场景重建。大量定性与定量实验表明，DGS-LRM 的动态场景重建质量可与基于优化的方法媲美，并在真实场景中显著优于当前最先进的预测式动态重建方法。其预测的物理一致性三维形变精确可靠，可直接应用于长距离三维跟踪任务，并在性能上达到当前最先进的单目视频三维跟踪方法的水准。
