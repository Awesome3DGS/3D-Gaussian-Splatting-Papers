### GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting

We propose GaussianTalker, a novel framework for real-time generation of pose-controllable talking heads. It leverages the fast rendering capabilities of 3D Gaussian Splatting (3DGS) while addressing the challenges of directly controlling 3DGS with speech audio. GaussianTalker constructs a canonical 3DGS representation of the head and deforms it in sync with the audio. A key insight is to encode the 3D Gaussian attributes into a shared implicit feature representation, where it is merged with audio features to manipulate each Gaussian attribute. This design exploits the spatial-aware features and enforces interactions between neighboring points. The feature embeddings are then fed to a spatial-audio attention module, which predicts frame-wise offsets for the attributes of each Gaussian. It is more stable than previous concatenation or multiplication approaches for manipulating the numerous Gaussians and their intricate parameters. Experimental results showcase GaussianTalker's superiority in facial fidelity, lip synchronization accuracy, and rendering speed compared to previous methods. Specifically, GaussianTalker achieves a remarkable rendering speed of 120 FPS, surpassing previous benchmarks.

我们提出了一个名为GaussianTalker的新型框架，用于实时生成可控姿态的说话头部。它利用3D高斯溅射（3DGS）的快速渲染能力，同时解决了直接用语音音频控制3DGS的挑战。GaussianTalker构建了一个头部的规范3DGS表示，并且与音频同步进行形变。一个关键的见解是将3D高斯属性编码到一个共享的隐式特征表示中，在此基础上与音频特征合并，以操纵每个高斯属性。这种设计利用了空间感知特征，并强化了相邻点之间的相互作用。然后将特征嵌入送入一个空间-音频注意力模块，该模块预测每个高斯的属性的帧偏移量。与以往的串联或乘法操纵大量高斯及其复杂参数的方法相比，它更为稳定。实验结果展示了GaussianTalker在面部保真度、唇部同步精度和渲染速度方面相比以往方法的优越性。特别是，GaussianTalker实现了120 FPS的显著渲染速度，超越了之前的基准。
