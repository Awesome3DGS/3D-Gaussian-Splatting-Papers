### Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration

We introduce Dr. Splat, a novel approach for open-vocabulary 3D scene understanding leveraging 3D Gaussian Splatting. Unlike existing language-embedded 3DGS methods, which rely on a rendering process, our method directly associates language-aligned CLIP embeddings with 3D Gaussians for holistic 3D scene understanding. The key of our method is a language feature registration technique where CLIP embeddings are assigned to the dominant Gaussians intersected by each pixel-ray. Moreover, we integrate Product Quantization (PQ) trained on general large-scale image data to compactly represent embeddings without per-scene optimization. Experiments demonstrate that our approach significantly outperforms existing approaches in 3D perception benchmarks, such as open-vocabulary 3D semantic segmentation, 3D object localization, and 3D object selection tasks.

我们提出 Dr. Splat，这是一种利用 3D Gaussian Splatting (3DGS) 进行 开放词汇 3D 场景理解 的新方法。与现有的基于语言嵌入的 3DGS 方法不同，它们依赖于渲染过程，而我们的方法直接将 与语言对齐的 CLIP 嵌入（embeddings） 关联到 3D Gaussians，以实现整体的 3D 场景理解。
我们方法的关键是 语言特征注册技术（Language Feature Registration），其中 CLIP 嵌入被分配到每条像素射线（pixel-ray）所交叉的 主要 Gaussians 上。此外，我们结合了 基于大规模通用图像数据训练的乘积量化（Product Quantization, PQ），以紧凑地表示嵌入，而无需针对每个场景进行优化。
实验表明，我们的方法在 3D 认知基准任务上 显著优于现有方法，包括 开放词汇 3D 语义分割、3D 目标定位和 3D 目标选择 等任务。

