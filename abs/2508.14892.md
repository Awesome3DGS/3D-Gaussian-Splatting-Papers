### Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds

Reconstructing 3D human bodies from sparse views has been an appealing topic, which is crucial to broader the related applications. In this paper, we propose a quite challenging but valuable task to reconstruct the human body from only two images, i.e., the front and back view, which can largely lower the barrier for users to create their own 3D digital humans. The main challenges lie in the difficulty of building 3D consistency and recovering missing information from the highly sparse input. We redesign a geometry reconstruction model based on foundation reconstruction models to predict consistent point clouds even input images have scarce overlaps with extensive human data training. Furthermore, an enhancement algorithm is applied to supplement the missing color information, and then the complete human point clouds with colors can be obtained, which are directly transformed into 3D Gaussians for better rendering quality. Experiments show that our method can reconstruct the entire human in 190 ms on a single NVIDIA RTX 4090, with two images at a resolution of 1024x1024, demonstrating state-of-the-art performance on the THuman2.0 and cross-domain datasets. Additionally, our method can complete human reconstruction even with images captured by low-cost mobile devices, reducing the requirements for data collection.

从稀疏视角重建三维人体一直是一个颇具吸引力的话题，对拓展相关应用具有重要意义。本文提出了一项具有相当挑战性但极具价值的任务，即仅利用两张图像（正面和背面视角）重建人体，这大大降低了用户创建自己三维数字人门槛。其主要挑战在于构建三维一致性以及从高度稀疏的输入中恢复缺失信息的困难。我们基于基础重建模型重新设计了几何重建模型，使其即使在输入图像重叠极少的情况下，也能通过大规模人体数据训练预测出一致的点云。此外，我们还引入了一种增强算法来补充缺失的颜色信息，从而获得完整的人体彩色点云，并直接转换为三维高斯表示，以提升渲染质量。实验结果表明，在单张 NVIDIA RTX 4090 上，我们的方法仅需 190 毫秒即可完成两张分辨率为 1024x1024 的图像的人体完整重建，并在 THuman2.0 及跨域数据集上展现了当前最优的性能。此外，即便是由低成本移动设备采集的图像，我们的方法也能完成人体重建，从而降低了数据采集的要求。
