### RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images

This paper presents RoGSplat, a novel approach for synthesizing high-fidelity novel views of unseen human from sparse multi-view images, while requiring no cumbersome per-subject optimization. Unlike previous methods that typically struggle with sparse views with few overlappings and are less effective in reconstructing complex human geometry, the proposed method enables robust reconstruction in such challenging conditions. Our key idea is to lift SMPL vertices to dense and reliable 3D prior points representing accurate human body geometry, and then regress human Gaussian parameters based on the points. To account for possible misalignment between SMPL model and images, we propose to predict image-aligned 3D prior points by leveraging both pixel-level features and voxel-level features, from which we regress the coarse Gaussians. To enhance the ability to capture high-frequency details, we further render depth maps from the coarse 3D Gaussians to help regress fine-grained pixel-wise Gaussians. Experiments on several benchmark datasets demonstrate that our method outperforms state-of-the-art methods in novel view synthesis and cross-dataset generalization.

本文提出了RoGSplat，一种新颖的方法，通过稀疏多视角图像合成未见过的人体的新颖视角，同时无需繁琐的每个主体优化。与以往通常在稀疏视角下重建效果差且对复杂人体几何形状表现不佳的方法不同，所提出的方法能够在这种挑战性条件下实现稳健的重建。我们的核心思路是将SMPL模型的顶点提升到表示准确人体几何的密集可靠三维先验点，然后基于这些点回归人体高斯参数。为了应对SMPL模型和图像之间可能的错位，我们提出通过利用像素级特征和体素级特征来预测与图像对齐的三维先验点，从这些点回归粗略的高斯点。为了增强捕捉高频细节的能力，我们进一步从粗略的三维高斯点渲染深度图，帮助回归细粒度的像素级高斯点。在多个基准数据集上的实验表明，我们的方法在新颖视角合成和跨数据集泛化方面优于最先进的方法。
