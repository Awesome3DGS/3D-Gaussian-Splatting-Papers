### Fix False Transparency by Noise Guided Splatting

Opaque objects reconstructed by 3DGS often exhibit a falsely transparent surface, leading to inconsistent background and internal patterns under camera motion in interactive viewing. This issue stems from the ill-posed optimization in 3DGS. During training, background and foreground Gaussians are blended via alpha-compositing and optimized solely against the input RGB images using a photometric loss. As this process lacks an explicit constraint on surface opacity, the optimization may incorrectly assign transparency to opaque regions, resulting in view-inconsistent and falsely transparent. This issue is difficult to detect in standard evaluation settings but becomes particularly evident in object-centric reconstructions under interactive viewing. Although other causes of view-inconsistency have been explored recently, false transparency has not been explicitly identified. To the best of our knowledge, we are the first to identify, characterize, and develop solutions for this artifact, an underreported artifact in 3DGS. Our strategy, NGS, encourages surface Gaussians to adopt higher opacity by injecting opaque noise Gaussians in the object volume during training, requiring only minimal modifications to the existing splatting process. To quantitatively evaluate false transparency in static renderings, we propose a transmittance-based metric that measures the severity of this artifact. In addition, we introduce a customized, high-quality object-centric scan dataset exhibiting pronounced transparency issues, and we augment popular existing datasets with complementary infill noise specifically designed to assess the robustness of 3D reconstruction methods to false transparency. Experiments across multiple datasets show that NGS substantially reduces false transparency while maintaining competitive performance on standard rendering metrics, demonstrating its overall effectiveness.

由 3D 高斯散射（3DGS）重建的非透明物体，常常表现出伪透明表面，在交互式浏览中随相机移动呈现出背景和物体内部纹理不一致的问题。这一问题源于 3DGS 中病态的优化过程。在训练阶段，前景与背景高斯通过 alpha 混合进行融合，并仅以输入的 RGB 图像为监督信号，通过光度损失进行优化。由于该过程缺乏对表面不透明性的显式约束，优化过程可能错误地将透明性赋予本应不透明的区域，从而导致视角不一致并产生伪透明现象。该问题在标准评估设定下难以察觉，但在以物体为中心的交互式重建任务中尤为明显。尽管已有研究探讨了其他导致视角不一致的因素，但“伪透明”现象尚未被明确识别。据我们所知，我们是首个识别、分析并提出解决方案来应对这一问题的工作，该现象是 3DGS 中一个被低估的伪影。我们提出的策略 NGS，通过在训练期间向物体内部注入不透明的噪声高斯，鼓励表面高斯趋向于更高的不透明性，只需对现有的 splatting 流程进行最小修改。为在静态渲染中对伪透明进行定量评估，我们提出了一种基于透射率的指标，用于衡量此类伪影的严重程度。此外，我们构建了一个定制的、高质量的以物体为中心的扫描数据集，展现出明显的伪透明问题；同时还在已有的主流数据集上加入了专门设计的填充噪声，用以评估 3D 重建方法对伪透明问题的鲁棒性。跨多个数据集的实验证明，NGS 能显著减少伪透明现象，同时在标准渲染指标上保持竞争性能，展示了其整体有效性。
