### Object-Aware 4D Human Motion Generation

Recent advances in video diffusion models have enabled the generation of high-quality videos. However, these videos still suffer from unrealistic deformations, semantic violations, and physical inconsistencies that are largely rooted in the absence of 3D physical priors. To address these challenges, we propose an object-aware 4D human motion generation framework grounded in 3D Gaussian representations and motion diffusion priors. With pre-generated 3D humans and objects, our method, Motion Score Distilled Interaction (MSDI), employs the spatial and prompt semantic information in large language models (LLMs) and motion priors through the proposed Motion Diffusion Score Distillation Sampling (MSDS). The combination of MSDS and LLMs enables our spatial-aware motion optimization, which distills score gradients from pre-trained motion diffusion models, to refine human motion while respecting object and semantic constraints. Unlike prior methods requiring joint training on limited interaction datasets, our zero-shot approach avoids retraining and generalizes to out-of-distribution object aware human motions. Experiments demonstrate that our framework produces natural and physically plausible human motions that respect 3D spatial context, offering a scalable solution for realistic 4D generation.

视频扩散模型的最新进展已实现了高质量视频的生成。然而，这些视频仍然存在不真实的形变、语义违背和物理不一致性等问题，其根源在于缺乏三维物理先验。为了解决这些挑战，我们提出了一个基于三维高斯表示和运动扩散先验的、具备物体感知能力的四维人体运动生成框架。借助预生成的3D人体与物体，我们的方法——Motion Score Distilled Interaction（MSDI），通过所提出的Motion Diffusion Score Distillation Sampling（MSDS）机制，结合大语言模型（LLMs）中的空间与语义提示信息以及运动先验，实现空间感知的运动优化。MSDS与LLMs的结合，使我们能够从预训练的运动扩散模型中提取梯度得分，用于在人-物体语义约束下优化人体运动。与以往需在有限交互数据集上联合训练的方法不同，我们的零样本方法无需重新训练，能够泛化到分布外的物体感知人体运动。实验结果表明，我们的框架能够生成自然、物理合理的3D空间上下文一致的人体运动，为现实可行的4D生成提供了可扩展的解决方案。
