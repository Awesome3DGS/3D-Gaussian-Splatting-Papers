### Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs

Bridging natural language and 3D geometry is a crucial step toward flexible, language-driven scene understanding. While recent advances in 3D Gaussian Splatting (3DGS) have enabled fast and high-quality scene reconstruction, research has also explored incorporating open-vocabulary understanding into 3DGS. However, most existing methods require iterative optimization over per-view 2D semantic feature maps, which not only results in inefficiencies but also leads to inconsistent 3D semantics across views. To address these limitations, we introduce a training-free framework that constructs a superpoint graph directly from Gaussian primitives. The superpoint graph partitions the scene into spatially compact and semantically coherent regions, forming view-consistent 3D entities and providing a structured foundation for open-vocabulary understanding. Based on the graph structure, we design an efficient reprojection strategy that lifts 2D semantic features onto the superpoints, avoiding costly multi-view iterative training. The resulting representation ensures strong 3D semantic coherence and naturally supports hierarchical understanding, enabling both coarse- and fine-grained open-vocabulary perception within a unified semantic field. Extensive experiments demonstrate that our method achieves state-of-the-art open-vocabulary segmentation performance, with semantic field reconstruction completed over 30× faster.

将自然语言与三维几何建立桥接是实现灵活、语言驱动场景理解的关键一步。尽管近年来 3D Gaussian Splatting（3DGS）在快速高质量场景重建方面取得了显著进展，研究者也开始尝试将开放词汇语义理解引入 3DGS。然而，现有方法大多依赖于对每视角的二维语义特征图进行迭代优化，这不仅效率低下，还容易导致不同视角下语义不一致的问题。
为克服这些限制，我们提出了一种无需训练的框架，直接基于高斯原语构建 superpoint 图结构。该图将场景划分为空间紧凑且语义一致的区域，形成跨视角一致的三维实体，为开放词汇理解提供了结构化基础。
在此图结构之上，我们设计了一种高效的 重投影策略，将二维语义特征映射至 superpoint，避免了传统多视角迭代训练的高昂代价。最终形成的表示不仅具备强一致性的三维语义结构，同时天然支持分层理解，可在统一的语义场中实现粗粒度与细粒度的开放词汇感知。
大量实验表明，该方法在开放词汇语义分割任务上取得了当前最优性能，且语义场构建速度提升超过 30 倍，在效率与质量之间实现了出色平衡。
