### AvatarBack: Back-Head Generation for Complete 3D Avatars from Front-View Images

Recent advances in Gaussian Splatting have significantly boosted the reconstruction of head avatars, enabling high-quality facial modeling by representing an 3D avatar as a collection of 3D Gaussians. However, existing methods predominantly rely on frontal-view images, leaving the back-head poorly constructed. This leads to geometric inconsistencies, structural blurring, and reduced realism in the rear regions, ultimately limiting the fidelity of reconstructed avatars. To address this challenge, we propose AvatarBack, a novel plug-and-play framework specifically designed to reconstruct complete and consistent 3D Gaussian avatars by explicitly modeling the missing back-head regions. AvatarBack integrates two core technical innovations,i.e., the Subject-specific Generator (SSG) and the Adaptive Spatial Alignment Strategy (ASA). The former leverages a generative prior to synthesize identity-consistent, plausible back-view pseudo-images from sparse frontal inputs, providing robust multi-view supervision. To achieve precise geometric alignment between these synthetic views and the 3D Gaussian representation, the later employs learnable transformation matrices optimized during training, effectively resolving inherent pose and coordinate discrepancies. Extensive experiments on NeRSemble and K-hairstyle datasets, evaluated using geometric, photometric, and GPT-4o-based perceptual metrics, demonstrate that AvatarBack significantly enhances back-head reconstruction quality while preserving frontal fidelity. Moreover, the reconstructed avatars maintain consistent visual realism under diverse motions and remain fully animatable.

近期在高斯点绘（Gaussian Splatting）方面的进展极大推动了头部虚拟人重建的发展，使得通过将三维虚拟人表示为三维高斯集合来实现高质量人脸建模成为可能。然而，现有方法主要依赖正面视角图像，导致后脑部分重建不足。这会引发几何不一致、结构模糊以及后部区域真实感下降，从而限制了重建虚拟人的保真度。为应对这一挑战，我们提出了 **AvatarBack**，一个新颖的即插即用框架，专门通过显式建模缺失的后脑区域来重建完整且一致的三维高斯虚拟人。AvatarBack 融合了两项核心技术创新：**主体特定生成器（SSG）** 和 **自适应空间对齐策略（ASA）**。前者利用生成先验，从稀疏的正面输入中合成与身份一致、合理可信的背面伪图像，从而提供稳健的多视角监督；后者通过在训练过程中优化的可学习变换矩阵，实现这些合成视图与三维高斯表示之间的精确几何对齐，有效解决了固有的姿态和坐标差异。在 NeRSemble 和 K-hairstyle 数据集上的大量实验（使用几何、光度和基于 GPT-4o 的感知指标进行评估）表明，AvatarBack 显著提升了后脑重建质量，同时保持了正面保真度。此外，重建的虚拟人在多样化动作下依然保持一致的视觉真实感，并且完全支持动画化。
