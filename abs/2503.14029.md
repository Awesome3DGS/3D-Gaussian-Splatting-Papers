### Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting

Lifting multi-view 2D instance segmentation to a radiance field has proven to be effective to enhance 3D understanding. Existing methods rely on direct matching for end-to-end lifting, yielding inferior results; or employ a two-stage solution constrained by complex pre- or post-processing. In this work, we design a new end-to-end object-aware lifting approach, named Unified-Lift that provides accurate 3D segmentation based on the 3D Gaussian representation. To start, we augment each Gaussian point with an additional Gaussian-level feature learned using a contrastive loss to encode instance information. Importantly, we introduce a learnable object-level codebook to account for individual objects in the scene for an explicit object-level understanding and associate the encoded object-level features with the Gaussian-level point features for segmentation predictions. While promising, achieving effective codebook learning is non-trivial and a naive solution leads to degraded performance. Therefore, we formulate the association learning module and the noisy label filtering module for effective and robust codebook learning. We conduct experiments on three benchmarks: LERF-Masked, Replica, and Messy Rooms datasets. Both qualitative and quantitative results manifest that our Unified-Lift clearly outperforms existing methods in terms of segmentation quality and time efficiency.

将多视角二维实例分割提升到辐射场已被证明是增强三维理解的有效方法。现有方法依赖于直接匹配进行端到端提升，导致效果较差；或者采用两阶段解决方案，受限于复杂的预处理或后处理。本文提出了一种新的端到端面向物体的提升方法，称为Unified-Lift，它基于三维高斯表示提供准确的三维分割。首先，我们通过对每个高斯点进行增强，学习一个额外的高斯级特征，并使用对比损失来编码实例信息。重要的是，我们引入了一个可学习的物体级代码簿，用以考虑场景中的个体物体，进行显式的物体级理解，并将编码的物体级特征与高斯级点特征关联，进行分割预测。尽管前景广阔，但实现有效的代码簿学习并非易事，简单的解决方案会导致性能下降。因此，我们提出了关联学习模块和噪声标签过滤模块，以实现有效且稳健的代码簿学习。我们在三个基准数据集（LERF-Masked、Replica和Messy Rooms）上进行了实验。定性和定量结果表明，我们的Unified-Lift在分割质量和时间效率方面明显优于现有方法。
