### D-MiSo: Editing Dynamic 3D Scenes using Multi-Gaussians Soup

Over the past years, we have observed an abundance of approaches for modeling dynamic 3D scenes using Gaussian Splatting (GS). Such solutions use GS to represent the scene's structure and the neural network to model dynamics. Such approaches allow fast rendering and extracting each element of such a dynamic scene. However, modifying such objects over time is challenging. SC-GS (Sparse Controlled Gaussian Splatting) enhanced with Deformed Control Points partially solves this issue. However, this approach necessitates selecting elements that need to be kept fixed, as well as centroids that should be adjusted throughout editing. Moreover, this task poses additional difficulties regarding the re-productivity of such editing. To address this, we propose Dynamic Multi-Gaussian Soup (D-MiSo), which allows us to model the mesh-inspired representation of dynamic GS. Additionally, we propose a strategy of linking parameterized Gaussian splats, forming a Triangle Soup with the estimated mesh. Consequently, we can separately construct new trajectories for the 3D objects composing the scene. Thus, we can make the scene's dynamic editable over time or while maintaining partial dynamics.

近年来，我们观察到许多使用高斯投影（GS）来建模动态3D场景的方法。这些解决方案使用GS来表示场景的结构，并使用神经网络来模拟动态。这种方法允许快速渲染并提取这种动态场景的每个元素。然而，随时间修改这些对象是一项挑战。通过变形控制点增强的SC-GS（稀疏控制高斯投影）部分解决了这个问题。然而，这种方法需要选择需要保持固定的元素，以及在编辑过程中应调整的质心。此外，这项任务还带来了关于此类编辑可重复性的额外困难。为了解决这个问题，我们提出了动态多高斯汤（D-MiSo），它允许我们模拟动态GS的网格启发式表示。此外，我们提出了一种策略，将参数化的高斯斑点链接起来，形成带有估计网格的三角汤。因此，我们可以单独构建构成场景的3D对象的新轨迹。这样，我们可以在保持部分动态的同时，随时间编辑场景的动态。
