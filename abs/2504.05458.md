### Optimizing 4D Gaussians for Dynamic Scene Video from Single Landscape Images

To achieve realistic immersion in landscape images, fluids such as water and clouds need to move within the image while revealing new scenes from various camera perspectives. Recently, a field called dynamic scene video has emerged, which combines single image animation with 3D photography. These methods use pseudo 3D space, implicitly represented with Layered Depth Images (LDIs). LDIs separate a single image into depth-based layers, which enables elements like water and clouds to move within the image while revealing new scenes from different camera perspectives. However, as landscapes typically consist of continuous elements, including fluids, the representation of a 3D space separates a landscape image into discrete layers, and it can lead to diminished depth perception and potential distortions depending on camera movement. Furthermore, due to its implicit modeling of 3D space, the output may be limited to videos in the 2D domain, potentially reducing their versatility. In this paper, we propose representing a complete 3D space for dynamic scene video by modeling explicit representations, specifically 4D Gaussians, from a single image. The framework is focused on optimizing 3D Gaussians by generating multi-view images from a single image and creating 3D motion to optimize 4D Gaussians. The most important part of proposed framework is consistent 3D motion estimation, which estimates common motion among multi-view images to bring the motion in 3D space closer to actual motions. As far as we know, this is the first attempt that considers animation while representing a complete 3D space from a single landscape image. Our model demonstrates the ability to provide realistic immersion in various landscape images through diverse experiments and metrics.

为了在风景图像中实现真实的沉浸感，诸如水体与云层等流体元素需要在图像内产生动态变化，同时随着相机视角的移动呈现出新的景观。近期，一种结合单张图像动画与三维摄影的新研究方向——**动态场景视频（dynamic scene video）**逐渐兴起。此类方法通常采用伪三维空间建模，借助 分层深度图像（Layered Depth Images, LDIs） 实现图像的三维表现。LDIs 将单张图像划分为基于深度的多个层，使得水面、云层等元素能够在图像中产生运动，同时随着视角变化揭示新的场景内容。
然而，由于风景图像通常由连续元素构成，包括大量的流体结构，使用 LDIs 将图像划分为离散层的方式可能导致深度感减弱，并在相机运动时产生几何扭曲。此外，由于该类方法采用的是对三维空间的隐式建模，输出内容常局限于二维视频，从而限制了其应用的多样性。
为此，本文提出了一种从单张图像出发，通过构建显式表示——4D 高斯（4D Gaussians），来对完整三维空间进行建模的方法，用于生成动态场景视频。该框架的核心是通过从单张图像生成多视角图像并构建三维运动，进而优化三维高斯表示，最终获得 4D 高斯场景。
框架的关键在于一致性的三维运动估计，该模块用于从多视角图像中估计出共通的运动表达，使得三维空间中的运动更加贴近真实世界的动态行为。据我们所知，这是首次尝试在动画建模的同时，从单张风景图像出发构建完整的三维空间表示。
通过大量实验与评估指标，我们的方法展示出在不同类型风景图像中提供真实沉浸感的能力。
