### Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting

This paper investigates an open research challenge of reconstructing high-quality, large 3D open scenes from images. It is observed existing methods have various limitations, such as requiring precise camera poses for input and dense viewpoints for supervision. To perform effective and efficient 3D scene reconstruction, we propose a novel graph-guided 3D scene reconstruction framework, GraphGS. Specifically, given a set of images captured by RGB cameras on a scene, we first design a spatial prior-based scene structure estimation method. This is then used to create a camera graph that includes information about the camera topology. Further, we propose to apply the graph-guided multi-view consistency constraint and adaptive sampling strategy to the 3D Gaussian Splatting optimization process. This greatly alleviates the issue of Gaussian points overfitting to specific sparse viewpoints and expedites the 3D reconstruction process. We demonstrate GraphGS achieves high-fidelity 3D reconstruction from images, which presents state-of-the-art performance through quantitative and qualitative evaluation across multiple datasets.

本文研究了从图像重建 高质量、大规模 3D 开放场景 这一开放性研究挑战。现有方法存在诸多局限性，例如 需要精确的相机姿态输入，以及 依赖稠密视角进行监督。
为了实现高效且高质量的 3D 场景重建，我们提出了一种 基于图引导的 3D 场景重建框架——GraphGS。具体而言，给定由 RGB 相机 拍摄的一组场景图像，我们首先设计了一种 基于空间先验的场景结构估计算法，并利用该估计结果 构建相机图（Camera Graph），以描述相机的拓扑关系。此外，我们在 3D Gaussian Splatting 优化过程中 引入 图引导的多视角一致性约束（Graph-Guided Multi-View Consistency Constraint） 和 自适应采样策略（Adaptive Sampling Strategy），有效缓解 3D 高斯点（Gaussian Points）过拟合于特定稀疏视角 的问题，并加速 3D 重建过程。
实验结果表明，GraphGS 能够从图像高保真地重建 3D 场景，在多个数据集上的定量和定性评估均达到 当前最先进（SOTA） 的性能。
