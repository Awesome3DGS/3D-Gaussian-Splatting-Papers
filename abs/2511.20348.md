### Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin

3D reconstruction for Digital Twins often relies on LiDAR-based methods, which provide accurate geometry but lack the semantics and textures naturally captured by cameras. Traditional LiDAR-camera fusion approaches require complex calibration and still struggle with certain materials like glass, which are visible in images but poorly represented in point clouds. We propose a camera-only pipeline that reconstructs scenes using 3D Gaussian Splatting from multi-view images, extracts semantic material masks via vision models, converts Gaussian representations to mesh surfaces with projected material labels, and assigns physics-based material properties for accurate sensor simulation in modern graphics engines and simulators. This approach combines photorealistic reconstruction with physics-based material assignment, providing sensor simulation fidelity comparable to LiDAR-camera fusion while eliminating hardware complexity and calibration requirements. We validate our camera-only method using an internal dataset from an instrumented test vehicle, leveraging LiDAR as ground truth for reflectivity validation alongside image similarity metrics.

数字孪生中的三维重建通常依赖于基于激光雷达（LiDAR）的方法，这类方法能够提供精确的几何信息，但缺乏摄像头自然捕捉到的语义与纹理。传统的激光雷达-摄像头融合方法需要复杂的标定流程，且在处理诸如玻璃等材料时仍存在困难——这些材料在图像中清晰可见，但在点云中表现不佳。为此，我们提出了一种仅基于摄像头的重建流程：通过多视角图像实现三维高斯渲染（3D Gaussian Splatting）进行场景重建，借助视觉模型提取语义材质掩膜，将高斯表示转换为带有投影材质标签的网格表面，并赋予物理驱动的材质属性，以支持现代图形引擎与仿真器中的精确传感器模拟。该方法融合了真实感重建与基于物理的材质赋值，在消除硬件复杂性与标定需求的同时，提供了可与激光雷达-摄像头融合方法媲美的仿真精度。我们使用来自一辆搭载传感器的测试车辆的内部数据集对该摄像头-only 方法进行了验证，利用激光雷达作为反射率验证的参考，并结合图像相似度指标进行评估。
