### RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting

Radiance field methods, such as Neural Radiance Field or 3D Gaussian Splatting, have emerged as seminal 3D representations for synthesizing realistic novel views. For practical applications, there is ongoing research on flexible scene editing techniques, among which object removal is a representative task. However, removing objects exposes occluded regions, often leading to unnatural appearances. Thus, studies have employed image inpainting techniques to replace such regions with plausible content - a task referred to as 3D scene inpainting. However, image inpainting methods produce one of many plausible completions for each view, leading to inconsistencies between viewpoints. A widely adopted approach leverages perceptual cues to blend inpainted views smoothly. However, it is prone to detail loss and can fail when there are perceptual inconsistencies across views. In this paper, we propose a novel 3D scene inpainting method that reliably produces realistic and perceptually consistent results even for complex scenes by leveraging a reference view. Given the inpainted reference view, we estimate the inpainting similarity of the other views to adjust their contribution in constructing an accurate geometry tailored to the reference. This geometry is then used to warp the reference inpainting to other views as pseudo-ground truth, guiding the optimization to match the reference appearance. Comparative evaluation studies have shown that our approach improves both the geometric fidelity and appearance consistency of inpainted scenes.

辐射场方法（如神经辐射场 Neural Radiance Field 或三维高斯投影 3D Gaussian Splatting）已成为合成真实感新视角的典型三维表示形式。在实际应用中，灵活的场景编辑技术是研究热点，其中物体移除是具有代表性的一类任务。然而，移除物体会暴露原本被遮挡的区域，往往导致不自然的视觉效果。因此，已有研究采用图像修复技术为这些区域填充合理内容——这一任务被称为三维场景修复（3D scene inpainting）。但图像修复方法在每个视图中生成的只是众多合理补全之一，从而导致不同视角之间的不一致。主流方法通常利用感知线索平滑融合修复后的视图，但这种方法容易造成细节丢失，并在视角间存在感知不一致时失效。本文提出了一种新颖的三维场景修复方法，即使在复杂场景下也能生成真实且感知一致的结果，核心思想是利用参考视图。给定修复完成的参考视图，我们估计其他视图的修复相似度，并据此调整它们在构建针对参考视图的精确几何中的贡献。随后利用该几何将参考修复结果变形到其他视图，作为伪真实值，指导优化过程以匹配参考视图的外观。对比实验结果表明，我们的方法同时提升了修复场景的几何保真度与外观一致性。
