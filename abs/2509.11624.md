### A Controllable 3D Deepfake Generation Framework with Gaussian Splatting

We propose a novel 3D deepfake generation framework based on 3D Gaussian Splatting that enables realistic, identity-preserving face swapping and reenactment in a fully controllable 3D space. Compared to conventional 2D deepfake approaches that suffer from geometric inconsistencies and limited generalization to novel view, our method combines a parametric head model with dynamic Gaussian representations to support multi-view consistent rendering, precise expression control, and seamless background integration. To address editing challenges in point-based representations, we explicitly separate the head and background Gaussians and use pre-trained 2D guidance to optimize the facial region across views. We further introduce a repair module to enhance visual consistency under extreme poses and expressions. Experiments on NeRSemble and additional evaluation videos demonstrate that our method achieves comparable performance to state-of-the-art 2D approaches in identity preservation, as well as pose and expression consistency, while significantly outperforming them in multi-view rendering quality and 3D consistency. Our approach bridges the gap between 3D modeling and deepfake synthesis, enabling new directions for scene-aware, controllable, and immersive visual forgeries, revealing the threat that emerging 3D Gaussian Splatting technique could be used for manipulation attacks.

我们提出了一种基于三维高斯溅射（3D Gaussian Splatting）的新型三维深度伪造生成框架，能够在可完全控制的三维空间中实现真实且保留身份特征的换脸与重演。与传统的二维深度伪造方法相比，后者常受几何不一致性与对新视角泛化能力有限的问题影响，我们的方法将参数化头部模型与动态高斯表示相结合，从而支持多视角一致渲染、精确的表情控制以及与背景的无缝融合。为了解决点基表示（point-based representations）中的编辑难题，我们对头部与背景高斯进行了显式分离，并利用预训练的二维引导在多视图间优化面部区域。此外，我们引入了一个修复模块，以在极端姿态与表情下增强视觉一致性。在NeRSemble及其他评估视频上的实验表明，我们的方法在身份保持以及姿态与表情一致性方面可达到与最先进二维方法相当的效果，同时在多视角渲染质量与三维一致性方面显著优于它们。我们的方法弥合了三维建模与深度伪造合成之间的鸿沟，推动了面向场景、可控且沉浸式的视觉伪造新方向，并揭示了新兴的三维高斯溅射技术可能被用于操纵攻击的风险。
