### Beyond Existance: Fulfill 3D Reconstructed Scenes with Pseudo Details

The emergence of 3D Gaussian Splatting (3D-GS) has significantly advanced 3D reconstruction by providing high fidelity and fast training speeds across various scenarios. While recent efforts have mainly focused on improving model structures to compress data volume or reduce artifacts during zoom-in and zoom-out operations, they often overlook an underlying issue: training sampling deficiency. In zoomed-in views, Gaussian primitives can appear unregulated and distorted due to their dilation limitations and the insufficient availability of scale-specific training samples. Consequently, incorporating pseudo-details that ensure the completeness and alignment of the scene becomes essential. In this paper, we introduce a new training method that integrates diffusion models and multi-scale training using pseudo-ground-truth data. This approach not only notably mitigates the dilation and zoomed-in artifacts but also enriches reconstructed scenes with precise details out of existing scenarios. Our method achieves state-of-the-art performance across various benchmarks and extends the capabilities of 3D reconstruction beyond training datasets.

3D Gaussian Splatting (3D-GS) 的出现极大推动了3D 重建的发展，在不同场景中提供高保真度和快速训练速度。尽管近期研究主要致力于优化模型结构以压缩数据体积或减少缩放操作中的伪影，但一个核心问题往往被忽视：训练采样不足（training sampling deficiency）。
在放大视角（zoomed-in views）下，由于高斯基元的膨胀（dilation）限制及缺乏尺度特定的训练样本，高斯分布可能会表现出不稳定和变形。因此，引入伪细节（pseudo-details） 以确保场景的完整性和对齐性变得尤为重要。
在本文中，我们提出了一种新型训练方法，结合扩散模型（diffusion models） 与 多尺度训练（multi-scale training），并利用伪真值数据（pseudo-ground-truth data） 进行优化。这种方法不仅能够显著缓解高斯基元的膨胀问题和缩放伪影，还可以丰富重建场景的精细细节，超越训练数据集中的原始信息。
我们的实验表明，该方法在多个基准测试上达到了最先进（SOTA）性能，并进一步拓展了3D 重建的能力边界，使其能够在训练数据集之外的场景中表现卓越。
