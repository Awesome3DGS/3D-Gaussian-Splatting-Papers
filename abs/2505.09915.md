### Large-Scale Gaussian Splatting SLAM

The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have shown encouraging and impressive results for visual SLAM. However, most representative methods require RGBD sensors and are only available for indoor environments. The robustness of reconstruction in large-scale outdoor scenarios remains unexplored. This paper introduces a large-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The proposed LSG-SLAM employs a multi-modality strategy to estimate prior poses under large view changes. In tracking, we introduce feature-alignment warping constraints to alleviate the adverse effects of appearance similarity in rendering losses. For the scalability of large-scale scenarios, we introduce continuous Gaussian Splatting submaps to tackle unbounded scenes with limited memory. Loops are detected between GS submaps by place recognition and the relative pose between looped keyframes is optimized utilizing rendering and feature warping losses. After the global optimization of camera poses and Gaussian points, a structure refinement module enhances the reconstruction quality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM achieves superior performance over existing Neural, 3DGS-based, and even traditional approaches.

近年来发展起来的神经辐射场（Neural Radiance Fields, NeRF）与三维高斯投影（3D Gaussian Splatting, 3DGS）在视觉 SLAM 任务中展现出令人鼓舞的成果。然而，现有主流方法大多依赖 RGB-D 传感器，且仅适用于室内场景，对于大规模户外环境的重建鲁棒性尚未得到系统探索。
本文提出了一种基于 3DGS 的大规模立体视觉 SLAM 系统，称为 LSG-SLAM（Large-Scale Gaussian Splatting SLAM）。该方法利用双目相机，并采用多模态策略以应对大视角变化下的先验位姿估计问题。在跟踪阶段，我们引入了特征对齐变形约束（feature-alignment warping constraints），缓解由于渲染损失中图像外观相似性所带来的不利影响。
为支持大规模场景的可扩展性，LSG-SLAM 设计了连续高斯子图（continuous Gaussian Splatting submaps）结构，有效处理非边界限制场景下的内存约束问题。系统通过地点识别（place recognition）检测高斯子图间的回环，并结合渲染损失与特征变形损失优化回环关键帧之间的相对位姿。在完成相机姿态与高斯点的全局优化后，我们进一步引入结构精化模块以提升重建质量。
在 EuRoc 与 KITTI 等真实数据集上的大量实验验证表明，LSG-SLAM 的性能显著优于现有神经方法、3DGS 方法，乃至传统 SLAM 方法。
