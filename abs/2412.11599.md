### 3D2-Actor: Learning Pose-Conditioned 3D-Aware Denoiser for Realistic Gaussian Avatar Modeling

Advancements in neural implicit representations and differentiable rendering have markedly improved the ability to learn animatable 3D avatars from sparse multi-view RGB videos. However, current methods that map observation space to canonical space often face challenges in capturing pose-dependent details and generalizing to novel poses. While diffusion models have demonstrated remarkable zero-shot capabilities in 2D image generation, their potential for creating animatable 3D avatars from 2D inputs remains underexplored. In this work, we introduce 3D2-Actor, a novel approach featuring a pose-conditioned 3D-aware human modeling pipeline that integrates iterative 2D denoising and 3D rectifying steps. The 2D denoiser, guided by pose cues, generates detailed multi-view images that provide the rich feature set necessary for high-fidelity 3D reconstruction and pose rendering. Complementing this, our Gaussian-based 3D rectifier renders images with enhanced 3D consistency through a two-stage projection strategy and a novel local coordinate representation. Additionally, we propose an innovative sampling strategy to ensure smooth temporal continuity across frames in video synthesis. Our method effectively addresses the limitations of traditional numerical solutions in handling ill-posed mappings, producing realistic and animatable 3D human avatars. Experimental results demonstrate that 3D2-Actor excels in high-fidelity avatar modeling and robustly generalizes to novel poses.

神经隐式表示和可微渲染的进步显著提升了从稀疏多视角RGB视频中学习可动画3D角色的能力。然而，目前将观察空间映射到规范空间的方法在捕捉依赖姿态的细节以及推广到新姿态时常面临挑战。尽管扩散模型在2D图像生成中展现了卓越的零样本能力，但其在从2D输入中创建可动画3D角色的潜力仍未被充分挖掘。
在这项工作中，我们提出了 3D2-Actor，一种新颖的姿态条件3D感知人类建模管线，集成了迭代的2D去噪和3D校正步骤。2D去噪模块通过姿态线索引导，生成详细的多视角图像，为高保真3D重建和姿态渲染提供了丰富的特征集合。与此相辅相成，我们的基于高斯的3D校正模块通过两阶段投影策略和一种新颖的局部坐标表示，渲染出具有增强3D一致性的图像。此外，我们提出了一种创新的采样策略，确保视频合成中跨帧的平滑时间连续性。
我们的方法有效解决了传统数值解法在处理病态映射时的局限性，生成真实且可动画的3D人类角色。实验结果表明，3D2-Actor 在高保真角色建模方面表现卓越，并能够稳健地推广到新姿态。
