### GS4: Generalizable Sparse Splatting Semantic SLAM

Traditional SLAM algorithms are excellent at camera tracking but might generate lower resolution and incomplete 3D maps. Recently, Gaussian Splatting (GS) approaches have emerged as an option for SLAM with accurate, dense 3D map building. However, existing GS-based SLAM methods rely on per-scene optimization which is time-consuming and does not generalize to diverse scenes well. In this work, we introduce the first generalizable GS-based semantic SLAM algorithm that incrementally builds and updates a 3D scene representation from an RGB-D video stream using a learned generalizable network. Our approach starts from an RGB-D image recognition backbone to predict the Gaussian parameters from every downsampled and backprojected image location. Additionally, we seamlessly integrate 3D semantic segmentation into our GS framework, bridging 3D mapping and recognition through a shared backbone. To correct localization drifting and floaters, we propose to optimize the GS for only 1 iteration following global localization. We demonstrate state-of-the-art semantic SLAM performance on the real-world benchmark ScanNet with an order of magnitude fewer Gaussians compared to other recent GS-based methods, and showcase our model's generalization capability through zero-shot transfer to the NYUv2 and TUM RGB-D datasets.

传统的 SLAM 算法在相机跟踪方面表现出色，但往往生成的三维地图分辨率较低且不完整。近年来，高斯泼溅（Gaussian Splatting, GS）方法逐渐成为构建高精度、稠密三维地图的 SLAM 选项。然而，现有基于 GS 的 SLAM 方法依赖于每个场景的优化过程，既耗时又难以泛化至多样化的场景。
在本工作中，我们提出了首个可泛化的基于 GS 的语义 SLAM 算法。该方法利用训练好的通用网络，从 RGB-D 视频流中逐步构建并更新三维场景表示。我们的方法以 RGB-D 图像识别骨干网络为起点，从每一个下采样并反投影后的图像位置预测高斯参数。同时，我们将三维语义分割无缝集成进 GS 框架，通过共享骨干网络实现三维建图与语义识别的融合。
为修正定位漂移与浮点伪影，我们提出在全局定位后，仅进行一次迭代的 GS 优化策略。实验表明，我们的方法在真实场景基准数据集 ScanNet 上实现了最先进的语义 SLAM 性能，所需高斯数量相比其他近期 GS 方法少一个数量级。此外，我们还通过零样本迁移在 NYUv2 和 TUM RGB-D 数据集上展示了模型的优秀泛化能力。
