### MVD-HuGaS: Human Gaussians from a Single Image via 3D Human Multi-view Diffusion Prior

3D human reconstruction from a single image is a challenging problem and has been exclusively studied in the literature. Recently, some methods have resorted to diffusion models for guidance, optimizing a 3D representation via Score Distillation Sampling(SDS) or generating one backview image for facilitating reconstruction. However, these methods tend to produce unsatisfactory artifacts (e.g. flattened human structure or over-smoothing results caused by inconsistent priors from multiple views) and struggle with real-world generalization in the wild. In this work, we present MVD-HuGaS, enabling free-view 3D human rendering from a single image via a multi-view human diffusion model. We first generate multi-view images from the single reference image with an enhanced multi-view diffusion model, which is well fine-tuned on high-quality 3D human datasets to incorporate 3D geometry priors and human structure priors. To infer accurate camera poses from the sparse generated multi-view images for reconstruction, an alignment module is introduced to facilitate joint optimization of 3D Gaussians and camera poses. Furthermore, we propose a depth-based Facial Distortion Mitigation module to refine the generated facial regions, thereby improving the overall fidelity of the reconstruction. Finally, leveraging the refined multi-view images, along with their accurate camera poses, MVD-HuGaS optimizes the 3D Gaussians of the target human for high-fidelity free-view renderings. Extensive experiments on Thuman2.0 and 2K2K datasets show that the proposed MVD-HuGaS achieves state-of-the-art performance on single-view 3D human rendering.

从单张图像重建3D 人体是一个极具挑战的问题，并已在文献中广泛研究。近期，一些方法尝试利用扩散模型（diffusion models）进行引导，例如使用得分蒸馏采样（Score Distillation Sampling, SDS）优化 3D 表示，或生成后视图图像（backview image）以辅助重建。然而，这些方法往往会产生不理想的伪影（例如，扁平化的人体结构或因多视角先验不一致导致的过度平滑），并且在**真实世界场景（in-the-wild）**中的泛化能力较弱。
为了解决这些问题，我们提出 MVD-HuGaS，一种基于多视角人体扩散模型（multi-view human diffusion model）的自由视角 3D 人体渲染方法，仅需单张输入图像即可生成高质量 3D 头像。
具体而言，我们首先使用增强型多视角扩散模型（multi-view diffusion model）从单张参考图像生成多个视角的图像。该模型经过高质量3D 人体数据集的精细调优，使其能够有效学习3D 几何先验和人体结构先验。
为了从这些稀疏的多视角生成图像中推断准确的相机位姿以进行 3D 重建，我们引入对齐模块（alignment module），用于联合优化3D 高斯（3D Gaussians）和相机位姿，提高重建的准确性。此外，我们提出基于深度的面部失真缓解模块（Depth-based Facial Distortion Mitigation module），专门优化生成的面部区域，从而提升整体重建的保真度。
最终，利用优化后的多视角图像及其精准相机位姿，MVD-HuGaS 进一步优化目标人体的3D 高斯表示，从而实现高保真度的自由视角渲染。在 Thuman2.0 和 2K2K 数据集上的广泛实验表明，MVD-HuGaS 在单视角 3D 人体渲染任务上达到了当前最先进水平（state-of-the-art）。
