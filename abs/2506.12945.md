### Metropolis-Hastings Sampling for 3D Gaussian Reconstruction

We propose an adaptive sampling framework for 3D Gaussian Splatting (3DGS) that leverages comprehensive multi-view photometric error signals within a unified Metropolis-Hastings approach. Traditional 3DGS methods heavily rely on heuristic-based density-control mechanisms (e.g., cloning, splitting, and pruning), which can lead to redundant computations or the premature removal of beneficial Gaussians. Our framework overcomes these limitations by reformulating densification and pruning as a probabilistic sampling process, dynamically inserting and relocating Gaussians based on aggregated multi-view errors and opacity scores. Guided by Bayesian acceptance tests derived from these error-based importance scores, our method substantially reduces reliance on heuristics, offers greater flexibility, and adaptively infers Gaussian distributions without requiring predefined scene complexity. Experiments on benchmark datasets, including Mip-NeRF360, Tanks and Temples, and Deep Blending, show that our approach reduces the number of Gaussians needed, enhancing computational efficiency while matching or modestly surpassing the view-synthesis quality of state-of-the-art models.

我们提出了一种适用于三维高斯溅射（3DGS）的自适应采样框架，在统一的 **Metropolis-Hastings** 方法中利用全面的多视角光度误差信号。传统的 3DGS 方法高度依赖启发式的密度控制机制（如克隆、拆分与裁剪），这可能导致冗余计算，或过早移除有用的高斯。我们的框架通过将加密与裁剪重新表述为一种概率采样过程，基于聚合的多视角误差与不透明度分数动态插入和重新定位高斯。该方法利用由误差驱动的重要性评分推导出的 **贝叶斯接受检验** 进行引导，大幅减少对启发式规则的依赖，提供更高的灵活性，并能够在无需预设场景复杂度的情况下自适应地推断高斯分布。在 **Mip-NeRF360**、**Tanks and Temples** 及 **Deep Blending** 等基准数据集上的实验表明，我们的方法在减少高斯数量、提升计算效率的同时，在视图合成质量上能够达到甚至略微超过当前最先进模型的水平。
