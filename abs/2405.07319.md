### LayGA: Layered Gaussian Avatars for Animatable Clothing Transfer

Animatable clothing transfer, aiming at dressing and animating garments across characters, is a challenging problem. Most human avatar works entangle the representations of the human body and clothing together, which leads to difficulties for virtual try-on across identities. What's worse, the entangled representations usually fail to exactly track the sliding motion of garments. To overcome these limitations, we present Layered Gaussian Avatars (LayGA), a new representation that formulates body and clothing as two separate layers for photorealistic animatable clothing transfer from multi-view videos. Our representation is built upon the Gaussian map-based avatar for its excellent representation power of garment details. However, the Gaussian map produces unstructured 3D Gaussians distributed around the actual surface. The absence of a smooth explicit surface raises challenges in accurate garment tracking and collision handling between body and garments. Therefore, we propose two-stage training involving single-layer reconstruction and multi-layer fitting. In the single-layer reconstruction stage, we propose a series of geometric constraints to reconstruct smooth surfaces and simultaneously obtain the segmentation between body and clothing. Next, in the multi-layer fitting stage, we train two separate models to represent body and clothing and utilize the reconstructed clothing geometries as 3D supervision for more accurate garment tracking. Furthermore, we propose geometry and rendering layers for both high-quality geometric reconstruction and high-fidelity rendering. Overall, the proposed LayGA realizes photorealistic animations and virtual try-on, and outperforms other baseline methods.

面对跨角色的服装转移和动画化，可动画化服装转移是一个充满挑战的问题。大多数人体化身作品将人体和服装的表示混合在一起，这导致跨身份的虚拟试穿存在困难。更糟糕的是，这种纠缠的表示通常无法准确跟踪服装的滑动运动。为了克服这些限制，我们提出了Layered Gaussian Avatars（LayGA），这是一种新的表示方法，将身体和服装作为两个独立的层来实现从多视角视频中进行真实感动画化服装转移。我们的表示基于高斯地图化身，因其在服装细节表现上的卓越能力。然而，高斯地图产生的非结构化3D高斯分布在实际表面周围。缺乏光滑的显式表面在精确的服装跟踪和处理身体与服装之间的碰撞时带来挑战。因此，我们提出了两阶段训练，包括单层重建和多层拟合。在单层重建阶段，我们提出一系列几何约束来重建平滑表面，并同时获得身体和服装之间的分割。接下来，在多层拟合阶段，我们训练两个分离的模型来分别表示身体和服装，并利用重建的服装几何体作为3D监督，以实现更精确的服装跟踪。此外，我们还提出了几何和渲染层，以实现高质量的几何重建和高保真渲染。总体而言，所提出的LayGA实现了逼真的动画和虚拟试穿，并且性能超过了其他基线方法。
