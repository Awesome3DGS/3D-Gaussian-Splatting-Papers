### RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI

The emerging field of Vision-Language-Action (VLA) for humanoid robots faces several fundamental challenges, including the high cost of data acquisition, the lack of a standardized benchmark, and the significant gap between simulation and the real world. To overcome these obstacles, we propose RealMirror, a comprehensive, open-source embodied AI VLA platform. RealMirror builds an efficient, low-cost data collection, model training, and inference system that enables end-to-end VLA research without requiring a real robot. To facilitate model evolution and fair comparison, we also introduce a dedicated VLA benchmark for humanoid robots, featuring multiple scenarios, extensive trajectories, and various VLA models. Furthermore, by integrating generative models and 3D Gaussian Splatting to reconstruct realistic environments and robot models, we successfully demonstrate zero-shot Sim2Real transfer, where models trained exclusively on simulation data can perform tasks on a real robot seamlessly, without any fine-tuning. In conclusion, with the unification of these critical components, RealMirror provides a robust framework that significantly accelerates the development of VLA models for humanoid robots.

新兴的人形机器人视觉-语言-动作（Vision-Language-Action, VLA）研究领域面临若干根本性挑战，包括数据采集成本高、缺乏统一基准测试，以及模拟与真实世界之间存在显著差距。为应对这些问题，我们提出了 **RealMirror**——一个全面的开源具身智能 VLA 平台。RealMirror 构建了一个高效、低成本的数据采集、模型训练与推理系统，使研究者无需真实机器人即可开展端到端的 VLA 研究。为促进模型演化与公平比较，我们还引入了一个专门面向人形机器人的 VLA 基准测试，涵盖多种场景、大量轨迹及多类型 VLA 模型。此外，我们结合生成模型与三维高斯溅射（3D Gaussian Splatting）重建逼真的环境与机器人模型，实现了**零样本仿真到现实（Sim2Real）迁移**——即仅基于模拟数据训练的模型即可无缝执行真实机器人任务，无需任何微调。综上所述，RealMirror 通过整合这些关键组件，提供了一个稳健的框架，显著加速了人形机器人 VLA 模型的研究与发展。
