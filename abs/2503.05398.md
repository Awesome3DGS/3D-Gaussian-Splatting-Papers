### Self-Modeling Robots by Photographing

Self-modeling enables robots to build task-agnostic models of their morphology and kinematics based on data that can be automatically collected, with minimal human intervention and prior information, thereby enhancing machine intelligence. Recent research has highlighted the potential of data-driven technology in modeling the morphology and kinematics of robots. However, existing self-modeling methods suffer from either low modeling quality or excessive data acquisition costs. Beyond morphology and kinematics, texture is also a crucial component of robots, which is challenging to model and remains unexplored. In this work, a high-quality, texture-aware, and link-level method is proposed for robot self-modeling. We utilize three-dimensional (3D) Gaussians to represent the static morphology and texture of robots, and cluster the 3D Gaussians to construct neural ellipsoid bones, whose deformations are controlled by the transformation matrices generated by a kinematic neural network. The 3D Gaussians and kinematic neural network are trained using data pairs composed of joint angles, camera parameters and multi-view images without depth information. By feeding the kinematic neural network with joint angles, we can utilize the well-trained model to describe the corresponding morphology, kinematics and texture of robots at the link level, and render robot images from different perspectives with the aid of 3D Gaussian splatting. Furthermore, we demonstrate that the established model can be exploited to perform downstream tasks such as motion planning and inverse kinematics.

自建模 (Self-modeling) 使机器人能够在最小化人工干预和先验信息的情况下，基于自动采集的数据构建与任务无关的形态与运动学模型，从而提升机器智能。近年来，数据驱动技术在机器人形态 (Morphology) 和运动学 (Kinematics) 建模中的潜力已被广泛研究。然而，现有的自建模方法通常在建模质量较低或数据采集成本过高之间存在权衡。此外，除了形态和运动学，纹理 (Texture) 也是机器人建模中的关键组成部分，但由于建模难度较大，该方面仍然未被充分探索。
在本研究中，我们提出了一种高质量、具备纹理感知能力 (Texture-aware) 且基于链节级 (Link-level) 的机器人自建模方法。我们采用三维高斯散点 (3D Gaussians) 来表示机器人的静态形态和纹理，并通过对 3D 高斯散点进行聚类来构建神经椭球骨骼 (Neural Ellipsoid Bones)，其变形由运动学神经网络 (Kinematic Neural Network) 生成的变换矩阵控制。
在训练过程中，我们的 3D 高斯散点和运动学神经网络利用仅包含关节角度、相机参数和多视角图像（不含深度信息）的数据对进行优化。通过向运动学神经网络输入关节角度，训练好的模型能够在链节级准确描述机器人形态、运动学和纹理，并借助3D 高斯散点渲染 (3D Gaussian Splatting) 生成不同视角下的机器人图像。
此外，我们进一步验证了所建立模型在下游任务中的应用价值，例如运动规划 (Motion Planning) 和逆运动学 (Inverse Kinematics)，展现了该方法的广泛适用性和潜力。
