### PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors

Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an efficient representation for novel-view synthesis, achieving impressive visual quality. However, in scenes dominated by large and low-texture regions, common in indoor environments, the photometric loss used to optimize 3DGS yields ambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome this limitation, we introduce PlanarGS, a 3DGS-based framework tailored for indoor scene reconstruction. Specifically, we design a pipeline for Language-Prompted Planar Priors (LP3) that employs a pretrained vision-language segmentation model and refines its region proposals via cross-view fusion and inspection with geometric priors. 3D Gaussians in our framework are optimized with two additional terms: a planar prior supervision term that enforces planar consistency, and a geometric prior supervision term that steers the Gaussians toward the depth and normal cues. We have conducted extensive experiments on standard indoor benchmarks. The results show that PlanarGS reconstructs accurate and detailed 3D surfaces, consistently outperforming state-of-the-art methods by a large margin.

三维高斯泼洒（3DGS）近年来作为一种高效的新视角合成表示方法受到广泛关注，并在视觉质量上取得了令人印象深刻的成果。然而，在以大面积低纹理区域为主的场景中（如常见的室内环境），用于优化 3DGS 的光度损失容易导致几何形状模糊，难以还原高保真的三维表面。为了解决这一问题，我们提出了 PlanarGS——一个专为室内场景重建设计的 3DGS 框架。具体而言，我们设计了一条名为“语言提示平面先验”（LP3）的处理流程，利用预训练的视觉-语言分割模型生成初始区域提议，并通过跨视图融合与几何先验的检验机制进一步优化这些提议。在此基础上，我们在 3D 高斯的优化过程中引入了两个附加监督项：一是平面先验监督项，用于保持平面一致性；二是几何先验监督项，用于引导高斯分布对齐于深度和法向信息。我们在多个标准室内数据集上进行了大量实验，结果表明 PlanarGS 能够重建出准确且细节丰富的三维表面，在多个指标上大幅超越当前最先进方法。
