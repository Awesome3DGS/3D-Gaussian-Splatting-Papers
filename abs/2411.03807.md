### GS2Pose: Two-stage 6D Object Pose Estimation Guided by Gaussian Splatting

This paper proposes a new method for accurate and robust 6D pose estimation of novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose can utilize the reconstruction results without requiring a high-quality CAD model, which means it only requires segmented RGBD images as input. Specifically, GS2Pose employs a two-stage structure consisting of coarse estimation followed by refined estimation. In the coarse stage, a lightweight U-Net network with a polarization attention mechanism, called Pose-Net, is designed. By using the 3DGS model for supervised training, Pose-Net can generate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose formulates a pose regression algorithm following the idea of reprojection or Bundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to extend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that refines the coarse pose by comparing the input images with the rendered images. GS-Refiner also selectively updates parameters in the 3DGS model to achieve environmental adaptation, thereby enhancing the algorithm's robustness and flexibility to illuminative variation, occlusion, and other challenging disruptive factors. GS2Pose was evaluated through experiments conducted on the LineMod dataset, where it was compared with similar algorithms, yielding highly competitive results.

本文提出了一种名为 GS2Pose 的新方法，用于对新物体进行准确且鲁棒的 6D 姿态估计。通过引入 3D Gaussian Splatting，GS2Pose 可以利用重建结果而无需高质量的 CAD 模型，仅需分割后的 RGBD 图像作为输入。具体而言，GS2Pose 采用了由粗估计和精估计组成的两阶段结构。在粗估计阶段，设计了一个轻量化的 U-Net 网络 Pose-Net，该网络结合极化注意力机制，并通过 3DGS 模型进行监督训练，以生成 NOCS 图像用于计算粗略姿态。在精估计阶段，GS2Pose 基于重投影或捆绑调整（Bundle Adjustment, BA）的思想，设计了一种姿态回归算法，称为 GS-Refiner。通过利用 Lie 代数扩展 3DGS，GS-Refiner 实现了一个姿态可微的渲染管线，通过将输入图像与渲染图像进行比较来优化粗略姿态。此外，GS-Refiner 有选择性地更新 3DGS 模型中的参数，以适应环境变化，从而增强算法对光照变化、遮挡以及其他挑战性干扰因素的鲁棒性和灵活性。通过在 LineMod 数据集上的实验评估，GS2Pose 与类似算法进行了对比，展现了极具竞争力的结果。
