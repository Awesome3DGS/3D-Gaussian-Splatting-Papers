### GS-Phong: Meta-Learned 3D Gaussians for Relightable Novel View Synthesis

Decoupling the illumination in 3D scenes is crucial for novel view synthesis and relighting. In this paper, we propose a novel method for representing a scene illuminated by a point light using a set of relightable 3D Gaussian points. Inspired by the Blinn-Phong model, our approach decomposes the scene into ambient, diffuse, and specular components, enabling the synthesis of realistic lighting effects. To facilitate the decomposition of geometric information independent of lighting conditions, we introduce a novel bilevel optimization-based meta-learning framework. The fundamental idea is to view the rendering tasks under various lighting positions as a multi-task learning problem, which our meta-learning approach effectively addresses by generalizing the learned Gaussian geometries not only across different viewpoints but also across diverse light positions. Experimental results demonstrate the effectiveness of our approach in terms of training efficiency and rendering quality compared to existing methods for free-viewpoint relighting.

在三维场景中分离照明对于新视角合成和重新照明至关重要。在本文中，我们提出了一种新方法，使用一组可重新照明的三维高斯点来表示由点光源照亮的场景。受到Blinn-Phong模型的启发，我们的方法将场景分解为环境光、漫反射和镜面反射成分，从而实现了真实的照明效果的合成。为了便于独立于照明条件分解几何信息，我们引入了一种新的双层优化基元学习框架。基本思想是将在不同照明位置下的渲染任务视为一个多任务学习问题，我们的元学习方法有效地通过泛化学习到的高斯几何形状，不仅跨不同视点，还跨不同的光线位置。实验结果证明了我们方法在训练效率和渲染质量方面与现有的自由视点重新照明方法相比的有效性。
