### MoGaFace: Momentum-Guided and Texture-Aware Gaussian Avatars for Consistent Facial Geometry

Existing 3D head avatar reconstruction methods adopt a two-stage process, relying on tracked FLAME meshes derived from facial landmarks, followed by Gaussian-based rendering. However, misalignment between the estimated mesh and target images often leads to suboptimal rendering quality and loss of fine visual details. In this paper, we present MoGaFace, a novel 3D head avatar modeling framework that continuously refines facial geometry and texture attributes throughout the Gaussian rendering process. To address the misalignment between estimated FLAME meshes and target images, we introduce the Momentum-Guided Consistent Geometry module, which incorporates a momentum-updated expression bank and an expression-aware correction mechanism to ensure temporal and multi-view consistency. Additionally, we propose Latent Texture Attention, which encodes compact multi-view features into head-aware representations, enabling geometry-aware texture refinement via integration into Gaussians. Extensive experiments show that MoGaFace achieves high-fidelity head avatar reconstruction and significantly improves novel-view synthesis quality, even under inaccurate mesh initialization and unconstrained real-world settings.

现有的三维头像重建方法通常采用两阶段流程，首先依赖由面部关键点估计得到的 FLAME 网格进行跟踪，然后再进行基于高斯的渲染。然而，估计网格与目标图像之间的错位常常导致渲染质量不佳，并丢失细节视觉信息。本文提出了 MoGaFace，这是一种新颖的三维头像建模框架，可在高斯渲染过程中持续优化面部几何和纹理属性。为解决估计的 FLAME 网格与目标图像的错位问题，我们引入了动量引导一致几何（Momentum-Guided Consistent Geometry）模块，该模块结合了动量更新的表情库和基于表情感知的校正机制，以确保时间和多视图的一致性。此外，我们提出了潜纹理注意（Latent Texture Attention）机制，将紧凑的多视图特征编码为面部感知表征，并将其融合到高斯中，实现基于几何感知的纹理优化。大量实验表明，MoGaFace 在不准确网格初始化和不受约束的真实场景下，依然能够实现高保真头像重建，并显著提升新视角合成质量。
