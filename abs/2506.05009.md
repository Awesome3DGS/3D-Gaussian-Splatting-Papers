### Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting

Training neural networks for tasks such as 3D point cloud semantic segmentation demands extensive datasets, yet obtaining and annotating real-world point clouds is costly and labor-intensive. This work aims to introduce a novel pipeline for generating realistic synthetic data, by leveraging 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) to generate 3D assets of multiple different agricultural vehicles instead of using generic models. These assets are placed in a simulated environment, where the point clouds are generated using a simulated LiDAR. This is a flexible approach that allows changing the LiDAR specifications without incurring additional costs. We evaluated the impact of synthetic data on segmentation models such as PointNet++, Point Transformer V3, and OACNN, by training and validating the models only on synthetic data. Remarkably, the PTv3 model had an mIoU of 91.35%, a noteworthy result given that the model had neither been trained nor validated on any real data. Further studies even suggested that in certain scenarios the models trained only on synthetically generated data performed better than models trained on real-world data. Finally, experiments demonstrated that the models can generalize across semantic classes, enabling accurate predictions on mesh models they were never trained on.

训练神经网络以执行诸如三维点云语义分割等任务，通常需要大量数据集。然而，获取和标注真实世界的点云数据既昂贵又耗费人力。为此，本文提出了一种全新的合成数据生成流程，利用三维高斯泼洒（3D Gaussian Splatting，3DGS）与高斯不透明度场（Gaussian Opacity Fields，GOF）来生成多种农业机械的高逼真三维资产，取代以往使用通用模型的做法。
这些资产被置于模拟环境中，并通过模拟 LiDAR 生成点云数据。该方法具有高度灵活性，允许在不产生额外成本的前提下变更 LiDAR 的参数配置。
我们评估了合成数据对语义分割模型（如 PointNet++、Point Transformer V3 和 OACNN）的影响，训练和验证过程完全基于合成数据。值得注意的是，PTv3 模型在未接触任何真实数据的情况下，仍然达到了 91.35% 的 mIoU，展现出极具意义的性能表现。进一步研究表明，在某些场景下，仅使用合成数据训练的模型甚至优于使用真实数据训练的模型。
最后，实验还表明这些模型具备语义类别的泛化能力，能够对训练时从未见过的网格模型作出准确预测。
