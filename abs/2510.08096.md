### Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting

Accurate face parsing under extreme viewing angles remains a significant challenge due to limited labeled data in such poses. Manual annotation is costly and often impractical at scale. We propose a novel label refinement pipeline that leverages 3D Gaussian Splatting (3DGS) to generate accurate segmentation masks from noisy multiview predictions. By jointly fitting two 3DGS models, one to RGB images and one to their initial segmentation maps, our method enforces multiview consistency through shared geometry, enabling the synthesis of pose-diverse training data with only minimal post-processing. Fine-tuning a face parsing model on this refined dataset significantly improves accuracy on challenging head poses, while maintaining strong performance on standard views. Extensive experiments, including human evaluations, demonstrate that our approach achieves superior results compared to state-of-the-art methods, despite requiring no ground-truth 3D annotations and using only a small set of initial images. Our method offers a scalable and effective solution for improving face parsing robustness in real-world settings.

在极端视角下实现精确的人脸解析仍是一项重大挑战，原因在于此类姿态下的标注数据极为稀缺。人工标注不仅成本高昂，而且在大规模场景中往往难以实现。为此，我们提出了一种基于三维高斯泼溅（3DGS）的标签精炼新方案，可通过多视角噪声预测生成准确的分割掩码。该方法联合拟合两个 3DGS 模型，分别对应原始 RGB 图像与其初始分割图，通过共享几何实现多视角一致性，从而仅需极少的后处理便可合成姿态多样的训练数据。利用该精炼数据集微调人脸解析模型，可显著提升其在困难头部姿态下的解析精度，同时在标准视角下仍保持优异性能。大量实验（包括人工评估）表明，尽管无需任何真实三维标注，且仅依赖少量初始图像，我们的方法在性能上仍全面优于现有最先进方法，提供了一种可扩展、有效的现实世界人脸解析鲁棒性提升方案。
