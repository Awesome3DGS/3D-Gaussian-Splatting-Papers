### Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields

Recent advancements in 2D and multimodal models have achieved remarkable success by leveraging large-scale training on extensive datasets. However, extending these achievements to enable free-form interactions and high-level semantic operations with complex 3D/4D scenes remains challenging. This difficulty stems from the limited availability of large-scale, annotated 3D/4D or multi-view datasets, which are crucial for generalizable vision and language tasks such as open-vocabulary and prompt-based segmentation, language-guided editing, and visual question answering (VQA). In this paper, we introduce Feature4X, a universal framework designed to extend any functionality from 2D vision foundation model into the 4D realm, using only monocular video input, which is widely available from user-generated content. The "X" in Feature4X represents its versatility, enabling any task through adaptable, model-conditioned 4D feature field distillation. At the core of our framework is a dynamic optimization strategy that unifies multiple model capabilities into a single representation. Additionally, to the best of our knowledge, Feature4X is the first method to distill and lift the features of video foundation models (e.g., SAM2, InternVideo2) into an explicit 4D feature field using Gaussian Splatting. Our experiments showcase novel view segment anything, geometric and appearance scene editing, and free-form VQA across all time steps, empowered by LLMs in feedback loops. These advancements broaden the scope of agentic AI applications by providing a foundation for scalable, contextually and spatiotemporally aware systems capable of immersive dynamic 4D scene interaction.

近年来，二维及多模态模型借助大规模数据训练，在多个任务上取得了显著成功。然而，将这些成果拓展到复杂三维/四维场景中的自由交互和高层语义操作仍面临巨大挑战。这主要归因于缺乏大规模带注释的三维/四维或多视图数据集，而这些数据对实现具备泛化能力的视觉-语言任务至关重要，如开放词汇与提示式分割、语言引导编辑、视觉问答（VQA）等。
为此，本文提出了 Feature4X ——一个通用框架，旨在将任何二维视觉基础模型的能力扩展到四维场景，仅需单目视频输入，这类数据广泛存在于用户生成内容中。框架名称中的 “X” 表示其通用性，通过可适配的、模型条件驱动的四维特征场蒸馏机制，支持任意任务。
Feature4X 的核心是一种动态优化策略，能够将多个模型能力统一融合进一个共享表示中。此外，据我们所知，Feature4X 是首个方法可将视频基础模型（如 SAM2、InternVideo2）的特征蒸馏并提升为显式的四维特征场，采用高斯溅射（Gaussian Splatting）进行建模。
实验展示了我们方法在任意视角分割（novel view segment anything）、几何与外观场景编辑以及**跨时间步的自由形式视觉问答（VQA）**中的强大能力，并通过大型语言模型（LLMs）引入反馈闭环。上述成果为具备时空感知和上下文理解能力的可扩展智能体系统奠定了基础，拓展了 Agentic AI 在沉浸式动态四维场景交互中的应用前景。
