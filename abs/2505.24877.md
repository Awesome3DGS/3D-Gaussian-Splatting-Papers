### AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion

Existing methods for image-to-3D avatar generation struggle to produce highly detailed, animation-ready avatars suitable for real-world applications. We introduce AdaHuman, a novel framework that generates high-fidelity animatable 3D avatars from a single in-the-wild image. AdaHuman incorporates two key innovations: (1) A pose-conditioned 3D joint diffusion model that synthesizes consistent multi-view images in arbitrary poses alongside corresponding 3D Gaussian Splats (3DGS) reconstruction at each diffusion step; (2) A compositional 3DGS refinement module that enhances the details of local body parts through image-to-image refinement and seamlessly integrates them using a novel crop-aware camera ray map, producing a cohesive detailed 3D avatar. These components allow AdaHuman to generate highly realistic standardized A-pose avatars with minimal self-occlusion, enabling rigging and animation with any input motion. Extensive evaluation on public benchmarks and in-the-wild images demonstrates that AdaHuman significantly outperforms state-of-the-art methods in both avatar reconstruction and reposing.

现有的图像到三维头像生成方法在生成具有高度细节、可用于动画制作的三维头像方面仍存在明显不足，难以满足现实应用需求。我们提出了 AdaHuman，一个能够从单张自然图像中生成高保真、可动画化三维头像的全新框架。

AdaHuman 包含两个关键创新点：
(1)	姿态条件 3D 关节点扩散模型：该模型可在任意姿态下合成一致的多视角图像，并在每一步扩散过程中同步完成对应的 3D Gaussian Splatting（3DGS）重建；
(2)	组合式 3DGS 细化模块：该模块通过图像到图像的细化方式增强局部身体部位的细节，并结合一种新颖的**裁剪感知相机光线映射（crop-aware camera ray map）**机制，实现各局部区域的无缝整合，最终生成一个结构完整、细节丰富的三维头像。
得益于以上设计，AdaHuman 能够生成高度写实的标准 A 姿态头像，自遮挡极小，便于进行骨骼绑定与任意动作的动画驱动。
在多个公开基准与真实自然图像上的广泛评估表明，AdaHuman 在头像重建与姿态迁移两个方面均显著优于当前最先进的方法。
