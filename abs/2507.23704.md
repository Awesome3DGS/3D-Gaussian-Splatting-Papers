### Enhanced Velocity Field Modeling for Gaussian Video Reconstruction

High-fidelity 3D video reconstruction is essential for enabling real-time rendering of dynamic scenes with realistic motion in virtual and augmented reality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has achieved near-photorealistic results in video reconstruction due to the great representation capability of deep deformation networks. However, in videos with complex motion and significant scale variations, deformation networks often overfit to irregular Gaussian trajectories, leading to suboptimal visual quality. Moreover, the gradient-based densification strategy designed for static scene reconstruction proves inadequate to address the absence of dynamic content. In light of these challenges, we propose a flow-empowered velocity field modeling scheme tailored for Gaussian video reconstruction, dubbed FlowGaussian-VR. It consists of two core components: a velocity field rendering (VFR) pipeline which enables optical flow-based optimization, and a flow-assisted adaptive densification (FAD) strategy that adjusts the number and size of Gaussians in dynamic regions. We validate our model's effectiveness on multi-view dynamic reconstruction and novel view synthesis with multiple real-world datasets containing challenging motion scenarios, demonstrating not only notable visual improvements (over 2.5 dB gain in PSNR) and less blurry artifacts in dynamic textures, but also regularized and trackable per-Gaussian trajectories.

高保真 3D 视频重建对于在虚拟现实（VR）和增强现实（AR）中实现具有真实运动的动态场景实时渲染至关重要。3D 高斯泼溅的形变场范式，凭借深度形变网络强大的表征能力，在视频重建中已取得接近照片级的效果。然而，在具有复杂运动和显著尺度变化的视频中，形变网络往往会对不规则的高斯轨迹发生过拟合，从而导致次优的视觉质量。此外，为静态场景重建设计的基于梯度的密集化策略，难以有效解决动态内容缺失的问题。针对这些挑战，我们提出了一种面向高斯视频重建的光流驱动速度场建模方案——FlowGaussian-VR。该方案包含两个核心组件：一是速度场渲染（VFR）流水线，使得基于光流的优化成为可能；二是光流辅助自适应密集化（FAD）策略，用于在动态区域调整高斯的数量与尺寸。我们在包含复杂运动场景的多个真实世界数据集上，验证了该模型在多视角动态重建和新视角合成任务中的有效性，结果显示不仅在视觉质量上有显著提升（PSNR 提高超过 2.5 dB），动态纹理中的模糊伪影减少，而且高斯粒子的轨迹更加规整且可追踪。
