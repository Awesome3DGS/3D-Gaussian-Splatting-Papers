### GSFix3D: Diffusion-Guided Repair of Novel Views in Gaussian Splatting

Recent developments in 3D Gaussian Splatting have significantly enhanced novel view synthesis, yet generating high-quality renderings from extreme novel viewpoints or partially observed regions remains challenging. Meanwhile, diffusion models exhibit strong generative capabilities, but their reliance on text prompts and lack of awareness of specific scene information hinder accurate 3D reconstruction tasks. To address these limitations, we introduce GSFix3D, a novel framework that improves the visual fidelity in under-constrained regions by distilling prior knowledge from diffusion models into 3D representations, while preserving consistency with observed scene details. At its core is GSFixer, a latent diffusion model obtained via our customized fine-tuning protocol that can leverage both mesh and 3D Gaussians to adapt pretrained generative models to a variety of environments and artifact types from different reconstruction methods, enabling robust novel view repair for unseen camera poses. Moreover, we propose a random mask augmentation strategy that empowers GSFixer to plausibly inpaint missing regions. Experiments on challenging benchmarks demonstrate that our GSFix3D and GSFixer achieve state-of-the-art performance, requiring only minimal scene-specific fine-tuning on captured data. Real-world test further confirms its resilience to potential pose errors.

近年来，三维高斯喷溅（3DGS）在新视角合成方面取得了显著进展，但从极端新视角或部分可见区域生成高质量渲染仍然具有挑战性。与此同时，扩散模型展现了强大的生成能力，但其对文本提示的依赖以及缺乏对具体场景信息的感知限制了其在精确三维重建任务中的应用。为克服这些限制，我们提出了 GSFix3D，一种新颖的框架，通过将扩散模型的先验知识蒸馏到三维表示中，提升欠约束区域的视觉保真度，同时保持与观测场景细节的一致性。其核心组件是 GSFixer，一种通过定制化微调协议获得的潜空间扩散模型，能够同时利用网格和三维高斯，将预训练生成模型适配到多种环境和来自不同重建方法的伪影类型，从而实现对未见相机位姿的鲁棒新视角修复。此外，我们提出了一种随机掩码增强策略，使 GSFixer 能够合理地补全缺失区域。大量具有挑战性的基准实验表明，GSFix3D 和 GSFixer 在仅需极少场景特定微调的情况下，达到了当前最先进的性能。真实场景测试进一步验证了其对潜在位姿误差的鲁棒性。
